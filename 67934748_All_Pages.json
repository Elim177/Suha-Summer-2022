[{"items": [{"tags": ["python", "tensorflow", "keras", "keras-layer", "model-fitting"], "owner": {"account_id": 20460445, "reputation": 119, "user_id": 15013202, "user_type": "registered", "profile_image": "https://i.stack.imgur.com/LYZT9.jpg?s=256&g=1", "display_name": "rolalaw", "link": "https://stackoverflow.com/users/15013202/rolalaw"}, "is_answered": false, "view_count": 60, "answer_count": 0, "score": 0, "last_activity_date": 1623421874, "creation_date": 1623404704, "last_edit_date": 1623421874, "question_id": 67934748, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/67934748/why-is-there-a-difference-between-a-for-loop-optimization-and-an-optimization-vi", "title": "Why is there a difference between a for-loop optimization and an optimization via a personalized .fit() method for a keras.Model?", "body": "<p>I have been trying to create a keras.Model which can fit a Generalized Pareto Distribution (GPD) based on either samples of a GPD or its quantiles. The fit is done by minimizing the difference between the observation and the quantiles of the estimated GPD.</p>\n<h3>Imports</h3>\n<pre><code>import tensorflow as tf\nfrom tensorflow import keras\nimport tensorflow_probability as tfp\n</code></pre>\n<h1>The GPD layer</h1>\n<p>I created a basic GPD layer by subclassing <code>keras.layers.Layer</code> and by keeping the parameters outside of the layer as recommanded for better performances. I am also using the GPD implemented in <code>tensorflow_probability.distributions.GeneralizedPareto</code> (<a href=\"https://www.tensorflow.org/probability/api_docs/python/tfp/distributions/GeneralizedPareto\" rel=\"nofollow noreferrer\">see doc</a>). The two parameters of the GPD are <code>gamma</code> and <code>sigma</code>.</p>\n<pre><code>class GPD_layer(keras.layers.Layer):\n    def __init__(self):\n        super(GPD_layer, self).__init__()\n    def call(self, gamma,sigma,num):\n        pareto = tfp.distributions.GeneralizedPareto(\n            loc=0.0,\n            scale=sigma,\n            concentration=gamma\n            )\n        return pareto.quantile(tf.cast(tf.range(start=1/(num+1),limit=1.0,delta=1/(num+1),dtype=tf.float64),dtype=tf.float32))\n</code></pre>\n<h1>The GPD model</h1>\n<p>I created a <code>keras.Model</code> subclass to have a proper model and to be able to train it like a regular keras.Model. Following the <a href=\"https://keras.io/guides/customizing_what_happens_in_fit/\" rel=\"nofollow noreferrer\">guide</a> provided by the Keras team. I made the following subclass :</p>\n<pre><code>class GPD_model(keras.Model):\n    def __init__(self):\n        super(GPD_model, self).__init__()\n        self.gpd_layer = GPD_layer()\n        self.gamma = tf.Variable(\n            initial_value=tf.random_normal_initializer(mean=0.2)(shape=(1,),dtype=&quot;float32&quot;),\n            trainable=True,\n            name=&quot;gamma&quot;)\n        self.sigma = tf.Variable(\n            initial_value=tf.random_normal_initializer(mean=1.0)(shape=(1,),dtype=&quot;float32&quot;),\n            trainable=True,\n            name=&quot;sigma&quot;)\n        \n    def call(self, num, training=None, *args, **kwargs):\n        if training:\n            return self.gpd_layer(gamma=self.gamma,sigma=self.sigma, num=num)\n        return self.gpd_layer(gamma=self.gamma, sigma=self.sigma, num=num)\n    \n    def train_step(self,data):\n        num = data.shape[0]\n        with tf.GradientTape() as tape:\n            X_gpd = self(num = num,training=True)\n            loss = tf.norm(data-X_gpd,ord=1)\n        gradients = tape.gradient(loss, [self.sigma, self.gamma])\n\n        self.optimizer.apply_gradients(zip(gradients, [self.sigma, self.gamma]))\n        return {&quot;loss&quot;:loss}\n</code></pre>\n<h2>Training the model</h2>\n<pre><code>N=1000\ngamma_th = 0.4\nsigma_th = 2.0\n\npareto = tfp.distributions.GeneralizedPareto(loc=0,scale=sigma_th,concentration=gamma_th)\nX_train = pareto.quantile(tf.cast(tf.range(start=1/(N+1),limit=1.0,delta=1/(N+1),dtype=tf.float64),dtype=tf.float32))\n\nmodel = GPD_model()\nmodel.compile(\n    optimizer=keras.optimizers.SGD(learning_rate=1e-2),\n    loss=&quot;mae&quot;,\n    run_eagerly=True\n    )\nhistory = model.fit(X_train, epochs=200, batch_size=X_train.shape[0])\n</code></pre>\n<p>This training leads to a value of gamma that becomes negative and that seems to diverge slowly and to the following effect on the loss :\n<a href=\"https://i.stack.imgur.com/5ULXU.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/5ULXU.png\" alt=\"Evolution of personalized fit\" /></a></p>\n<h2>Creating an other method</h2>\n<p>This is a method of the class <code>GPD_model</code> which is similar to an external training loop.</p>\n<pre><code>def manual_fit(self,data, epochs):\n        history = {&quot;loss&quot;:[],&quot;sigma&quot;:[],&quot;gamma&quot;:[]}\n        num = data.shape[0]\n        for step in range(epochs):\n            with tf.GradientTape() as tape:\n                Y = self(num = num)\n                loss = tf.norm(data-Y,ord=1)\n\n            gradients = tape.gradient(loss, [self.sigma,self.gamma])\n            self.optimizer.apply_gradients(zip(gradients, [self.sigma, self.gamma]))\n\n            history[&quot;loss&quot;].append(loss)\n            history[&quot;sigma&quot;].append(tf.constant(self.sigma))\n            history[&quot;gamma&quot;].append(tf.constant(gamma))\n            print(&quot;\\n&quot;,str(step+1)+&quot;/&quot;+str(epochs))\n            print([f&quot;{k}: {history[k][-1]}&quot; for k in history.keys()])\n        return history\n</code></pre>\n<p>This method leads to the expected behavior for the loss, gamma and sigma.</p>\n<p><a href=\"https://i.stack.imgur.com/cK2RU.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/cK2RU.png\" alt=\"Evolution of outter loop\" /></a></p>\n<p><em>Note that the two optimization methods were performed with the same number of epochs, the same learning rate and the same optimizer. The oscillations at the end are due to the fact that the learning rate is not the best one.</em></p>\n<h1>Questions</h1>\n<ul>\n<li>Why is there such a different behavior between the two methods?</li>\n<li>Does the <code>train_step</code> do something differents than the loops inside <code>.manual_fit()</code>?</li>\n<li>What is causing this ? Is it an issue related to the computation of the gradient? The fact that I'm using a <code>tensorflow_probability.distributions.Distribution</code>? Is it a difference of in the gradient descent method inside <code>.fit()</code> that I don't know?</li>\n</ul>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 125}]
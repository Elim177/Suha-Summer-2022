[{"items": [{"tags": ["python", "tensorflow", "keras", "tensorflow2.0", "dcgan"], "owner": {"user_type": "does_not_exist", "display_name": "user11563547"}, "is_answered": true, "view_count": 2580, "accepted_answer_id": 56944378, "answer_count": 2, "score": 0, "last_activity_date": 1568650294, "creation_date": 1561174126, "last_edit_date": 1568650294, "question_id": 56712351, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/56712351/how-to-ensure-tensorflow-generator-upsampling-process-creates-seed-with-full-cov", "title": "How to ensure TensorFlow Generator upsampling process creates seed with full coverage of random noise?", "body": "<p>I'm working on adapting the code from the tensorflow 2.0 dcGAN tutorial (<a href=\"https://www.tensorflow.org/beta/tutorials/generative/dcgan\" rel=\"nofollow noreferrer\">https://www.tensorflow.org/beta/tutorials/generative/dcgan</a>) to a spectrogram of audio signals.  I'm using libroasa chroma_cqt to convert the raw audio data into a WxHx2 matrix, and using that as the input.  When I attempt to create the seed matrix by upscaling random noise, the result I'm getting is an alternating bands in time-space of random noise and 0s and a thin black bar on the top (see image).<a href=\"https://i.stack.imgur.com/MpyAG.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/MpyAG.png\" alt=\"bared noise\"></a></p>\n\n<p>I've adapted the original tutorial code to work with various sized images with good results for the seed image and the ultimate output, but the same principals are not leading me anywhere with the 3 dimensional data.  How can I ensure that I'm making a seed with appropriate coverage, and not continuing the issue while actually training the model?</p>\n\n<pre><code>from __future__ import absolute_import, division, print_function, unicode_literals\n\nimport tensorflow as tf\n\ntf.__version__\n\nimport numpy as np\nimport os\nfrom tensorflow.keras import layers\nimport librosa\nimport librosa.display\n\nimport matplotlib.pyplot as plt\n\nos.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n\nsr = 44100/2\nsample_path = os.getcwd()\n\n\ndef make_generator_model():\n    model = tf.keras.Sequential()\n    model.add(layers.Dense(2*7*19*128, use_bias=False, dtype='float32', input_shape=(361,)))\n    model.add(layers.BatchNormalization())\n    model.add(layers.LeakyReLU())\n\n    model.add(layers.Reshape((2 ,7, 19, 128)))\n    assert model.output_shape == (None,2, 7, 19, 128) # Note: None is the batch size\n\n    model.add(layers.Conv3DTranspose(128, (2, 5, 5), strides=(1, 6, 1), padding='same', use_bias=False))\n    assert model.output_shape == (None, 2, 42, 19, 128)\n    model.add(layers.BatchNormalization())\n    model.add(layers.LeakyReLU())\n\n    model.add(layers.Conv3DTranspose(128, (2, 5, 5), strides=(1, 3, 19), padding='same', use_bias=False))\n    assert model.output_shape == (None, 2, 126, 361, 128)\n    model.add(layers.BatchNormalization())\n    model.add(layers.LeakyReLU())\n\n    model.add(layers.Conv3DTranspose(1, (2, 5, 5), strides=(1, 2, 1), padding='same', use_bias=False, activation='tanh'))\n    assert model.output_shape == (None, 2, 252, 361, 1)\n\n    return model\n\n\ngenerator = make_generator_model()\nnoise = tf.random.normal([1, 361])\ngenerated_audio = generator(noise, training=False)\n\n\nD = []\nfor x in range(len(generated_audio[0][0])):\n    this_line = []    \n    for y in range(len(generated_audio[0][0][x])):\n        this_line.append(np.complex(generated_audio[0][0][x][y],generated_audio[0][1][x][y]))\n    D.append(this_line)\nD = np.asarray(D)\n\n\nlibrosa.display.specshow(librosa.amplitude_to_db(np.abs(D), ref=np.max),\n                          sr=sr, x_axis='time', y_axis='cqt_note')\nplt.axis('off')\nplt.savefig(sample_path + '\\\\image_at_epoch_fuzz.png')\nplt.show()\n\n\nprint(D.shape)\n</code></pre>\n\n<p>I'm outputting a visual representation of the audio noise, which should look like an image that is completely fuzzy.  Instead I'm getting alternating noise and big black vertical bars and that thin black bar on the top.</p>\n\n<p>The question is ultimately what rules do I need to follow to match the generator seed, kernel size, and strides?  Can someone provide an example of how to programmatically ensure there isn't a mismatch in the strides and kernel size for a given number of layers?</p>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 47}]
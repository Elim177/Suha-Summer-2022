[{"items": [{"tags": ["python", "tensorflow"], "owner": {"account_id": 113180, "reputation": 4305, "user_id": 298209, "user_type": "registered", "accept_rate": 50, "profile_image": "https://www.gravatar.com/avatar/22dcc7ab1b47c2f014361452b5453544?s=256&d=identicon&r=PG&f=1", "display_name": "Milad", "link": "https://stackoverflow.com/users/298209/milad"}, "is_answered": true, "view_count": 388, "answer_count": 1, "score": 0, "last_activity_date": 1514494606, "creation_date": 1514491557, "question_id": 48013711, "content_license": "CC BY-SA 3.0", "link": "https://stackoverflow.com/questions/48013711/using-op-inputs-when-defining-custom-gradients-in-tensorflow", "title": "Using op inputs when defining custom gradients in TensorFlow", "body": "<p>I'm trying to define a gradient method for my custom TF operation. Most of the solutions I have found online seem to based on a <a href=\"https://gist.github.com/harpone/3453185b41d8d985356cbe5e57d67342\" rel=\"nofollow noreferrer\">gist</a> by <a href=\"https://github.com/harpone\" rel=\"nofollow noreferrer\">harpone</a>. I'm reluctant to use that approach as it uses <code>py_func</code> which won't run on GPU. I found another solution <a href=\"https://stackoverflow.com/questions/43256517/how-to-register-a-custom-gradient-for-a-operation-composed-of-tf-operations\">here</a> that uses <code>tf.identity()</code> that looks more elegant and I <em>think</em> will run on GPU. However, I have some problems accessing inputs of the ops in my custom gradient function. Here's my code:</p>\n\n<pre><code>@tf.RegisterGradient('MyCustomGradient')\ndef _custom_gradient(op, gradients):\n    x = op.inputs[0]\n    return(x)\n\ndef my_op(w):\n    return tf.pow(w,3)\n\n\nvar_foo = tf.Variable(5, dtype=tf.float32)\nbar = my_op(var_foo)\n\n\ng = tf.get_default_graph()\nwith g.gradient_override_map({'Identity': 'MyCustomGradient'}):\n    bar = tf.identity(bar)\n    g = tf.gradients(bar, var_foo)\n\nwith tf.Session() as sess:\n\n    sess.run(tf.global_variables_initializer())\n    print(sess.run(g))\n</code></pre>\n\n<p>I was expecting <code>_custom_gradient()</code> to return the input to the op (5 in this example) but instead it seems to return <code>op output x gradient</code>. My custom my_op will have non-differentiable operations like tf.sign and I'd like to define my custom gradient based on the inputs. What am I doing wrong?  </p>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 90}]
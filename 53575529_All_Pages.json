[{"items": [{"tags": ["python", "tensorflow", "tensorflow-estimator"], "owner": {"account_id": 3948330, "reputation": 5043, "user_id": 3259896, "user_type": "registered", "accept_rate": 60, "profile_image": "https://www.gravatar.com/avatar/641c30a7b383022f22b53c8cedb04e3f?s=256&d=identicon&r=PG&f=1", "display_name": "SantoshGupta7", "link": "https://stackoverflow.com/users/3259896/santoshgupta7"}, "is_answered": false, "view_count": 124, "answer_count": 1, "score": 0, "last_activity_date": 1543738544, "creation_date": 1543702604, "last_edit_date": 1543738544, "question_id": 53575529, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/53575529/question-on-tensorflow-estimator-practices-should-tensorflow-operations-be-cond", "title": "Question on Tensorflow Estimator practices, should Tensorflow Operations be conducted in `my_model`, or elsewhere?", "body": "<p>I am getting an error when I try to convert my model to use a Tensorflow Estimator, and it think it's due to <code>my_model</code> not having an active session in place. So should Tensorflow operations be conducted outside of my_model ?</p>\n\n<p>For example, I am getting an error by the way I currently define it:</p>\n\n<pre><code>def my_model( features, labels, mode, params):\n\n    train_dataset = features\n    train_labels = labels\n\n    batch_sizeE=params[\"batch_size\"]\n    embedding_sizeE=params[\"embedding_size\"]\n    num_inputsE=params[\"num_inputs\"]\n    num_sampledE=params[\"num_sampled\"]\n\n    print(features)\n    print(labels)\n\n    epochCount = tf.get_variable( 'epochCount', initializer= 0) #to store epoch count to total # of epochs are known\n    update_epoch = tf.assign(epochCount, epochCount + 1)\n\n    embeddings = tf.get_variable( 'embeddings', dtype=tf.float32,\n        initializer= tf.random_uniform([vocabulary_size, embedding_sizeE], -1.0, 1.0, dtype=tf.float32) )\n\n    softmax_weights = tf.get_variable( 'softmax_weights', dtype=tf.float32,\n        initializer= tf.truncated_normal([vocabulary_size, embedding_sizeE],\n                             stddev=1.0 / math.sqrt(embedding_sizeE), dtype=tf.float32 ) )\n\n    softmax_biases = tf.get_variable('softmax_biases', dtype=tf.float32,\n        initializer= tf.zeros([vocabulary_size], dtype=tf.float32),  trainable=False )\n\n    embed = tf.nn.embedding_lookup(embeddings, train_dataset) #train data set is\n\n    embed_reshaped = tf.reshape( embed, [batch_sizeE*num_inputs, embedding_sizeE] )\n\n    segments= np.arange(batch_size).repeat(num_inputs)\n\n    averaged_embeds = tf.segment_mean(embed_reshaped, segments, name=None)\n\n    if mode == \"train\":\n\n        sSML = tf.nn.sampled_softmax_loss(weights=softmax_weights, biases=softmax_biases, inputs=averaged_embeds,\n            labels=train_labels, num_sampled=64, num_classes=3096637)\n\n        loss = tf.reduce_mean( sSML )\n\n        optimizer = tf.train.AdagradOptimizer(1.0).minimize(loss) \n\n        return tf.estimator.EstimatorSpec(mode, loss=loss, train_op=optimizer)\n</code></pre>\n\n<p>The error is at the <code>sSML</code> loss function. Here is the error</p>\n\n<pre><code>INFO:tensorflow:Calling model_fn.\n\n&lt;tf.Variable 'softmax_weights:0' shape=(3096637, 50) dtype=float32_ref&gt;\n&lt;tf.Variable 'softmax_biases:0' shape=(3096637,) dtype=float32_ref&gt;\n---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\n&lt;ipython-input-49-955f44867ee5&gt; in &lt;module&gt;()\n      1 word2vecEstimator.train(\n      2     input_fn=generate_batch,\n----&gt; 3     steps=10)\n\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py in train(self, input_fn, hooks, steps, max_steps, saving_listeners)\n    352 \n    353       saving_listeners = _check_listeners_type(saving_listeners)\n--&gt; 354       loss = self._train_model(input_fn, hooks, saving_listeners)\n    355       logging.info('Loss for final step: %s.', loss)\n    356       return self\n\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py in _train_model(self, input_fn, hooks, saving_listeners)\n   1205       return self._train_model_distributed(input_fn, hooks, saving_listeners)\n   1206     else:\n-&gt; 1207       return self._train_model_default(input_fn, hooks, saving_listeners)\n   1208 \n   1209   def _train_model_default(self, input_fn, hooks, saving_listeners):\n\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py in _train_model_default(self, input_fn, hooks, saving_listeners)\n   1235       worker_hooks.extend(input_hooks)\n   1236       estimator_spec = self._call_model_fn(\n-&gt; 1237           features, labels, model_fn_lib.ModeKeys.TRAIN, self.config)\n   1238       global_step_tensor = training_util.get_global_step(g)\n   1239       return self._train_with_estimator_spec(estimator_spec, worker_hooks,\n\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py in _call_model_fn(self, features, labels, mode, config)\n   1193 \n   1194     logging.info('Calling model_fn.')\n-&gt; 1195     model_fn_results = self._model_fn(features=features, **kwargs)\n   1196     logging.info('Done calling model_fn.')\n   1197 \n\n&lt;ipython-input-47-95d390a50046&gt; in my_model(features, labels, mode, params)\n     47 \n     48         sSML = tf.nn.sampled_softmax_loss(weights=softmax_weights, biases=softmax_biases, inputs=averaged_embeds,\n---&gt; 49             labels=train_labels, num_sampled=64, num_classes=3096637)\n     50 \n     51         loss = tf.reduce_mean( sSML )\n\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py in sampled_softmax_loss(weights, biases, labels, inputs, num_sampled, num_classes, num_true, sampled_values, remove_accidental_hits, partition_strategy, name, seed)\n   1347       partition_strategy=partition_strategy,\n   1348       name=name,\n-&gt; 1349       seed=seed)\n   1350   labels = array_ops.stop_gradient(labels, name=\"labels_stop_gradient\")\n   1351   sampled_losses = nn_ops.softmax_cross_entropy_with_logits_v2(\n\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py in _compute_sampled_logits(weights, biases, labels, inputs, num_sampled, num_classes, num_true, sampled_values, subtract_log_q, remove_accidental_hits, partition_strategy, name, seed)\n   1029   with ops.name_scope(name, \"compute_sampled_logits\",\n   1030                       weights + [biases, inputs, labels]):\n-&gt; 1031     if labels.dtype != dtypes.int64:\n   1032       labels = math_ops.cast(labels, dtypes.int64)\n   1033     labels_flat = array_ops.reshape(labels, [-1])\n\nTypeError: data type not understood\n</code></pre>\n\n<p>I was wondering what the error was so I tried to print out my inputs to the samples softmax and I got this error</p>\n\n<pre><code>`ValueError: Cannot evaluate tensor using `eval()`: No default session is registered. Use `with sess.as_default()` or pass an explicit session to `eval(session=sess)`\n</code></pre>\n\n<p>So it seems that there is no active graph being run? </p>\n\n<p>Here's a link to my full code</p>\n\n<p><a href=\"https://colab.research.google.com/drive/1LH343QcKknMeUByjqifZPp2Hepfypz-L\" rel=\"nofollow noreferrer\">https://colab.research.google.com/drive/1LH343QcKknMeUByjqifZPp2Hepfypz-L</a></p>\n\n<p>Here is a link to the original question this is based on. </p>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 106}]
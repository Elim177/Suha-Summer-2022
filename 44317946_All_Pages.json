[{"items": [{"tags": ["tensorflow", "recurrent-neural-network"], "owner": {"account_id": 10716056, "reputation": 2138, "user_id": 7886651, "user_type": "registered", "accept_rate": 76, "profile_image": "https://i.stack.imgur.com/zfb59.jpg?s=256&g=1", "display_name": "I. A", "link": "https://stackoverflow.com/users/7886651/i-a"}, "is_answered": true, "view_count": 216, "accepted_answer_id": 44331314, "answer_count": 1, "score": 1, "last_activity_date": 1496413577, "creation_date": 1496355400, "last_edit_date": 1496369772, "question_id": 44317946, "content_license": "CC BY-SA 3.0", "link": "https://stackoverflow.com/questions/44317946/updating-the-initial-state-of-a-recurrent-neural-network-in-tensorflow", "title": "Updating the Initial state of a recurrent neural network in tensorflow", "body": "<p>Currently I have the following code:</p>\n\n<pre><code>init_state = tf.Variable(tf.zeros([batch_partition_length, state_size]))    # -&gt; [16, 1024].\nfinal_state = tf.Variable(tf.zeros([batch_partition_length, state_size]))\n\nAnd inside my inference method that is responsible producing the output, I have the following:\n\ndef inference(frames):\n    # Note that I write the final_state as a global valriable to avoid the shadowing issue, since it is referenced at the dynamic_rnn line. \n    global final_state\n    # ....  Here we have some conv layers and so on... \n\n    # Now the RNN cell\n    with tf.variable_scope('local1') as scope:\n\n        # Move everything into depth so we can perform a single matrix multiply.\n        shape_d = pool3.get_shape()\n        shape = shape_d[1] * shape_d[2] * shape_d[3]\n        # tf_shape = tf.stack(shape)\n        tf_shape = 1024\n\n        print(\"shape:\", shape, shape_d[1], shape_d[2], shape_d[3])\n\n        # So note that tf_shape = 1024, this means that we have 1024 features are fed into the network. And\n        # the batch size = 1024. Therefore, the aim is to divide the batch_size into num_steps so that\n        reshape = tf.reshape(pool3, [-1, tf_shape])\n        # Now we need to reshape/divide the batch_size into num_steps so that we would be feeding a sequence\n        rnn_inputs = tf.reshape(reshape, [batch_partition_length, step_size, tf_shape])\n\n        print('RNN inputs shape: ', rnn_inputs.get_shape()) # -&gt; (16, 64, 1024).\n\n        cell = tf.contrib.rnn.BasicRNNCell(state_size)\n        # note that rnn_outputs are the outputs but not multiplied by W.\n        rnn_outputs, final_state = tf.nn.dynamic_rnn(cell, rnn_inputs, initial_state=init_state)\n\n    # linear Wx + b\n    with tf.variable_scope('softmax_linear') as scope:\n        weight_softmax = \\\n            tf.Variable(\n                tf.truncated_normal([state_size, n_classes], stddev=1 / state_size, dtype=tf.float32, name='weight_softmax'))\n        bias_softmax = tf.constant(0.0, tf.float32, [n_classes], name='bias_softmax')\n\n        softmax_linear = tf.reshape(\n            tf.matmul(tf.reshape(rnn_outputs, [-1, state_size]), weight_softmax) + bias_softmax,\n            [batch_size, n_classes])\n\n        print('Output shape:', softmax_linear.get_shape())\n\n    return softmax_linear\n\n# Here we define the loss, accuracy and the optimzer. \n# now run the graph:\n\nwith tf.Session() as sess:\n    _, accuracy_train, loss_train, summary = \\\n            sess.run([optimizer, accuracy, cost_scalar, merged], feed_dict={x: image_batch,\n                                                                            y_valence: valences,\n                                                                            confidence_holder: confidences})\n\n    ....\n</code></pre>\n\n<p><strong>Problem</strong>: How I would be able to assign initial_state the value stored in final_state? That is, how to more update a Variable value given the other?</p>\n\n<p>I have used the following:</p>\n\n<pre><code>tf.assign(init_state, final_state.eval())\n</code></pre>\n\n<p>under session after running the sess.run command. But, this is throwing an error:\nYou must feed a value for placeholder tensor 'inputs' with dtype float\nWhere tf.Variable: \"input\" is declared as follows: </p>\n\n<pre><code>x = tf.placeholder(tf.float32, [None, 112, 112, 3], name='inputs')\n</code></pre>\n\n<p>And the feeding is done after reading the images from the tfRecords through the following command:</p>\n\n<pre><code>example = tf.train.Example()\nexample.ParseFromString(string_record)\n\nheight = int(example.features.feature['height']\n             .int64_list\n             .value[0])\n\nwidth = int(example.features.feature['width']\n            .int64_list\n            .value[0])\n\nimg_string = (example.features.feature['image_raw']\n              .bytes_list\n              .value[0])\n\nimg_1d = np.fromstring(img_string, dtype=np.uint8)\nreconstructed_img = img_1d.reshape((height, width, -1)) # Where this is added to the image_batch list, which is fed into the placeholder. \n</code></pre>\n\n<p>And if tried the following:</p>\n\n<pre><code>img_1d = np.fromstring(img_string, dtype=np.float32)\n</code></pre>\n\n<p>This will produce the following error: </p>\n\n<p>ValueError: cannot reshape array of size 9408 into shape (112,112,newaxis)</p>\n\n<p>Any help is much appreciated!!</p>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 69}]
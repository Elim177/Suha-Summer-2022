[{"items": [{"tags": ["python", "tensorflow", "machine-learning", "deep-learning", "generative-adversarial-network"], "owner": {"account_id": 14980499, "reputation": 1, "user_id": 13768102, "user_type": "registered", "profile_image": "https://www.gravatar.com/avatar/9b8d8c2141e581fe3d4e5a10f841d1ec?s=256&d=identicon&r=PG&f=1", "display_name": "shobi", "link": "https://stackoverflow.com/users/13768102/shobi"}, "is_answered": false, "view_count": 50, "answer_count": 1, "score": 0, "last_activity_date": 1599754975, "creation_date": 1592473901, "last_edit_date": 1592484007, "question_id": 62447232, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/62447232/getting-an-error-list-index-out-of-range-when-executing-tensorflow-code", "title": "Getting an error &quot;list index out of range&quot; when executing tensorflow code", "body": "<p>I am trying to execute following code developed in tensorflow for GAN, but whenever I execute it I receive index error \"list index out of range\"</p>\n\n<pre><code>\nimport pandas as pd\nimport numpy as np\nimport tensorflow as tf\nimport time\n\ndataset = pd.read_csv('kagglecreditcard.csv')\n\nis_Class0 = dataset['Class'] == 0\n\nnorm_set = dataset[is_Class0]\nis_Class1 = dataset['Class'] == 1\n\ntest_set = dataset[is_Class1]\n#test_labels = test_set.pop('Class')\n\nDATA_SIZE = 5\n# BATCH_SIZE = 50\n# TEST_SIZE = 400\n# LAYER_DENSITY = [500, 400, 300, 100, 31]\nEPOCHS = 5\n# noise_dim = 50\n\n\n# Y_test = test_set.sample(TEST_SIZE)\n# Y = tf.data.Dataset.from_tensor_slices(Y_test).batch(BATCH_SIZE)\n\n\nX_train = norm_set.sample(DATA_SIZE)\nnorm_targets = X_train.pop('Class')\nX = tf.data.Dataset.from_tensor_slices((X_train.values)).batch(1)\ntarget = tf.data.Dataset.from_tensor_slices((norm_targets.values))\n\nY_train = test_set.sample(DATA_SIZE)\nY = tf.data.Dataset.from_tensor_slices((Y_train.values))\n\ntwo = []\none = []\n\n\ndef make_generator():\n    inputs = tf.keras.Input(shape=(30,),name='myInput')\n    x = tf.keras.layers.Dense(50, activation=tf.nn.softmax)(inputs)\n    outputs = tf.keras.layers.Dense(30)(x)\n    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n\n    return model\n\n\ndef make_discriminator():\n    inputs = tf.keras.Input(shape=(30,))\n    x = tf.keras.layers.Dense(40, activation=tf.nn.softmax)(inputs)\n    outputs = tf.keras.layers.Dense(1, activation=tf.nn.leaky_relu)(x)\n    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n    return model\n\n\n# This method returns a helper function to compute cross entropy loss\ncross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n\ndef discriminator_loss(real_output, fake_output):\n    return tf.losses.binary_crossentropy(real_output, fake_output)\n\n\ndef generator_loss(ith_sample,fake_output):\n    return tf.keras.losses.kullback_leibler_divergence(ith_sample,fake_output)\n\n\n\ngenerator_optimizer = tf.keras.optimizers.Adam(1e-4)\ndiscriminator_optimizer = tf.keras.optimizers.Adam(1e-4)\n\nnoise = tf.random.normal([1,30])\n\ngenerator = make_generator()\ndiscriminator = make_discriminator()\n\ngen_out = generator(noise)\ndisc_out = discriminator(gen_out)\n\n\ngen_loss = generator_loss(two[0],gen_out)\ndisc_loss = discriminator_loss(one[0],disc_out)\n\n\n\n\nre_out = []\nfk_out = []\ngn_loss = []\ndc_loss = []\ngen_gradients = []\ndisc_gradients = []\n\ndef train_step(records):\n    noise = tf.random.normal([1, 30])\n\n    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n      generated_records = generator(noise, training=True)\n\n      real_output = discriminator(records, training=True)\n      fake_output = discriminator(generated_records, training=True)\n\n      re_out.append(real_output)\n      fk_out.append(fake_output)\n\n      gen_loss = generator_loss(records,fake_output)\n      disc_loss = discriminator_loss(real_output, fake_output)\n\n      gn_loss.append(gen_loss)\n      dc_loss.append(disc_loss)\n\n\n    gradients_of_generator = gen_tape.gradient(tuple(gen_loss), generator.trainable_variables)\n    gradients_of_discriminator = disc_tape.gradient(tuple(disc_loss), discriminator.trainable_variables)\n\n    gen_gradients.append(gradients_of_generator)\n    disc_gradients.append(gradients_of_discriminator)\n\n    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n\n\ndef train(dataset, epochs):\n\n   for epoch in range(epochs):\n     start = time.time()\n\n\n     for image_batch in dataset:\n       train_step(image_batch)\n\n\n     print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n\n\ntrain(X, 4)\n\n\n</code></pre>\n\n<p>But when I execute the code, I get an error:</p>\n\n<p><a href=\"https://i.stack.imgur.com/EFPSH.png\" rel=\"nofollow noreferrer\">error in the generation of loss value; hence there won't be any gradient associated with it</a></p>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 222}]
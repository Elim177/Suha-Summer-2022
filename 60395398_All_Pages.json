[{"items": [{"tags": ["tensorflow", "keras", "python-3.6", "tensorflow2.0"], "owner": {"account_id": 17358980, "reputation": 91, "user_id": 12575714, "user_type": "registered", "profile_image": "https://www.gravatar.com/avatar/671029a3023bda059a9105fd1ef2473b?s=256&d=identicon&r=PG&f=1", "display_name": "Endurance", "link": "https://stackoverflow.com/users/12575714/endurance"}, "is_answered": true, "view_count": 587, "accepted_answer_id": 61135887, "answer_count": 1, "score": 3, "last_activity_date": 1657799022, "creation_date": 1582636169, "last_edit_date": 1657799022, "question_id": 60395398, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/60395398/correct-way-to-apply-gradients-in-tf2-custom-training-loop-with-multiple-keras-m", "title": "Correct way to apply gradients in TF2 custom training loop with multiple Keras models", "body": "<p>I am working to implement a custom training loop with GradientTape involving multiple Keras models.\nI have 3 networks, <code>model_a</code>, <code>model_b</code>, and <code>model_c</code>. I have created a list to hold their <code>trainbale_weights</code> as:</p>\n<pre><code>trainables = list() \ntrainables.append(model_a.trainable_weights) # CovNet \ntrainables.append(model_b.trainable_weights) # CovNet \ntrainables.append(model_c.trainable_weights) # Fully Connected Network\n</code></pre>\n<p>I then calculate loss and try to apply gradients as:</p>\n<pre><code>loss = 0.\noptimizer = tf.keras.optimizers.Adam()\nfor x, y in train_dataset:\n    with tf.GradientTape() as tape:\n        y = ...\n        loss = ... # custom loss function!\n    gradients = tape.gradient(loss, trainables)\n    optimizer.apply_gradients(zip(gradients, trainables))    \n</code></pre>\n<p>But I get a following error I am not sure where's the mistake:</p>\n<pre><code>AttributeError: 'list' object has no attribute '_in_graph_mode'\n</code></pre>\n<p>If I iterate over gradients and trainables and then apply gradients it works but I am not sure if this is the right way to do it.</p>\n<pre><code>for i in range(len(gradients)):\n    optimizer.apply_gradients(zip(gradients[i], trainables[i]))\n</code></pre>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 110}]
[{"items": [{"tags": ["keras", "tensorflow2.0"], "owner": {"account_id": 108161, "reputation": 5951, "user_id": 287238, "user_type": "registered", "accept_rate": 75, "profile_image": "https://i.stack.imgur.com/oQJH2.jpg?s=256&g=1", "display_name": "mathtick", "link": "https://stackoverflow.com/users/287238/mathtick"}, "is_answered": false, "view_count": 414, "answer_count": 1, "score": 1, "last_activity_date": 1567763756, "creation_date": 1567714950, "last_edit_date": 1567763756, "question_id": 57812517, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/57812517/how-to-create-a-keras-model-that-depends-dynamically-on-the-input-dimension-not", "title": "How to create a keras model that depends dynamically on the input dimension (not batch size)?", "body": "<p>If you use the keras subclass api and you want to spawn a bunch of layers (n) depending on the the input dimension x = (batch_dim, n) is there a way to do this inside the build method? </p>\n\n<p>Or is the only way to pass the input dim into the model at <strong>init</strong> time so the layers can be created within the init scope? </p>\n\n<p>UPDATE: pseudo-code (untested) example</p>\n\n<pre><code>class BigModel(tf.keras.models.Model):\n    def __init__(self):\n        super.__init__()\n        self._my_submodels = list()\n\n    def build(self, input_shape):\n        for i in range(input_shape[1]):\n            self.my_submodels.append(MyModel(param=i))\n\n    def call(self, *inputs):\n        stuff = list()\n        for submodel in self.my_submodels:\n            stuff.append(submodel(*inputs))\n        # do something amazing with all the models\n        fan_in = ... # combine \n        return fan_in\n</code></pre>\n\n<p>You could <em>probably</em> rewrite the whole structure in a more vectorized way using one model with a lot of splits but it will be harder to read and deal with and I think the new tf 2.0 allows this kind of dynamism without any cost penalty.</p>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 72}]
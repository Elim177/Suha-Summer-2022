[{"items": [{"tags": ["tensorflow"], "owner": {"account_id": 7060318, "reputation": 869, "user_id": 5405823, "user_type": "registered", "accept_rate": 50, "profile_image": "https://i.stack.imgur.com/5H9hi.jpg?s=256&g=1", "display_name": "thinkdeep", "link": "https://stackoverflow.com/users/5405823/thinkdeep"}, "is_answered": false, "view_count": 447, "answer_count": 1, "score": 0, "last_activity_date": 1609875042, "creation_date": 1609873704, "question_id": 65585095, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/65585095/why-tf-keras-optimizers-sgd-has-no-global-step", "title": "Why tf.keras.optimizers.SGD has no global_step", "body": "<p>In TF 1.14, below code will raise exception.</p>\n<pre><code> optimizer = tf.keras.optimizers.SGD(learning_rate=params['lr'])\n train_op = optimizer.minimize(loss, global_step=tf.train.get_or_create_global_step())\n</code></pre>\n<p>The exception is</p>\n<pre><code>TypeError: minimize() got an unexpected keyword argument 'global_step'\n</code></pre>\n<p>It seems that <code>tf.keras.optimizers</code> in unavailable in TF 1.14. However, why the <code>global_step</code> is gone in tf.keras.optimizers.SGD? It is supposed to be there in <code>tf.train.Optimizer</code> of TF 1.14</p>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 268}]
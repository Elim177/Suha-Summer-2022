[{"items": [{"tags": ["python", "tensorflow", "machine-learning", "deep-learning", "autoencoder"], "owner": {"account_id": 1162208, "reputation": 24701, "user_id": 1141493, "user_type": "registered", "accept_rate": 99, "profile_image": "https://www.gravatar.com/avatar/25452a0e44babf480d85311e5ece4421?s=256&d=identicon&r=PG", "display_name": "kiriloff", "link": "https://stackoverflow.com/users/1141493/kiriloff"}, "is_answered": false, "view_count": 568, "answer_count": 1, "score": 0, "last_activity_date": 1631740444, "creation_date": 1631706551, "last_edit_date": 1631740444, "question_id": 69192568, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/69192568/tensorflow-save-and-load-variational-auto-encoder-model", "title": "tensorflow save and load variational auto encoder model", "body": "<p>I run a python script based on this <a href=\"https://colab.research.google.com/github/tensorflow/probability/blob/main/tensorflow_probability/examples/jupyter_notebooks/Probabilistic_Layers_VAE.ipynb#scrollTo=ow7rfh6YLLx1\" rel=\"nofollow noreferrer\">tensorflow colab</a> : I rewrote the colab content into a script which I run under linux on a server with 2 GPUs --&gt; this runs smoothly. I refer to the colab code implementation in this post.</p>\n<p>I would like now to modify the script in order to practice saving and loading the model.</p>\n<p><strong>two models</strong></p>\n<p>&quot;Two models&quot; are used to illustrate the training : (1) the whole <code>variational encoder model</code>, variable named <code>vae</code> in the script, which is made of an encoder and a decoder part, and (2) the <code>decoder model only</code>, created with the Functional API and variable named <code>decoder</code> in the script.</p>\n<p>I quote the implementation for the encoder</p>\n<pre><code>encoder = tfk.Sequential([\n    tfkl.InputLayer(input_shape=input_shape),\n    tfkl.Lambda(lambda x: tf.cast(x, tf.float32) - 0.5),\n    tfkl.Conv2D(base_depth, 5, strides=1,\n                padding='same', activation=tf.nn.leaky_relu),\n    tfkl.Conv2D(base_depth, 5, strides=2,\n                padding='same', activation=tf.nn.leaky_relu),\n    tfkl.Conv2D(2 * base_depth, 5, strides=1,\n                padding='same', activation=tf.nn.leaky_relu),\n    tfkl.Conv2D(2 * base_depth, 5, strides=2,\n                padding='same', activation=tf.nn.leaky_relu),\n    tfkl.Conv2D(4 * encoded_size, 7, strides=1,\n                padding='valid', activation=tf.nn.leaky_relu),\n    tfkl.Flatten(),\n    tfkl.Dense(tfpl.MultivariateNormalTriL.params_size(encoded_size),\n               activation=None),\n    tfpl.MultivariateNormalTriL(\n        encoded_size,\n        activity_regularizer=tfpl.KLDivergenceRegularizer(prior)),\n])\n</code></pre>\n<p>the decoder</p>\n<pre><code>decoder = tfk.Sequential([\n    tfkl.InputLayer(input_shape=[encoded_size]),\n    tfkl.Reshape([1, 1, encoded_size]),\n    tfkl.Conv2DTranspose(2 * base_depth, 7, strides=1,\n                         padding='valid', activation=tf.nn.leaky_relu),\n    tfkl.Conv2DTranspose(2 * base_depth, 5, strides=1,\n                         padding='same', activation=tf.nn.leaky_relu),\n    tfkl.Conv2DTranspose(2 * base_depth, 5, strides=2,\n                         padding='same', activation=tf.nn.leaky_relu),\n    tfkl.Conv2DTranspose(base_depth, 5, strides=1,\n                         padding='same', activation=tf.nn.leaky_relu),\n    tfkl.Conv2DTranspose(base_depth, 5, strides=2,\n                         padding='same', activation=tf.nn.leaky_relu),\n    tfkl.Conv2DTranspose(base_depth, 5, strides=1,\n                         padding='same', activation=tf.nn.leaky_relu),\n    tfkl.Conv2D(filters=1, kernel_size=5, strides=1,\n                padding='same', activation=None),\n    tfkl.Flatten(),\n    tfpl.IndependentBernoulli(input_shape, tfd.Bernoulli.logits),\n])\n</code></pre>\n<p>the whole variational autoencoder</p>\n<pre><code>vae = tfk.Model(inputs=encoder.inputs,\n                outputs=decoder(encoder.outputs[0])) \n</code></pre>\n<p>Illustration goes as follow, (1) we take ten digits and apply the whole encoding+decoding chain on it to vizualize the reconstruction. We use the <code>vae</code> model.</p>\n<pre><code># We'll just examine ten random digits.\nx = next(iter(eval_dataset))[0][:10]\nxhat = vae(x)\n</code></pre>\n<p>(2) we sample 10 &quot;never-seen-before&quot; digits from our prior distribution, and apply the decoder to obtain realistic &quot;hand-written&quot; digits</p>\n<pre><code># Now, let's generate ten never-before-seen digits.\nz = prior.sample(10)\nxtilde = decoder(z)\n</code></pre>\n<p><strong>my question : how to implement saving and loading the models</strong></p>\n<p>This is my code change for saving the <code>vae</code> modelL</p>\n<pre><code>vae.save('saved_vae')\n</code></pre>\n<p>which produces this error</p>\n<pre><code>Traceback (most recent call last):\n  File &quot;probabilistic_vae.py&quot;, line 103, in &lt;module&gt;\n    vae.save('saved_vae')\n  File &quot;/usr/local/lib/python3.6/dist-packages/keras/engine/training.py&quot;, line 2146, in save\n    signatures, options, save_traces)\n  File &quot;/usr/local/lib/python3.6/dist-packages/keras/saving/save.py&quot;, line 150, in save_model\n    signatures, options, save_traces)\n  File &quot;/usr/local/lib/python3.6/dist-packages/keras/saving/saved_model/save.py&quot;, line 91, in save\n    model, filepath, signatures, options)\n  File &quot;/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/save.py&quot;, line 1228, in save_and_return_nodes\n    _build_meta_graph(obj, signatures, options, meta_graph_def))\n  File &quot;/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/save.py&quot;, line 1399, in _build_meta_graph\n    return _build_meta_graph_impl(obj, signatures, options, meta_graph_def)\n  File &quot;/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/save.py&quot;, line 1336, in _build_meta_graph_impl\n    checkpoint_graph_view)\n  File &quot;/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/signature_serialization.py&quot;, line 99, in find_function_to_export\n    functions = saveable_view.list_functions(saveable_view.root)\n  File &quot;/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/save.py&quot;, line 164, in list_functions\n    self._serialization_cache)\n  File &quot;/usr/local/lib/python3.6/dist-packages/keras/engine/training.py&quot;, line 2813, in _list_functions_for_serialization\n    Model, self)._list_functions_for_serialization(serialization_cache)\n  File &quot;/usr/local/lib/python3.6/dist-packages/keras/engine/base_layer.py&quot;, line 3086, in _list_functions_for_serialization\n    .list_functions_for_serialization(serialization_cache))\n  File &quot;/usr/local/lib/python3.6/dist-packages/keras/saving/saved_model/base_serialization.py&quot;, line 93, in list_functions_for_serialization\n    fns = self.functions_to_serialize(serialization_cache)\n  File &quot;/usr/local/lib/python3.6/dist-packages/keras/saving/saved_model/layer_serialization.py&quot;, line 74, in functions_to_serialize\n    serialization_cache).functions_to_serialize)\n  File &quot;/usr/local/lib/python3.6/dist-packages/keras/saving/saved_model/layer_serialization.py&quot;, line 90, in _get_serialized_attributes\n    serialization_cache)\n  File &quot;/usr/local/lib/python3.6/dist-packages/keras/saving/saved_model/model_serialization.py&quot;, line 57, in _get_serialized_attributes_internal\n    serialization_cache))\n  File &quot;/usr/local/lib/python3.6/dist-packages/keras/saving/saved_model/layer_serialization.py&quot;, line 99, in _get_serialized_attributes_internal\n    functions = save_impl.wrap_layer_functions(self.obj, serialization_cache)\n  File &quot;/usr/local/lib/python3.6/dist-packages/keras/saving/saved_model/save_impl.py&quot;, line 149, in wrap_layer_functions\n    original_fns = _replace_child_layer_functions(layer, serialization_cache)\n  File &quot;/usr/local/lib/python3.6/dist-packages/keras/saving/saved_model/save_impl.py&quot;, line 277, in _replace_child_layer_functions\n    serialization_cache).functions)\n  File &quot;/usr/local/lib/python3.6/dist-packages/keras/saving/saved_model/layer_serialization.py&quot;, line 90, in _get_serialized_attributes\n    serialization_cache)\n  File &quot;/usr/local/lib/python3.6/dist-packages/keras/saving/saved_model/layer_serialization.py&quot;, line 99, in _get_serialized_attributes_internal\n    functions = save_impl.wrap_layer_functions(self.obj, serialization_cache)\n  File &quot;/usr/local/lib/python3.6/dist-packages/keras/saving/saved_model/save_impl.py&quot;, line 197, in wrap_layer_functions\n    fn.get_concrete_function()\n  File &quot;/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py&quot;, line 1233, in get_concrete_function\n    concrete = self._get_concrete_function_garbage_collected(*args, **kwargs)\n  File &quot;/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py&quot;, line 1213, in _get_concrete_function_garbage_collected\n    self._initialize(args, kwargs, add_initializers_to=initializers)\n  File &quot;/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py&quot;, line 760, in _initialize\n    *args, **kwds))\n  File &quot;/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py&quot;, line 3066, in _get_concrete_function_internal_garbage_collected\n    graph_function, _ = self._maybe_define_function(args, kwargs)\n  File &quot;/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py&quot;, line 3463, in _maybe_define_function\n    graph_function = self._create_graph_function(args, kwargs)\n  File &quot;/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py&quot;, line 3308, in _create_graph_function\n    capture_by_value=self._capture_by_value),\n  File &quot;/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py&quot;, line 1007, in func_graph_from_py_func\n    func_outputs = python_func(*func_args, **func_kwargs)\n  File &quot;/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py&quot;, line 668, in wrapped_fn\n    out = weak_wrapped_fn().__wrapped__(*args, **kwds)\n  File &quot;/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py&quot;, line 994, in wrapper\n    raise e.ag_error_metadata.to_exception(e)\nAttributeError: in user code:\n\n    /usr/local/lib/python3.6/dist-packages/tensorflow_probability/python/layers/distribution_layer.py:1261 __call__  *\n        return self._kl_divergence_fn(distribution_a)\n    /usr/local/lib/python3.6/dist-packages/tensorflow_probability/python/layers/distribution_layer.py:1380 _fn  **\n        kl = kl_divergence_fn(distribution_a, distribution_b_)\n    /usr/local/lib/python3.6/dist-packages/tensorflow_probability/python/layers/distribution_layer.py:1364 kl_divergence_fn\n        distribution_a.log_prob(z) - distribution_b.log_prob(z),\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:401 __getattr__\n        self.__getattribute__(name)\n\n    AttributeError: 'Tensor' object has no attribute 'log_prob'\n</code></pre>\n<p><strong>Beyond this error, I would like to know if my implementation and my approach is correct.</strong></p>\n<p>I do the same for the decoder only</p>\n<pre><code>decoder_rec=keras.models.load_model('decoder_saved')\n\n# Now, let's generate ten never-before-seen digits.\nz = prior.sample(10)\nxtilde = decoder_rec(z)\nassert isinstance(xtilde, tfd.Distribution)\n</code></pre>\n<p>Same thing, I would like to know if my approach is correct : saving and loading separately weights/model corresponding to the &quot;whole vae&quot; and to the &quot;decoder only&quot;.</p>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 45}]
[{"items": [{"tags": ["python", "tensorflow", "keras", "google-colaboratory"], "owner": {"account_id": 6544044, "reputation": 551, "user_id": 5060588, "user_type": "registered", "profile_image": "https://www.gravatar.com/avatar/2b49c205f9c761e0aa134916965faec5?s=256&d=identicon&r=PG&f=1", "display_name": "Roshan Salian", "link": "https://stackoverflow.com/users/5060588/roshan-salian"}, "is_answered": false, "view_count": 4575, "answer_count": 1, "score": 0, "last_activity_date": 1653380028, "creation_date": 1621972380, "question_id": 67694762, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/67694762/from-keras-engine-import-inputspec-stopped-working", "title": "from keras.engine import InputSpec stopped working", "body": "<p>I was using InputSpec in my code from 'keras.engine' but it has suddenly stopped importing in Google colab. Used to work fine till yesterday.</p>\n<pre><code>ImportError: cannot import name 'InputSpec' from 'keras.engine' (/usr/local/lib/python3.7/dist-packages/keras/engine/__init__.py)\n</code></pre>\n<p>I realise there is 'from keras.layers import InputSpec' which works without error. However, I was traing my model using InputSpec from 'keras.engine' and now I am unable to load previously saved model. When I try to load previously saved model I get the error</p>\n<pre><code>ValueError: You are trying to load a weight file containing 29 layers into a model with 24 layers.\n</code></pre>\n<p>Is there anyway I can use my older saved models again?</p>\n<p>I was using InputSpec in Reflection Padding code</p>\n<pre><code>def spatial_reflection_2d_padding(x, padding=((1, 1), (1, 1)), data_format=None):\n\nassert len(padding) == 2\nassert len(padding[0]) == 2\nassert len(padding[1]) == 2\n\nif data_format is None:\n    data_format = image_data_format()\n\nif data_format not in {'channels_first', 'channels_last'}:\n    raise ValueError('Unknown data_format ' + str(data_format))\n\nif data_format == 'channels_first':\n    pattern = [[0, 0],\n               [0, 0],\n               list(padding[0]),\n               list(padding[1])]\nelse:\n    pattern = [[0, 0],\n               list(padding[0]), list(padding[1]),\n               [0, 0]]\nreturn tf.pad(x, pattern, &quot;REFLECT&quot;)\n\nclass ReflectionPadding2D(Layer):\n\n    def __init__(self,\n                 padding=(1, 1),\n                 data_format=None,\n                 **kwargs):\n        super(ReflectionPadding2D, self).__init__(**kwargs)\n        self.data_format = normalize_data_format(data_format)\n        if isinstance(padding, int):\n            self.padding = ((padding, padding), (padding, padding))\n        elif hasattr(padding, '__len__'):\n            if len(padding) != 2:\n                raise ValueError('`padding` should have two elements. '\n                                 'Found: ' + str(padding))\n            height_padding = conv_utils.normalize_tuple(padding[0], 2,\n                                                        '1st entry of padding')\n            width_padding = conv_utils.normalize_tuple(padding[1], 2,\n                                                       '2nd entry of padding')\n            self.padding = (height_padding, width_padding)\n        else:\n            raise ValueError('`padding` should be either an int, '\n                             'a tuple of 2 ints '\n                             '(symmetric_height_pad, symmetric_width_pad), '\n                             'or a tuple of 2 tuples of 2 ints '\n                             '((top_pad, bottom_pad), (left_pad, right_pad)). '\n                             'Found: ' + str(padding))\n        self.input_spec = InputSpec(ndim=4)\n\n    def compute_output_shape(self, input_shape):\n        if self.data_format == 'channels_first':\n            if input_shape[2] is not None:\n                rows = input_shape[2] + self.padding[0][0] + self.padding[0][1]\n            else:\n                rows = None\n            if input_shape[3] is not None:\n                cols = input_shape[3] + self.padding[1][0] + self.padding[1][1]\n            else:\n                cols = None\n            return (input_shape[0],\n                    input_shape[1],\n                    rows,\n                    cols)\n        elif self.data_format == 'channels_last':\n            if input_shape[1] is not None:\n                rows = input_shape[1] + self.padding[0][0] + self.padding[0][1]\n            else:\n                rows = None\n            if input_shape[2] is not None:\n                cols = input_shape[2] + self.padding[1][0] + self.padding[1][1]\n            else:\n                cols = None\n            return (input_shape[0],\n                    rows,\n                    cols,\n                    input_shape[3])\n\n    def call(self, inputs):\n        return spatial_reflection_2d_padding(inputs,\n                                             padding=self.padding,\n                                             data_format=self.data_format)\n\n    def get_config(self):\n        config = {'padding': self.padding,\n                  'data_format': self.data_format}\n        base_config = super(ReflectionPadding2D, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n</code></pre>\n<p>Code of generator model with mismatched layers</p>\n<pre><code>def generator_model():\ninputs = Input(shape=image_shape)\n\nx = ReflectionPadding2D((3, 3))(inputs)\nx = Conv2D(filters=ngf, kernel_size=(7, 7), padding='valid')(x)\nx = InstanceNormalization()(x)\nx0 = Activation('relu')(x)\n\nn_downsampling = 2\n\nmult = 1 #128 filters\nx = Conv2D(filters=ngf*mult*2, kernel_size=(3, 3), strides=2, padding='same')(x0) \nx = InstanceNormalization()(x)\nx1 = Activation('relu')(x)\n\nmult = 2 #256 filters\nx = Conv2D(filters=ngf*mult*2, kernel_size=(3, 3), strides=2, padding='same')(x1) \nx = InstanceNormalization()(x)\nx2 = Activation('relu')(x)\n\nmult = 2**n_downsampling\nfor i in range(n_blocks_gen):\n    x = res_block(x, ngf*mult, use_dropout=True)   \nx = concatenate([x, x2])\n\nmult = 2**(n_downsampling - 0)\nx = UpSampling2D()(x)\nx = Conv2D(filters=int(ngf * mult / 2), kernel_size=(3, 3), padding='same')(x)\nx = InstanceNormalization()(x)\nx = Activation('relu')(x)\nx = concatenate([x, x1])\n\nmult = 2**(n_downsampling - 1)\nx = UpSampling2D()(x)\nx = Conv2D(filters=int(ngf * mult / 2), kernel_size=(3, 3), padding='same')(x)\nx = InstanceNormalization()(x)\nx = Activation('relu')(x)\nx = concatenate([x, x0])\n\n\nx = ReflectionPadding2D((3, 3))(x)\nx = Conv2D(filters=output_nc, kernel_size=(7, 7), padding='valid')(x)\nx = Activation('tanh')(x)\n\noutputs = Add()([x, inputs])\noutputs = Lambda(lambda z: z/2)(outputs)\n\nmodel = Model(inputs=inputs, outputs=outputs, name='Generator')\nreturn model\n</code></pre>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 135}]
[{"items": [{"tags": ["tensorflow"], "owner": {"account_id": 8550263, "reputation": 2937, "user_id": 6407393, "user_type": "registered", "accept_rate": 57, "profile_image": "https://www.gravatar.com/avatar/9bb0b98b4ea95c6d68fbe20eedcb7f81?s=256&d=identicon&r=PG&f=1", "display_name": "yanachen", "link": "https://stackoverflow.com/users/6407393/yanachen"}, "is_answered": true, "view_count": 478, "answer_count": 1, "score": 0, "last_activity_date": 1521650134, "creation_date": 1515034180, "question_id": 48088000, "content_license": "CC BY-SA 3.0", "link": "https://stackoverflow.com/questions/48088000/initializing-the-embedding-tensor-with-a-local-numpy-array", "title": "Initializing the embedding tensor with a local numpy array", "body": "<p>I want to initialize the word embedding layer from a local numpy array with the same shape, which is a pre trained embedding from another model.\nIt is OK if I did not add the partitioner param.\ndef word_embedding(shape, dtype=tf.float32, name='word_embedding'):</p>\n\n<pre><code>  f = open('./cnn_embed_array', 'r')\n  embedding_array = pickle.load(f)\n  f.close()\n  print 'embedding_array loaded......'\n  with tf.device('/cpu:0'), tf.variable_scope(name):\n    return tf.get_variable('embedding', shape, dtype=dtype, initializer=tf.constant_initializer(embedding_array), trainable = False) \n</code></pre>\n\n<p>But if I add <code>partitioner=tf.fixed_size_partitioner(20)</code> in the tf.get_variable function, it give me error saying that the param is redundant.</p>\n\n<p><code>partitioner</code>  param tends to accelerate the training speed. Can I add the param in some other way ?</p>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 88}]
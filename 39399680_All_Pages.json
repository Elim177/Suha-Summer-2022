[{"items": [{"tags": ["tensorflow"], "owner": {"account_id": 3237236, "reputation": 1636, "user_id": 2731113, "user_type": "registered", "accept_rate": 100, "profile_image": "https://www.gravatar.com/avatar/?s=256&d=identicon&r=PG&f=1", "display_name": "Davis Yoshida", "link": "https://stackoverflow.com/users/2731113/davis-yoshida"}, "is_answered": false, "view_count": 52, "answer_count": 0, "score": 0, "last_activity_date": 1473366589, "creation_date": 1473366589, "question_id": 39399680, "content_license": "CC BY-SA 3.0", "link": "https://stackoverflow.com/questions/39399680/losing-performance-when-switching-order-of-operations-in-tensorflow", "title": "Losing performance when switching order of operations in tensorflow", "body": "<p>I want to put a softmax layer on the final output of an RNN. However, not all my sequences are the same length, so I am using tf.gather() to collect the final outputs of the RNN. For some reason, I have to do this <em>after</em> I apply the matrix multiplication for the softmax like so:</p>\n\n<pre><code>rnn_output = make_rnn_output()\noutputs = tf.reshape(rnn_output, (-1, self._num_units))\n\nindices = (tf.range(self._batch_size) *\n               self._max_steps + self._sequence_length - 1)\nsoftmax_w = tf.get_variable('softmax_w', (self._num_units, self._output_size))\nsoftmax_b = tf.get_variable('softmax_b', self._output_size)\nlogits = tf.matmul(outputs, softmax_w) + softmax_b\nfinal_logits = tf.gather(indices)\n# blah blah\n</code></pre>\n\n<p>If I move the gather call to before the matmul call, I get significantly lower accuracy. I do not see why this is the case, as it should make no difference. I would like to move the gather call before the matmul call to reduce the unnecessary operations being done in the matmul.</p>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 40}]
[{"items": [{"tags": ["tensorflow", "keras", "conv-neural-network", "matrix-multiplication", "array-broadcasting"], "owner": {"account_id": 9968983, "reputation": 2869, "user_id": 7375754, "user_type": "registered", "accept_rate": 77, "profile_image": "https://www.gravatar.com/avatar/830f6d236ab0502a68fd9b9daf7f729f?s=256&d=identicon&r=PG&f=1", "display_name": "Jane Sully", "link": "https://stackoverflow.com/users/7375754/jane-sully"}, "is_answered": true, "view_count": 865, "accepted_answer_id": 64130124, "answer_count": 2, "score": 0, "last_activity_date": 1601453000, "creation_date": 1601426200, "last_edit_date": 1601432332, "question_id": 64129397, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/64129397/how-to-multiply-tensors-with-different-shapes-dimensions", "title": "How to multiply tensors with different shapes/dimensions?", "body": "<p>I have a convolutional autoencoder model. While an autoencoder typically focuses on reconstructing the input without using any label information, I want to use the class label to perform class conditional scaling/shifting after convolutions. I am curious if utilizing the label in this way might help produce better reconstructions.</p>\n<pre><code>num_filters = 32\ninput_img = layers.Input(shape=(28, 28, 1)) # input image\nlabel = layers.Input(shape=(10,)) # label\n\n# separate scale value for each of the filter dimensions\nscale = layers.Dense(num_filters, activation=None)(label) \n# conv_0 produces something of shape (None,14,14,32)\nconv_0 = layers.Conv2D(num_filters, (3, 3), strides=2, activation=None, padding='same')(input_img) \n\n# TODO: Need help here. Multiply conv_0 by scale along each of the filter dimensions. \n# This still outputs something of shape (None,14,14,32)\n# Essentially each 14x14x1 has it's own scalar multiplier \n</code></pre>\n<p>In the example above, the output of the convolutional layer is (14,14,32) and the scale layer is of shape (32,). I want the convolutional output to be multiplied by the corresponding scale value along each filter dimension. For example, if these were numpy arrays I could do something like <code>conv_0[:, :, i] * scale[i]</code> for i in range(32).</p>\n<p>I looked at <code>tf.keras.layers.Multiply</code> which can be found <a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/layers/Multiply\" rel=\"nofollow noreferrer\">here</a>, but based on the documentation I believe that takes in tensors of the same size as input. How do I work around this?</p>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 179}]
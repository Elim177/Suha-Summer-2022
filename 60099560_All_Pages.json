[{"items": [{"tags": ["python", "machine-learning", "tensorflow2.0", "gradienttape"], "owner": {"account_id": 17704292, "reputation": 21, "user_id": 12853286, "user_type": "registered", "profile_image": "https://lh5.googleusercontent.com/-Y-JJ2z6iTcc/AAAAAAAAAAI/AAAAAAAAAAA/ACHi3rcikTukmjCOZF42Wu-ixQOHTvlAFQ/photo.jpg?sz=256", "display_name": "Maximilian", "link": "https://stackoverflow.com/users/12853286/maximilian"}, "is_answered": false, "view_count": 533, "answer_count": 0, "score": 2, "last_activity_date": 1581006595, "creation_date": 1581006595, "question_id": 60099560, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/60099560/tensorflow-2-gradient-tape-not-working-as-expected", "title": "Tensorflow 2 gradient tape not working as expected", "body": "<p>I am currently training a large object detection model in <strong>Tensorflow 2</strong> with a custom training loop using <strong>gradient tape</strong>. The problem is that the model is not improving the loss as the gradients are very low. I reproduced the problem on a simple classification task using cifar10 and discovered, that a small model is training fine with no problem while a larger model (VGG16) is not improving the loss at all. Below is some code for reproducing the problem.</p>\n\n<p>VGG16 model:</p>\n\n<pre><code>import tensorflow as tf\nfrom tensorflow.keras.layers import Dense, Flatten, Conv2D, Dropout, MaxPooling2D, BatchNormalization, Input, Concatenate\nimport os\n\ndef create_vgg16(number_classes, include_fully=True, input_shape=(300, 300, 3), input_tensor=None):\n    if input_tensor is None:\n        img_input = Input(shape=input_shape)\n    else:\n        img_input = input_tensor\n    x = Conv2D(64, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal', name='conv1_1')(img_input)\n    x = Conv2D(64, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal', name='conv1_2')(x)\n    x = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same', name='pool1')(x)\n\n    x = Conv2D(128, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal', name='conv2_1')(x)\n    x = Conv2D(128, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal', name='conv2_2')(x)\n    x = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same', name='pool2')(x)\n\n    x = Conv2D(256, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal', name='conv3_1')(x)\n    x = Conv2D(256, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal', name='conv3_2')(x)\n    x = Conv2D(256, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal', name='conv3_3')(x)\n    x = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same', name='pool3')(x)\n\n    x = Conv2D(512, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal', name='conv4_1')(x)\n    x = Conv2D(512, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal', name='conv4_2')(x)\n    x = Conv2D(512, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal', name='conv4_3')(x)\n    x = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same', name='pool4')(x)\n\n    x = Conv2D(512, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal', name='conv5_1')(x)\n    x = Conv2D(512, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal', name='conv5_2')(x)\n    x = Conv2D(512, (3, 3), activation='relu', padding='same', kernel_initializer='he_normal', name='conv5_3')(x)\n    x = MaxPooling2D(pool_size=(3, 3), strides=(1, 1), padding='same', name='pool5')(x)\n\n    if include_fully:\n        x = Flatten(name='flatten')(x)\n        x = Dense(4096, activation='relu', name='fc1')(x)\n        x = Dense(4096, activation='relu', name='fc2')(x)\n        x = Dense(number_classes, activation='softmax', name='predictions')(x)\n\n    if input_tensor is not None:\n        inputs = tf.keras.utils.get_source_inputs(input_tensor)\n    else:\n        inputs = img_input\n    model = tf.keras.models.Model(inputs, x, name='vgg16')\n\n    return model\n</code></pre>\n\n<p>Small CNN model:</p>\n\n<pre><code>def create_small_cnn(n_classes, input_shape=(32, 32, 3)):\n    img_input = tf.keras.Input(shape=input_shape)\n    x = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same', name='conv1_1')(img_input)\n    x = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same', name='conv1_2')(x)\n    x = tf.keras.layers.Flatten(name='flatten')(x)\n    x = tf.keras.layers.Dense(16, activation='relu', name='fc1')(x)\n    x = tf.keras.layers.Dense(n_classes, activation='softmax', name='softmax')(x)\n\n    model = tf.keras.Model(img_input, x, name='small_cnn')\n    return model\n</code></pre>\n\n<p>Training loop:</p>\n\n<pre><code>def main():\n    number_classes = 10\n    # Load and one hot encode data\n    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n    x_train, x_test = x_train, x_test\n    y_train = tf.reshape(y_train, [-1])\n    y_train = tf.one_hot(y_train, number_classes).numpy()\n    y_test = tf.reshape(y_test, [-1])\n    y_test = tf.one_hot(y_test, number_classes).numpy()\n\n\n    # Define model\n    model = create_vgg16(number_classes, input_shape=(32, 32, 3))\n    # model = create_small_cnn(number_classes, input_shape=(32, 32, 3))\n\n    # Instantiate an optimizer to train the model.\n    optimizer = tf.keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n\n    # Instantiate a loss function.s\n    loss_fn = tf.keras.losses.CategoricalCrossentropy()\n\n    # Prepare the metrics.\n    train_acc_metric = tf.keras.metrics.CategoricalAccuracy()\n    val_acc_metric = tf.keras.metrics.CategoricalAccuracy()\n\n    # Prepare the training dataset.\n    batch_size = 64\n    train_dataset = tf.data.Dataset.from_tensor_slices(\n      (tf.cast(x_train/255, tf.float32),\n       tf.cast(y_train,tf.int64)))\n    train_dataset = train_dataset.shuffle(buffer_size=1024).batch(batch_size)\n\n    # Prepare the validation dataset.\n    val_dataset = tf.data.Dataset.from_tensor_slices(\n      (tf.cast(x_test/255, tf.float32),\n       tf.cast(y_test,tf.int64)))\n    val_dataset = val_dataset.shuffle(buffer_size=1024).batch(batch_size)\n\n    model.summary()\n\n    for epoch in range(100):\n      print('Start of epoch %d' % (epoch,))\n      for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n        with tf.GradientTape() as tape:\n          logits = model(x_batch_train)\n          loss_value = loss_fn(y_batch_train, logits)\n        grads = tape.gradient(loss_value, model.trainable_variables)\n        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n\n        train_acc_metric(y_batch_train[0], logits[0][:-1])\n\n        if step % 200 == 0:\n            print('Training loss (for one batch) at step %s: %s' % (step, float(loss_value)))\n\n\n      # Display metrics at the end of each epoch.\n      train_acc = train_acc_metric.result()\n      print('Training acc over epoch: %s' % (float(train_acc),))\n      # Reset training metrics at the end of each epoch\n      train_acc_metric.reset_states()\n\n      # Run a validation loop at the end of each epoch.\n      for x_batch_val, y_batch_val in val_dataset:\n        val_logits = model(x_batch_val)\n\n        val_acc_metric(y_batch_val[0], val_logits[0][:-1])\n      val_acc = val_acc_metric.result()\n      val_acc_metric.reset_states()\n      print('Validation acc: %s' % (float(val_acc),))\n\n\nif __name__ == '__main__':\n    main()\n</code></pre>\n\n<p>If you run the code shown you will see the network training fine while using the small CNN model. But on the other hand it does not work on the exact same dataset with the same preprocessing using a standard VGG16 model. To make matters more confusing, the VGG model will train perfectly fine when using <strong>model.fit</strong> instead of custom training loop with <strong>gradient tape</strong>. </p>\n\n<p>Does anybody have an idea why this is the case and how to fix this problem?</p>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 45}]
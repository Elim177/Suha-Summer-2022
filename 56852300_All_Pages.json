[{"items": [{"tags": ["deep-learning", "customization", "hyperparameters"], "owner": {"account_id": 15085414, "reputation": 147, "user_id": 11057642, "user_type": "registered", "profile_image": "https://www.gravatar.com/avatar/bcc1147639cc503c5323ed4503df7c2c?s=256&d=identicon&r=PG", "display_name": "Keren", "link": "https://stackoverflow.com/users/11057642/keren"}, "is_answered": true, "view_count": 3001, "answer_count": 2, "score": 3, "last_activity_date": 1589357052, "creation_date": 1562069880, "question_id": 56852300, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/56852300/hyperparameter-tuning-using-tensorboard-plugins-hparams-api-with-custom-loss-fun", "title": "Hyperparameter tuning using tensorboard.plugins.hparams api with custom loss function", "body": "<p>I am building a neural network with my own custom loss function (pretty long and complicated). My network is unsupervised so my input and expected output are identical and also at the moment I am using one single input (just trying to optimize the loss for a single input). </p>\n\n<p>I am trying to use tensorboard.plugins.hparams api for hyperparameter tuning and don't know how to incorporate my custom loss function there. I'm trying to follow the code suggested on the Tensorflow 2.0 <a href=\"https://www.tensorflow.org/tensorboard/r2/hyperparameter_tuning_with_hparams\" rel=\"nofollow noreferrer\">website</a>.</p>\n\n<p>This is what the website suggests:</p>\n\n<pre class=\"lang-py prettyprint-override\"><code>    HP_NUM_UNITS = hp.HParam('num_units', hp.Discrete([16, 32]))\n    HP_DROPOUT = hp.HParam('dropout', hp.RealInterval(0.1, 0.2))\n    HP_OPTIMIZER = hp.HParam('optimizer', hp.Discrete(['adam', 'sgd']))\n\n    METRIC_ACCURACY = 'accuracy'\n\n    with tf.summary.create_file_writer('logs/hparam_tuning').as_default():\n      hp.hparams_config(\n        hparams=[HP_NUM_UNITS, HP_DROPOUT, HP_OPTIMIZER],\n        metrics=[hp.Metric(METRIC_ACCURACY, display_name='Accuracy')],\n          )\n</code></pre>\n\n<p>I need to change that as I don't want to use the dropout layer, so I can just delete that. In terms of the METRIC_ACCURACY, I don't want to use accuracy as that has no use in my model but rather use my custom loss function. If I were to do the regular fit model it would look like this:</p>\n\n<pre class=\"lang-py prettyprint-override\"><code>    model.compile(optimizer=adam,loss=dl_tf_loss, metrics=[dl_tf_loss])\n</code></pre>\n\n<p>So I tried to change the suggested code into the following code but I get an error and am wondering how I should change it so that it suits my needs. Here is what I tried:</p>\n\n<pre class=\"lang-py prettyprint-override\"><code>    HP_NUM_UNITS = hp.HParam('num_units', hp.Discrete([16, 32]))\n    HP_OPTIMIZER = hp.HParam('optimizer', hp.Discrete(['adam', 'sgd']))\n\n    #METRIC_LOSS = dl_tf_loss\n\n    with tf.summary.create_file_writer('logs/hparam_tuning').as_default():\n      hp.hparams_config(hparams=[HP_NUM_UNITS, HP_OPTIMIZER],metrics= \n       [hp.Metric(dl_tf_loss, display_name='Loss')])\n</code></pre>\n\n<p>It gives me the following error:</p>\n\n<pre class=\"lang-py prettyprint-override\"><code>---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\n&lt;ipython-input-26-27d079c6be49&gt; in &lt;module&gt;()\n      5 \n      6 with tf.summary.create_file_writer('logs/hparam_tuning').as_default():\n----&gt; 7   hp.hparams_config(hparams=[HP_NUM_UNITS, HP_OPTIMIZER],metrics=[hp.Metric(dl_tf_loss, display_name='Loss')])\n      8 \n\n3 frames\n/usr/local/lib/python3.6/dist-packages/tensorboard/plugins/hparams/summary_v2.py in hparams_config(hparams, metrics, time_created_secs)\n    127       hparams=hparams,\n    128       metrics=metrics,\n--&gt; 129       time_created_secs=time_created_secs,\n    130   )\n    131   return _write_summary(\"hparams_config\", pb)\n\n/usr/local/lib/python3.6/dist-packages/tensorboard/plugins/hparams/summary_v2.py in hparams_config_pb(hparams, metrics, time_created_secs)\n    161       domain.update_hparam_info(info)\n    162     hparam_infos.append(info)\n--&gt; 163   metric_infos = [metric.as_proto() for metric in metrics]\n    164   experiment = api_pb2.Experiment(\n    165       hparam_infos=hparam_infos,\n\n/usr/local/lib/python3.6/dist-packages/tensorboard/plugins/hparams/summary_v2.py in &lt;listcomp&gt;(.0)\n    161       domain.update_hparam_info(info)\n    162     hparam_infos.append(info)\n--&gt; 163   metric_infos = [metric.as_proto() for metric in metrics]\n    164   experiment = api_pb2.Experiment(\n    165       hparam_infos=hparam_infos,\n\n/usr/local/lib/python3.6/dist-packages/tensorboard/plugins/hparams/summary_v2.py in as_proto(self)\n    532         name=api_pb2.MetricName(\n    533             group=self._group,\n--&gt; 534             tag=self._tag,\n    535         ),\n    536         display_name=self._display_name,\n\nTypeError: &lt;tensorflow.python.eager.def_function.Function object at 0x7f9f3a78e5c0&gt; has type Function, but expected one of: bytes, unicode\n</code></pre>\n\n<p>I also tried running the following code:</p>\n\n<pre class=\"lang-py prettyprint-override\"><code>    with tf.summary.create_file_writer('logs/hparam_tuning').as_default():\n      hp.hparams_config(hparams=[HP_NUM_UNITS, HP_OPTIMIZER],metrics= \n      [dl_tf_loss])\n</code></pre>\n\n<p>but got the following error:</p>\n\n<pre class=\"lang-py prettyprint-override\"><code>AttributeError                            Traceback (most recent call last)\n&lt;ipython-input-28-6778bdf7f1b1&gt; in &lt;module&gt;()\n      8 \n      9 with tf.summary.create_file_writer('logs/hparam_tuning').as_default():\n---&gt; 10   hp.hparams_config(hparams=[HP_NUM_UNITS, HP_OPTIMIZER],metrics=[dl_tf_loss])\n\n2 frames\n/usr/local/lib/python3.6/dist-packages/tensorboard/plugins/hparams/summary_v2.py in &lt;listcomp&gt;(.0)\n    161       domain.update_hparam_info(info)\n    162     hparam_infos.append(info)\n--&gt; 163   metric_infos = [metric.as_proto() for metric in metrics]\n    164   experiment = api_pb2.Experiment(\n    165       hparam_infos=hparam_infos,\n\nAttributeError: 'Function' object has no attribute 'as_proto'\n</code></pre>\n\n<p>Would greatly appreciate any help.\nThanks in advance!</p>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 266}]
[{"items": [{"tags": ["tensorflow", "tensorflow2.0", "loss-function"], "owner": {"account_id": 10967328, "reputation": 2032, "user_id": 8058705, "user_type": "registered", "profile_image": "https://www.gravatar.com/avatar/146fa54b2324332097a1b6cda3420328?s=256&d=identicon&r=PG&f=1", "display_name": "D.Griffiths", "link": "https://stackoverflow.com/users/8058705/d-griffiths"}, "is_answered": false, "view_count": 334, "answer_count": 1, "score": 1, "last_activity_date": 1574255582, "creation_date": 1574250585, "question_id": 58953700, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/58953700/replacing-gradient-calculation-of-loss-function-in-tensorflow-2-0", "title": "Replacing gradient calculation of loss function in tensorflow 2.0", "body": "<p>I would like to replace to gradient function for a loss function in <code>tensorflow 2.0</code>.</p>\n\n<p>Say for example I have a loss function which looks like:</p>\n\n<pre><code>def loss_function(prediction):\n    # do some standard tensorflow things here\n    return loss\n</code></pre>\n\n<p>I then apply the gradients using the <code>tf.GradientTape</code> method i.e.</p>\n\n<pre><code>with tf.GradientTape() as tape:\n\n     prediction = model(input)\n     loss = loss_function(prediction)\n\ngradients = tf.gradient(loss, model.trainable_variables)\noptimizer.apply_gradients(zip(gradients, model.trainable_variables))\n</code></pre>\n\n<p>My issue is that I want to change the gradient computation and explicitly calculate it myself for just the <code>loss_function()</code> that's currently automatically computed. </p>\n\n<p>I would guess this has something to do with the <code>@tf.custom_gradient</code> decorator, but unsure how I can make it work for the loss.</p>\n\n<p>I am using a custom training loop as apposed to sequential/functional api.</p>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 26}]
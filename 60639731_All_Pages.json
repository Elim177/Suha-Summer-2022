[{"items": [{"tags": ["python", "deep-learning", "tensorflow2.0", "tensorboard"], "owner": {"account_id": 14798558, "reputation": 144, "user_id": 10687511, "user_type": "registered", "profile_image": "https://graph.facebook.com/2270851286516090/picture?type=large", "display_name": "\u0396\u03b9 \u0392\u03ac\u03b3\u03b3\u03bf", "link": "https://stackoverflow.com/users/10687511/%ce%96%ce%b9-%ce%92%ce%ac%ce%b3%ce%b3%ce%bf"}, "is_answered": true, "view_count": 4471, "accepted_answer_id": 61173060, "answer_count": 1, "score": 7, "last_activity_date": 1586702012, "creation_date": 1583941408, "question_id": 60639731, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/60639731/tensorboard-for-custom-training-loop-in-tensorflow-2", "title": "Tensorboard for custom training loop in Tensorflow 2", "body": "<p>I want to create a custom training loop in tensorflow 2 and use tensorboard for visualization. Here is an example I've created based on tensorflow documentation:</p>\n\n<pre><code>import tensorflow as tf\nimport datetime\n\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"    # which gpu to use\n\nmnist = tf.keras.datasets.mnist\n\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\nx_train, x_test = x_train / 255.0, x_test / 255.0\n\ntrain_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\ntest_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n\ntrain_dataset = train_dataset.shuffle(60000).batch(64)\ntest_dataset = test_dataset.batch(64)\n\n\ndef create_model():\n    return tf.keras.models.Sequential([\n        tf.keras.layers.Flatten(input_shape=(28, 28), name='Flatten_1'),\n        tf.keras.layers.Dense(512, activation='relu', name='Dense_1'),\n        tf.keras.layers.Dropout(0.2, name='Dropout_1'),\n        tf.keras.layers.Dense(10, activation='softmax', name='Dense_2')\n    ], name='Network')\n\n\n# Loss and optimizer\nloss_object = tf.keras.losses.SparseCategoricalCrossentropy()\noptimizer = tf.keras.optimizers.Adam()\n\n# Define our metrics\ntrain_loss = tf.keras.metrics.Mean('train_loss', dtype=tf.float32)\ntrain_accuracy = tf.keras.metrics.SparseCategoricalAccuracy('train_accuracy')\ntest_loss = tf.keras.metrics.Mean('test_loss', dtype=tf.float32)\ntest_accuracy = tf.keras.metrics.SparseCategoricalAccuracy('test_accuracy')\n\n@tf.function\ndef train_step(model, optimizer, x_train, y_train):\n    with tf.GradientTape() as tape:\n        predictions = model(x_train, training=True)\n        loss = loss_object(y_train, predictions)\n    grads = tape.gradient(loss, model.trainable_variables)\n    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n\n    train_loss(loss)\n    train_accuracy(y_train, predictions)\n\n@tf.function\ndef test_step(model, x_test, y_test):\n    predictions = model(x_test)\n    loss = loss_object(y_test, predictions)\n\n    test_loss(loss)\n    test_accuracy(y_test, predictions)\n\n\ncurrent_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\ntrain_log_dir = '/NAS/Dataset/logs/gradient_tape/' + current_time + '/train'\ntest_log_dir = '/NAS/Dataset/logs/gradient_tape/' + current_time + '/test'\ntrain_summary_writer = tf.summary.create_file_writer(train_log_dir)\ntest_summary_writer = tf.summary.create_file_writer(test_log_dir)\n\nmodel = create_model()  # reset our model\n\nEPOCHS = 5\n\n\nfor epoch in range(EPOCHS):\n    for (x_train, y_train) in train_dataset:\n        train_step(model, optimizer, x_train, y_train)\n    with train_summary_writer.as_default():\n        tf.summary.scalar('loss', train_loss.result(), step=epoch)\n        tf.summary.scalar('accuracy', train_accuracy.result(), step=epoch)\n\n    for (x_test, y_test) in test_dataset:\n        test_step(model, x_test, y_test)\n    with test_summary_writer.as_default():\n        tf.summary.scalar('loss', test_loss.result(), step=epoch)\n        tf.summary.scalar('accuracy', test_accuracy.result(), step=epoch)\n\n    template = 'Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, Test Accuracy: {}'\n    print(template.format(epoch + 1,\n                          train_loss.result(),\n                          train_accuracy.result() * 100,\n                          test_loss.result(),\n                          test_accuracy.result() * 100))\n\n    # Reset metrics every epoch\n    train_loss.reset_states()\n    test_loss.reset_states()\n    train_accuracy.reset_states()\n    test_accuracy.reset_states()\n</code></pre>\n\n<p>I am accessing tensorboard with the following command on terminal:</p>\n\n<pre><code>tensorboard --logdir=.....\n</code></pre>\n\n<p>The code above produce summaries for losses and metrics. My question is:</p>\n\n<ul>\n<li><strong>How can i produce the graph of this process?</strong></li>\n</ul>\n\n<p>I've tried to use the recommended commands from tensorflow: <strong>tf.summary.trace_on()</strong> and <strong>tf.summary.trace_export()</strong>, but I haven't managed to plot the graph. Maybe I am using them wrong. I whould really appreciate any suggestion on how to do this.</p>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 2}]
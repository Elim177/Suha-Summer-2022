[{"items": [{"tags": ["tensorflow"], "owner": {"account_id": 2358376, "reputation": 3047, "user_id": 2065691, "user_type": "registered", "accept_rate": 85, "profile_image": "https://i.stack.imgur.com/z304s.png?s=256&g=1", "display_name": "DanielTheRocketMan", "link": "https://stackoverflow.com/users/2065691/danieltherocketman"}, "is_answered": true, "view_count": 5018, "accepted_answer_id": 35122970, "answer_count": 1, "score": 9, "last_activity_date": 1454312423, "creation_date": 1454244547, "last_edit_date": 1454257036, "question_id": 35114024, "content_license": "CC BY-SA 3.0", "link": "https://stackoverflow.com/questions/35114024/loss-functions-in-tensorflow-with-an-if-else", "title": "Loss functions in tensorflow (with an if - else)", "body": "<p>I am trying a different loss functions in tensorflow.</p>\n\n<p>The loss function I want is  a kind of an epsilon insensitive function (this is componentwise):</p>\n\n<pre><code>if(|yData-yModel|&lt;epsilon):\n    loss=0\nelse\n    loss=|yData-yModel|    \n</code></pre>\n\n<p>I tried this solution:</p>\n\n<pre><code>yData=tf.placeholder(\"float\",[None,numberOutputs]) \n\nyModel=model(...\n\nepsilon=0.2\nepsilonTensor=epsilon*tf.ones_like(yData)\nloss=tf.maximum(tf.abs(yData-yModel)-epsilonTensor,tf.zeros_like(yData))\noptimizer = tf.train.GradientDescentOptimizer(0.25)\ntrain = optimizer.minimize(loss)\n</code></pre>\n\n<p>I also used</p>\n\n<pre><code>optimizer = tf.train.MomentumOptimizer(0.001,0.9)\n</code></pre>\n\n<p>I do not find any error in the implementation. However, it does not converge, while the loss = tf.square(yData-yModel) converges and loss=tf.maximum(tf.square(yData-yModel)-epsilonTensor,tf.zeros_like(yData)) also converges.</p>\n\n<p>So, I also tried something simpler loss=tf.abs(yData-yModel) and it also does not converge. Am I making some mistake, or having problems with the non-differentiability of the abs at zero or something else? What is happenning with the abs function?</p>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 27}]
[{"items": [{"tags": ["tensorflow", "nan", "activation-function"], "owner": {"account_id": 10716056, "reputation": 2138, "user_id": 7886651, "user_type": "registered", "accept_rate": 76, "profile_image": "https://i.stack.imgur.com/zfb59.jpg?s=256&g=1", "display_name": "I. A", "link": "https://stackoverflow.com/users/7886651/i-a"}, "is_answered": false, "view_count": 463, "answer_count": 0, "score": 1, "last_activity_date": 1499694531, "creation_date": 1499694531, "question_id": 45013785, "content_license": "CC BY-SA 3.0", "link": "https://stackoverflow.com/questions/45013785/error-applying-selu-activation-function-with-tensorflow", "title": "Error Applying Selu Activation function with tensorflow", "body": "<p>I was trying to implement the new SELU activation function from <a href=\"https://arxiv.org/pdf/1706.02515\" rel=\"nofollow noreferrer\">https://arxiv.org/pdf/1706.02515</a>. For more information here is my code:</p>\n\n<pre><code>import tensorflow as tf\nimport numpy as np\nfrom PIL import Image\nimport os\nfrom keras.activations import elu\n\nbatch_size = 32\n\ndef weight_variable(kernal_shape):\n    weights = tf.get_variable(name='weights', shape=kernal_shape, dtype=tf.float32, trainable=True,\n                        initializer=tf.truncated_normal_initializer(stddev=0.02))\n    return weights\n\ndef bias_variable(shape):\n    initial = tf.constant(0.0, shape=shape)\n    return tf.Variable(initial)\n\ndef selu(x):\n    alpha = 1.6732632423543772848170429916717\n    scale = 1.0507009873554804934193349852946\n    #return scale * tf.where(x &gt;= 0.0, x, alpha * tf.exp(x) - alpha)\n    return scale * elu(x, alpha)\n\ndef conv_layer(x, w_shape, b_shape, padding='SAME'):\n    W = weight_variable(w_shape)\n    tf.summary.histogram(\"weights\", W)\n\n    b = bias_variable(b_shape)\n    tf.summary.histogram(\"biases\", b)\n\n    # Note that I used a stride of 2 on purpose in order not to use max pool layer.\n    activations = selu(tf.nn.conv2d(x, W, strides=[1, 2, 2, 1], padding=padding) + b)\n    tf.summary.histogram(activations.name, activations)\n\n    W1 = tf.shape(x)[1]\n    W2 = tf.shape(activations)[1]\n    F = w_shape[0]\n    P = tf.divide(tf.add(tf.subtract(tf.multiply(tf.subtract(W2, 1), 2), W1), F), 2)\n    return activations, P\n\ndef deconv_layer(x, w_shape, b_shape, padding=\"SAME\"):\n    W = weight_variable(w_shape)\n    tf.summary.histogram(\"weights\", W)\n\n    b = bias_variable(b_shape)\n    tf.summary.histogram('biases', b)\n\n    x_shape = tf.shape(x)\n\n    out_shape = tf.stack([x_shape[0], x_shape[1] * 2, x_shape[2] * 2, w_shape[2]])\n    # Note that I have used a stride of 2 since I used a stride of 2 in conv layer.\n    transposed_activations = tf.nn.conv2d_transpose(x, W, out_shape, [1, 2, 2, 1], padding=padding) + b\n    tf.summary.histogram(transposed_activations.name, transposed_activations)\n    return transposed_activations\n\ntfrecords_filename_seq = [\"P16_db.tfrecords\"]\nfilename_queue = tf.train.string_input_producer(tfrecords_filename_seq, num_epochs=None, shuffle=False, name='queue')\nreader = tf.TFRecordReader()\n\n_, serialized_example = reader.read(filename_queue)\nfeatures = tf.parse_single_example(\n    serialized_example,\n    # Defaults are not specified since both keys are required.\n    features={\n        'height': tf.FixedLenFeature([], tf.int64),\n        'width': tf.FixedLenFeature([], tf.int64),\n        'image_raw': tf.FixedLenFeature([], tf.string),\n        'annotation_raw': tf.FixedLenFeature([], tf.string)\n    })\n\n# This is how we create one example, that is, extract one example from the database.\nimage = tf.decode_raw(features['image_raw'], tf.uint8)\n# The height and the weights are used to\nheight = tf.cast(features['height'], tf.int32)\nwidth = tf.cast(features['width'], tf.int32)\n\n# The image is reshaped since when stored as a binary format, it is flattened. Therefore, we need the\n# height and the weight to restore the original image back.\nimage = tf.reshape(image, [height, width, 3])\nimage = tf.cast([image], tf.float32)\n\nwith tf.variable_scope('conv1'):\n    conv1, P1 = conv_layer(image, [3, 3, 3, 32], [32])      # image size: [56, 56]\nwith tf.variable_scope('conv2'):\n    conv2, P2 = conv_layer(conv1, [3, 3, 32, 64], [64])     # image size: [28, 28]\nwith tf.variable_scope('conv3'):\n    conv3, P3 = conv_layer(conv2, [3, 3, 64, 128], [128])   # image size: [14, 14]\nwith tf.variable_scope('conv4'):\n    conv4, P4 = conv_layer(conv3, [3, 3, 128, 256], [256])  # image size: [7, 7]\n    conv4_reshaped = tf.reshape(conv4, [-1, 7 * 7 * 256], name='conv4_reshaped')\n\nw_c = tf.Variable(tf.truncated_normal([7 * 7 * 256, 100], stddev=0.1), name='weight_fc')\nb_c = tf.Variable(tf.constant(0.1, shape=[100]), name='biases_fc')\ntf.summary.histogram('weights_c', w_c)\ntf.summary.histogram('biases_c', b_c)\n\nwith tf.variable_scope('z'):\n    z = selu(tf.nn.bias_add(tf.matmul(conv4_reshaped, w_c), b_c))\n    tf.summary.histogram('features_z', z)\n\nw_dc = tf.Variable(tf.truncated_normal([100, 7 * 7 * 256], stddev=0.1), name='weights_dc')\nb_dc = tf.Variable(tf.constant(0.1, shape=[7 * 7 * 256]), name='biases_dc')\ntf.summary.histogram('weights_dc', w_dc)\ntf.summary.histogram('biases_dc', b_dc)\n\nwith tf.variable_scope('deconv4'):\n    deconv4 = selu(tf.nn.bias_add(tf.matmul(z, w_dc), b_dc))\n    deconv4_reshaped = tf.reshape(deconv4, [-1, 7, 7, 256], name='deconv4_reshaped')\n\nwith tf.variable_scope('deconv3'):\n    deconv3 = deconv_layer(deconv4_reshaped, [3, 3, 128, 256], [128])\nwith tf.variable_scope('deconv2'):\n    deconv2 = deconv_layer(deconv3, [3, 3, 64, 128], [64])\nwith tf.variable_scope('deconv1'):\n    deconv1 = deconv_layer(deconv2, [3, 3, 32, 64], [32])\nwith tf.variable_scope('deconv_image'):\n    deconv_image = deconv_layer(deconv1, [3, 3, 3, 32], [3])\n\nwith tf.name_scope('loss'):\n    loss = tf.reduce_mean(tf.abs(deconv_image - image))\n    tf.summary.scalar('loss', loss)\nwith tf.name_scope('optimizer'):\n    optimizer = tf.train.AdamOptimizer(0.0001).minimize(loss)\n\ninit_op = tf.group(tf.local_variables_initializer(),\n                       tf.global_variables_initializer())\n\nsaver = tf.train.Saver()\nmodel_path = 'C:/Users/iayou005/Documents/tensorboard_logs/Graph_model/ckpt'\n\n# Here is the session...\nwith tf.Session() as sess:\n\n    train_writer = tf.summary.FileWriter('C:/Users/iayou005/Documents/tensorboard_logs/New_Runs/DeconvNet', sess.graph)\n    merged = tf.summary.merge_all()\n\n    coord = tf.train.Coordinator()\n    threads = tf.train.start_queue_runners(coord=coord)\n    step = 0\n\n    sess.run(init_op)\n\n    # Note that the last name \"Graph_model\" is the name of the saved checkpoints file =&gt; the ckpt is saved\n    # under tensorboard_logs.\n    ckpt = tf.train.get_checkpoint_state(\n        os.path.dirname('C:/Users/iayou005/Documents/tensorboard_logs/Graph_model/ckpt'))\n    if ckpt and ckpt.model_checkpoint_path:\n        saver.restore(sess, ckpt.model_checkpoint_path)\n        print('checkpoints are saved!!!')\n    else:\n        print('No stored checkpoints')\n\n    while step &lt; 100000:\n\n        if step % 1000 == 0:\n            img = sess.run([deconv_image])\n            img2 = Image.fromarray(np.uint8(img[0][0]))\n            img2.save('Reconstructed' + str(step) + '.png', 'png')\n\n        __, loss_s, summary = sess.run([optimizer, loss, merged])\n        if step % 100 == 0:\n            train_writer.add_summary(summary, step)\n            print(loss_s)\n        step += 1\n\n    save_path = saver.save(sess, model_path)\n    coord.request_stop()\n    coord.join(threads)\n    train_writer.close()\n</code></pre>\n\n<p>So without using Keras I kept getting a NAN:</p>\n\n<pre><code>InvalidArgumentError (see above for traceback): Nan in summary histogram for: conv1/weights_1\n     [[Node: conv1/weights_1 = HistogramSummary[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](conv1/weights_1/tag, conv1/weights/read/_61)]]\n</code></pre>\n\n<p>I would like to know the reason for getting a NAN.</p>\n\n<p>Any help is much appreciated!! </p>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 69}]
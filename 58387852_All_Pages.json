[{"items": [{"tags": ["python", "tensorflow", "tensorflow2.0"], "owner": {"account_id": 11679473, "reputation": 387, "user_id": 8551737, "user_type": "registered", "profile_image": "https://www.gravatar.com/avatar/1149a190044d92b2b32a9405c79bb65e?s=256&d=identicon&r=PG&f=1", "display_name": "YeongHwa Jin", "link": "https://stackoverflow.com/users/8551737/yeonghwa-jin"}, "is_answered": true, "view_count": 2347, "accepted_answer_id": 58390952, "answer_count": 2, "score": 1, "last_activity_date": 1630584069, "creation_date": 1571117863, "last_edit_date": 1571118970, "question_id": 58387852, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/58387852/what-does-please-wrap-your-loss-computation-in-a-zero-argument-lambda-means", "title": "What does &quot;Please wrap your loss computation in a zero argument `lambda`.&quot; means?", "body": "<p>I made a code for adding L2 loss to the main loss function:</p>\n\n<pre><code>def add_l2(model, penalty=0.001):\n    for layer in model.layers:\n        if \"conv\" in layer.name:\n            model.add_loss(penalty * tf.reduce_sum(tf.square(layer.trainable_variables[0])))\n    return\n\n## training\n@tf.function\ndef train_one_step(model, x, y, optimizer):\n    with tf.GradientTape() as tape:\n        logits = model(x, training=True)\n        loss = _criterion(y_true=y, y_pred=logits)\n\n        add_l2(model, 0.001)\n        loss += sum(model.losses)\n\n    grads = tape.gradient(loss, model.trainable_variables)\n    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n    return loss, logits\n\n</code></pre>\n\n<p>And when I started to train, I had a error like below:</p>\n\n<blockquote>\n  <p><strong>ValueError</strong>: Expected a symbolic Tensors or a callable for the loss value. Please wrap your loss computation in a zero argument <code>lambda</code>.</p>\n</blockquote>\n\n<p>What does it mean of this error? And How can I treat it?</p>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 16}]
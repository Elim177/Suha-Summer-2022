[{"items": [{"tags": ["python", "tensorflow", "keras"], "owner": {"account_id": 14366315, "reputation": 3, "user_id": 10468376, "user_type": "registered", "profile_image": "https://lh4.googleusercontent.com/-BHYE2MF5kUw/AAAAAAAAAAI/AAAAAAAAUW8/D1JZS7J_qWs/photo.jpg?sz=256", "display_name": "Acu", "link": "https://stackoverflow.com/users/10468376/acu"}, "is_answered": false, "view_count": 285, "answer_count": 1, "score": 0, "last_activity_date": 1647600828, "creation_date": 1624558918, "question_id": 68120930, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/68120930/attributeerror-tuple-object-has-no-attribute-items-keras-model-fit-err", "title": "AttributeError: &#39;tuple&#39; object has no attribute &#39;items&#39; - Keras, model.fit() error", "body": "<p>I'm trying to make a variational autoencoder with Keras using a custom model.</p>\n<p>Note that if I don't have a validation dataset it doesn't error! I believe this error is due to the validation loss logs but I can't manage to work it out.</p>\n<p>This is my model:</p>\n<pre><code>class VAE(keras.Model):\n    def __init__(self, encoder, decoder, **kwargs):\n        super(VAE, self).__init__(**kwargs)\n        self.encoder = encoder\n        self.decoder = decoder\n        # Train\n        self.total_train_loss_tracker = keras.metrics.Mean(name=&quot;total_train_loss&quot;)\n        self.recon_train_loss_tracker = keras.metrics.Mean(name=&quot;recon_train_loss&quot;)\n        self.kl_train_loss_tracker = keras.metrics.Mean(name=&quot;kl_train_loss&quot;)\n        # Val\n        self.total_val_loss_tracker = keras.metrics.Mean(name=&quot;total_val_loss&quot;)\n        self.recon_val_loss_tracker = keras.metrics.Mean(name=&quot;recon_val_loss&quot;)\n        self.kl_val_loss_tracker = keras.metrics.Mean(name=&quot;kl_val_loss&quot;)\n\n    @property\n    def metrics(self):\n        return [\n            self.total_train_loss_tracker,\n            self.recon_train_loss_tracker,\n            self.kl_train_loss_tracker,\n            self.total_val_loss_tracker,\n            self.recon_val_loss_tracker,\n            self.kl_val_loss_tracker\n        ]\n        \n    def train_step(self, data):\n        with tf.GradientTape() as tape:\n            x, y, weights = data\n\n            z_mean, z_log_var, z = self.encoder(x)\n            reconstruction = self.decoder(z)\n\n            ## Loss\n            # reconstruction\n            recon_loss = binary_crossentropy(x, reconstruction) # Shape = BATCH_SIZE\n            # Weights on recon loss\n            recon_train_loss = (weights * recon_loss) / K.sum(weights)\n            recon_loss = K.mean(recon_loss, axis = 0)\n\n            # KL\n            kl_loss = -0.5 * (1 + z_log_var - K.square(z_mean) - K.exp(z_log_var))\n            kl_loss = K.mean(K.sum(kl_loss, axis=1), axis=0)\n            # Weights on KL Loss\n            kl_loss = (weights * kl_loss) / K.sum(weights)\n            kl_loss = K.mean(kl_loss, axis = 0)\n\n            # Total\n            total_loss = recon_loss + kl_loss\n\n        # Step\n        grads = tape.gradient(total_loss, self.trainable_weights)\n        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n        \n        # Log\n        self.total_train_loss_tracker.update_state(total_loss)\n        self.recon_train_loss_tracker.update_state(recon_loss)\n        self.kl_train_loss_tracker.update_state(kl_loss)\n\n        return {\n            &quot;total_train_loss&quot;: self.total_train_loss_tracker.result(),\n            &quot;recon_train_loss&quot;: self.recon_train_loss_tracker.result(),\n            &quot;kl_train_loss&quot;: self.kl_train_loss_tracker.result(),\n        }\n\n    def validation_step(self, data):\n        # No tape, we don't need gradients\n        x, y = data\n\n        print(&quot;1&quot;, type(x), type(y))\n\n        z_mean, z_log_var, z = self.encoder(x)\n        reconstruction = self.decoder(z)\n\n        ## Loss\n        # reconstruction\n        recon_loss = binary_crossentropy(x, reconstruction) # Shape = BATCH_SIZE\n\n        # KL\n        kl_loss = -0.5 * (1 + z_log_var - K.square(z_mean) - K.exp(z_log_var))\n        kl_loss = K.mean(K.sum(kl_loss, axis=1), axis=0)\n\n        # Total\n        total_loss = recon_loss + kl_loss\n\n\n        loss = recon_loss*self.alpha + kl_loss\n\n        # Log\n        self.total_val_loss_tracker.update_state(total_loss)\n        self.recon_val_loss_tracker.update_state(recon_loss)\n        self.kl_val_loss_tracker.update_state(kl_loss)\n\n        return {\n            &quot;total_val_loss&quot;: self.total_val_loss_tracker.result(),\n            &quot;recon_val_loss&quot;: self.recon_val_loss_tracker.result(),\n            &quot;kl_val_loss&quot;: self.kl_val_loss_tracker.result(),\n        }\n\n    def test_step(self, data):\n        # No tape, we don't need gradients\n        x, y = data\n\n        z_mean, z_log_var, z = self.encoder(x)\n        reconstruction = self.decoder(z)\n        return reconstruction, z_mean, z_log_var, z # z is the latent vector\n\n# Compile\nvae = VAE(encoder, decoder)\nvae.compile(optimizer=keras.optimizers.Adam())\n</code></pre>\n<p>And when I fit the model with:</p>\n<pre><code>## Callbacks\n# Model name\nname = str(datetime.now().strftime(&quot;%d_%m_%Y__%H_%M_%S&quot;))\n\n# Tensorboard\nTB = keras.callbacks.TensorBoard(log_dir=join(&quot;logs&quot;, name), write_images=True)\n\n# Early Stopping\nES = keras.callbacks.EarlyStopping(monitor=&quot;total_val_loss&quot;, patience=30, verbose=2, mode=&quot;min&quot;)\n\n# Model Checkpoint\nMC = keras.callbacks.ModelCheckpoint(filepath=join(&quot;models_tf&quot;, name), save_best_only=True, monitor=&quot;total_val_loss&quot;, mode=&quot;min&quot;)\n\n# Fit\nhistory = vae.fit(\n    # Train\n    x=x_train, \n    y=x_train,\n    sample_weight=x_train_weights,\n\n    # Validation\n    validation_data=(x_val,x_val),\n\n    # Hyper-parameters    \n    epochs=30, \n    batch_size=4048,\n    callbacks=[TB, ES, MC])\n</code></pre>\n<p>It outputs:</p>\n<pre><code>Epoch 1/30\n90/92 [============================&gt;.] - ETA: 0s - total_train_loss: -1.3369 - recon_train_loss: -1.3404 - kl_train_loss: 0.0035\n---------------------------------------------------------------------------\nAttributeError                            Traceback (most recent call last)\n&lt;ipython-input-17-b3ea8a6b1b64&gt; in &lt;module&gt;\n      1 # Fit\n----&gt; 2 history = vae.fit(\n      3     # Train\n      4     x=x_train,\n      5     y=x_train,\n\n~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\n   1212                 model=self,\n   1213                 steps_per_execution=self._steps_per_execution)\n-&gt; 1214           val_logs = self.evaluate(\n   1215               x=val_x,\n   1216               y=val_y,\n\n~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py in evaluate(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\n   1494               callbacks.on_test_batch_end(end_step, logs)\n   1495       logs = tf_utils.sync_to_numpy_or_python_type(logs)\n-&gt; 1496       callbacks.on_test_end(logs=logs)\n   1497 \n   1498       if return_dict:\n\n~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py in on_test_end(self, logs)\n    543     logs = self._process_logs(logs)\n    544     for callback in self.callbacks:\n--&gt; 545       callback.on_test_end(logs)\n    546 \n    547   def on_predict_begin(self, logs=None):\n\n~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py in on_test_end(self, logs)\n   2391     if self.model.optimizer and hasattr(self.model.optimizer, 'iterations'):\n   2392       with summary_ops_v2.record_if(True), self._val_writer.as_default():\n-&gt; 2393         for name, value in logs.items():\n   2394           summary_ops_v2.scalar(\n   2395               'evaluation_' + name + '_vs_iterations',\n\nAttributeError: 'tuple' object has no attribute 'items'\n</code></pre>\n<p>I'm currently using Keras and tensorflow 2.5.0</p>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 118}]
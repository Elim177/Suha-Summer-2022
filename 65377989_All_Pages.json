[{"items": [{"tags": ["python", "tensorflow", "keras", "conv-neural-network"], "owner": {"account_id": 26373, "reputation": 43816, "user_id": 68571, "user_type": "registered", "accept_rate": 79, "profile_image": "https://i.stack.imgur.com/Yw9Lg.png?s=256&g=1", "display_name": "VansFannel", "link": "https://stackoverflow.com/users/68571/vansfannel"}, "is_answered": false, "view_count": 158, "answer_count": 1, "score": 0, "last_activity_date": 1608560920, "creation_date": 1608451104, "last_edit_date": 1608560920, "question_id": 65377989, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/65377989/how-can-i-compare-trainable-weights-from-a-model-to-know-if-it-is-learning-anyth", "title": "How can I compare trainable_weights from a model to know if it is learning anything?", "body": "<p>I'm using Tensorflow 2.x and Python 3.7.</p>\n<p>My model doesn't improve its loss and accuracy and I'm trying to guess what it is happening.</p>\n<p>I have found this article &quot;<a href=\"https://medium.com/@keeper6928/how-to-unit-test-machine-learning-code-57cf6fd81765\" rel=\"nofollow noreferrer\">How to unit test machine learning code</a>&quot; with the following code:</p>\n<pre><code>def test_convnet():\n  image = tf.placeholder(tf.float32, (None, 100, 100, 3)\n  model = Model(image)\n  sess = tf.Session()\n  sess.run(tf.global_variables_initializer())\n  before = sess.run(tf.trainable_variables())\n  _ = sess.run(model.train, feed_dict={\n               image: np.ones((1, 100, 100, 3)),\n               })\n  after = sess.run(tf.trainable_variables())\n  for b, a, n in zip(before, after):\n      # Make sure something changed.\n      assert (b != a).any()\n</code></pre>\n<p>This is my CNN:</p>\n<pre><code>import os\nimport glob\n\nfrom PIL import Image\n\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten\nfrom typing import Tuple\n\n# Create the function that get the embeddings. In this case, it is a CNN.\ndef get_embedding_function(img_shape):\n    inputs = Input(img_shape)\n\n    conv1 = Conv2D(64, (3, 3), activation='relu', padding='same', name='conv1_1')(inputs)\n    #conv1 = Conv2D(64, (3, 3), activation='relu', padding='same', name='conv1_2')(conv1)\n    pool1 = MaxPooling2D(pool_size=(2, 2), data_format='channels_last', name='pool1')(conv1)\n\n    conv2 = Conv2D(96, (3, 3), activation='relu', padding='same', name='conv2_1')(pool1)\n    #conv2 = Conv2D(96, (3, 3), activation='relu', padding='same', name='conv2_2')(conv2)\n    pool2 = MaxPooling2D(pool_size=(2, 2), data_format='channels_last', name='pool2')(conv2)\n\n    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same', name='conv3_1')(pool2)\n    #conv3 = Conv2D(128, (3, 3), activation='relu', padding='same', name='conv3_2')(conv3)\n    pool3 = MaxPooling2D(pool_size=(2, 2), data_format='channels_last', name='pool3')(conv3)\n\n    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same', name='conv4_1')(pool3)\n    #conv4 = Conv2D(256, (3, 3), activation='relu', padding='same', name='conv4_2')(conv4)\n    pool4 = MaxPooling2D(pool_size=(2, 2), data_format='channels_last', name='pool4')(conv4)\n\n    outputs = Flatten(data_format='channels_last')(pool4)\n    print(&quot;Pool 4 shape: &quot;, pool4.shape)\n    print(&quot;Outputs shape: &quot;, outputs.shape)\n\n    model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n\n    return model\n</code></pre>\n<p>And here is the training loop:</p>\n<pre><code># Load images from disk.\ntrain_dataset = load_images(main_dir, train_classes, (no_of_classes, num_examples, img_height, img_width))\n\n# Input image shape for embeddings function.\ninput_img_shape = (img_height, img_width, channels)\n# Get the embeddings function\nemb_function = get_embedding_function(input_img_shape)\n# Get the optimizer as Stochastic Gradient Descend.\nopt = tf.keras.optimizers.SGD(learning_rate=0.1, momentum=0.9)\n\nbefore = emb_function.trainable_variables\n\nfor epoch in range(num_epochs):\n    # 2.1. Since we perform episodic training.\n    for episode in range(num_episodes):\n        # Select 60 classes RANDOMLY\n        episodic_classes = np.random.permutation(no_of_classes)[:num_way]\n\n        support = np.zeros([num_way, num_shot, img_height, img_width], dtype=np.float32)\n        query = np.zeros([num_way, num_query, img_height, img_width], dtype=np.float32)\n\n        # 2.2. Randomly sample n number of data points per each class from our dataset, D, and prepare our\n        # support set, S.\n        for index, class_ in enumerate(episodic_classes):\n            selected = np.random.permutation(num_examples)[:num_shot + num_query]\n            support[index] = train_dataset[class_, selected[:num_shot]]\n\n            # 3. Similarly, we select n number of data points and prepare our query set, Q. (5 query points per class).\n            query[index] = train_dataset[class_, selected[num_shot:]]\n\n        # Add a new dimension at the end of the arrays to store the channels.\n        support_set = np.expand_dims(support, axis=-1)\n        query_set = np.expand_dims(query, axis=-1)\n\n        # Create an array of arrays [[0, ..., 0], [1, ..., 1], ..., [num_way, ..., num_way]]\n        # Each [0, ..., 0], [1, ..., 1], etc. has num_query elements.\n        labels = np.tile(np.arange(num_way)[:, np.newaxis], (1, num_query)).astype(np.uint8)\n\n        with tf.GradientTape() as tape:\n            # 4. We learn the embeddings of the data points in our support set using our embedding function.\n            support_set_embeddings = \\\n                emb_function(tf.reshape(support_set, (num_way * num_shot, img_height, img_width, channels)))\n\n            # Convert the label to one hot.\n            # Convert labels, [[0, ..., 0], [1, ..., 1], ...], into [[1.0, 0., ..., 0.], [0., 1.0, ...], ...]\n            y_one_hot = tf.one_hot(labels, depth=num_way)\n\n            # 5. Once we have the embeddings for each data point, we compute the prototype of each class by taking the\n            # mean.\n            # embeddings of the data points under each class.\n            class_prototype = tf.reduce_mean(tf.reshape(support_set_embeddings,\n                                                        (num_way, num_shot, support_set_embeddings.shape[-1])), axis=1)\n\n            # 6. Similarly, we learn the query set embeddings.\n            query_set_embeddings = \\\n                emb_function(np.reshape(query_set, (num_way * num_query, img_height, img_width, channels)))\n\n            # 7. We calculate the Euclidean distance, d, between query set embeddings and the class prototype.\n            distance = euclidean_distance(class_prototype, query_set_embeddings)\n\n            # 8. We predict the probability of the class of a query set by applying softmax over the distance d.\n            predicted_probability = tf.reshape(tf.nn.softmax(-distance), (num_way, num_query, -1))\n\n            # 9. We compute the loss as a negative log probability.\n            loss = -tf.math.log(\n                tf.reduce_mean(tf.reshape(tf.reduce_sum(tf.multiply(y_one_hot, predicted_probability), axis=-1), [-1])))\n\n            accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(predicted_probability, axis=-1), labels), tf.float32))\n\n            grad = tape.gradient([loss], emb_function.trainable_weights)\n            opt.apply_gradients(zip(grad, emb_function.trainable_weights))\n\n            after = emb_function.trainable_variables\n\n            for b, a in zip(before, after):\n                assert (b != a).any()\n\n            if (episode + 1) % 10 == 0:\n                print('Epoch {} : Episode {} : Loss: {}, Accuracy: {}'.format(epoch + 1, episode + 1, loss, accuracy))\n</code></pre>\n<p>To make you easier to find how I have migrated the article's code <code>test_convnet()</code>, I put it here:</p>\n<pre><code>before = emb_function.trainable_weights\n\n            # Code omitted for brevity...\n            grad = tape.gradient([loss], emb_function.trainable_weights)\n            opt.apply_gradients(zip(grad, emb_function.trainable_weights))\n\n            after = emb_function.trainable_weights\n\n            for b, a in zip(before, after):\n                assert (b != a).any()\n</code></pre>\n<p>My problem is with the code <code>assert (b != a).any()</code>, I get this error:</p>\n<pre><code>AttributeError: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'any'\n</code></pre>\n<p>I have also tried <code>assert (b.any() != a.any())</code> with the error:</p>\n<pre><code>AttributeError: 'ResourceVariable' object has no attribute 'any'\n</code></pre>\n<p><code>before</code> and <code>after</code> are <code>List</code>s, so I've been searching for how to compare it, but there are a lot of problems if the lists aren't ordered.</p>\n<p>How can I know if the model has been trained?</p>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 248}]
[{"items": [{"tags": ["python", "tensorflow", "deep-learning", "neural-network", "glove"], "owner": {"account_id": 13492482, "reputation": 437, "user_id": 9734248, "user_type": "registered", "profile_image": "https://www.gravatar.com/avatar/c8fd8584be5278402a0034f62976afbe?s=256&d=identicon&r=PG&f=1", "display_name": "DY92", "link": "https://stackoverflow.com/users/9734248/dy92"}, "is_answered": true, "view_count": 241, "accepted_answer_id": 61312496, "answer_count": 1, "score": 0, "last_activity_date": 1587335387, "creation_date": 1587329622, "question_id": 61311505, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/61311505/tf-matmulx-weight-vs-tf-matmulx-tf-trasposeweight-in-tensorflow", "title": "tf.matmul(X,weight) vs tf.matmul(X,tf.traspose(weight)) in tensorflow", "body": "<p>In standard ANN for fully connected layers we are using the following formula: <code>tf.matmul(X,weight) + bias</code>. Which is clear to me, as we use matrix multiplication in order to connect input with th hidden layer.</p>\n\n<p>But in GloVe implementation(<a href=\"https://nlp.stanford.edu/projects/glove/\" rel=\"nofollow noreferrer\">https://nlp.stanford.edu/projects/glove/</a>) we are using the following formula for embeddings multiplication: <code>tf.matmul(W, tf.transpose(U))</code> what confuses me is <code>tf.transpose(U)</code>part.\nWhy do we use <code>tf.matmul(W, tf.transpose(U))</code> instead of <code>tf.matmul(W, U)</code>?</p>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 3}]
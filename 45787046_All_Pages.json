[{"items": [{"tags": ["machine-learning", "tensorflow", "python-3.6", "knn"], "owner": {"account_id": 8122961, "reputation": 1012, "user_id": 6118987, "user_type": "registered", "accept_rate": 91, "profile_image": "https://i.stack.imgur.com/MZvTG.jpg?s=256&g=1", "display_name": "Masoud Masoumi Moghadam", "link": "https://stackoverflow.com/users/6118987/masoud-masoumi-moghadam"}, "is_answered": true, "view_count": 1026, "accepted_answer_id": 45790083, "answer_count": 1, "score": 0, "last_activity_date": 1503411267, "creation_date": 1503265328, "question_id": 45787046, "content_license": "CC BY-SA 3.0", "link": "https://stackoverflow.com/questions/45787046/tensorflow-knn-how-can-we-assign-the-k-parameter-for-defining-number-of-neighb", "title": "Tensorflow KNN : How can we assign the K parameter for defining number of neighbors in KNN?", "body": "<p>I have started working on a machine learning project using K-Nearest-Neighbors method on python tensorflow library. I have no experience working with tensorflow tools, so I found some code in github and modified it for my data.<br/><br/></p>\n\n<p>My dataset is like this:</p>\n\n<pre><code>2,2,2,2,0,0,3\n2,2,2,2,0,1,0\n2,2,2,4,2,2,1\n...\n2,2,2,4,2,0,0\n</code></pre>\n\n<p>And this is the code which actually works fine:</p>\n\n<pre><code>import tensorflow as tf\nimport numpy as np\n\n# Whole dataset =&gt; 1428 samples\ndataset = 'car-eval-data-1.csv'\n# samples for train, remaining for test\nsamples = 1300\nreader = np.loadtxt(open(dataset, \"rb\"), delimiter=\",\", skiprows=1, dtype=np.int32)\n\ntrain_x, train_y = reader[:samples,:5], reader[:samples,6]\ntest_x, test_y = reader[samples:, :5], reader[samples:, 6]\n\n# Placeholder you can assign values in future. its kind of a variable\n#  v = (\"variable type\",[None,4])  -- you can have multidimensional values here\ntraining_values = tf.placeholder(\"float\",[None,len(train_x[0])])\ntest_values     = tf.placeholder(\"float\",[len(train_x[0])])\n\n# MANHATTAN distance\ndistance = tf.abs(tf.reduce_sum(tf.square(tf.subtract(training_values,test_values)),reduction_indices=1))\n\nprediction = tf.arg_min(distance, 0)\ninit = tf.global_variables_initializer()\n\naccuracy = 0.0\n\nwith tf.Session() as sess:\n    sess.run(init)\n    # Looping through the test set to compare against the training set\n    for i in range (len(test_x)):\n        # Tensor flow method to get the prediction near to the test parameters in the training set.\n        index_in_trainingset = sess.run(prediction, feed_dict={training_values:train_x,test_values:test_x[i]})    \n\n        print(\"Test %d, and the prediction is %s, the real value is %s\"%(i,train_y[index_in_trainingset],test_y[i]))\n        if train_y[index_in_trainingset] == test_y[i]:\n        # if prediction is right so accuracy increases.\n            accuracy += 1. / len(test_x)\n\nprint('Accuracy -&gt; ', accuracy * 100, ' %')\n</code></pre>\n\n<p>The only thing I do not understand is that if it's the <strong>KNN</strong> method so there has to be some <strong>K parameter</strong> which defines the <strong>number of neighbors for predicting the label for each test sample</strong>.<br/>\nHow can we assign the K parameter to tune the number of nearest neighbors for  the code?<br/>\nIs there any way to modify this code to make use of K parameter?</p>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 97}]
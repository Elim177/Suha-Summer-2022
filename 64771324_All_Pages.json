[{"items": [{"tags": ["python", "numpy", "tensorflow"], "owner": {"account_id": 13716727, "reputation": 143, "user_id": 9897685, "user_type": "registered", "profile_image": "https://www.gravatar.com/avatar/041c8ac5f82ce66ee56110280e33bf9c?s=256&d=identicon&r=PG&f=1", "display_name": "DavidH", "link": "https://stackoverflow.com/users/9897685/davidh"}, "is_answered": true, "view_count": 289, "accepted_answer_id": 64771894, "answer_count": 1, "score": 2, "last_activity_date": 1605022364, "creation_date": 1605020259, "question_id": 64771324, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/64771324/why-does-tensorflows-automatic-differentiation-fail-when-numpy-is-used-in-th", "title": "Why does Tensorflow&#39;s automatic differentiation fail when .numpy() is used in the loss function?", "body": "<p>I've noticed that Tensorflow's automatic differentiation does not give the same values as finite differences when the loss function converts the input to a numpy array to calculate the output value. Here's a minimum working example of the problem:</p>\n<pre><code>import tensorflow as tf\nimport numpy as np\n\ndef lossFn(inputTensor):\n    # Input is a rank-2 square tensor\n    return tf.linalg.trace(inputTensor @ inputTensor)\n\ndef lossFnWithNumpy(inputTensor):\n    # Same function, but converts input to a numpy array before performing the norm\n    inputArray = inputTensor.numpy()\n\n    return tf.linalg.trace(inputArray @ inputArray)\n\nN = 2\ntf.random.set_seed(0)\nrandomTensor = tf.random.uniform([N, N])\n\n# Prove that the two functions give the same output; evaluates to exactly zero\nprint(lossFn(randomTensor) - lossFnWithNumpy(randomTensor)) \n\ntheoretical, numerical = tf.test.compute_gradient(lossFn, [randomTensor])\n# These two values match\nprint(theoretical[0])\nprint(numerical[0])\n\ntheoretical, numerical = tf.test.compute_gradient(lossFnWithNumpy, [randomTensor])\n# The theoretical value is [0 0 0 0]\nprint(theoretical[0])\nprint(numerical[0])\n\n</code></pre>\n<p>The function <code>tf.test.compute_gradients</code> computes the 'theoretical' gradient using automatic differentiation, and the numerical gradient using finite differences. As the code shows, if I use <code>.numpy()</code> in the loss function the automatic differentiation does not calculate the gradient.</p>\n<p>Could anybody explain the reason for this?</p>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 148}]
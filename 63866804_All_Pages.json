[{"items": [{"tags": ["tensorflow", "stylegan"], "owner": {"account_id": 18686486, "reputation": 79, "user_id": 13621877, "user_type": "registered", "profile_image": "https://lh5.googleusercontent.com/-XwQKKLqZ9WY/AAAAAAAAAAI/AAAAAAAAAAA/AMZuucnViQi1bSMYBwYtz3bL7hmce1UG6w/photo.jpg?sz=256", "display_name": "Will Mulcahey", "link": "https://stackoverflow.com/users/13621877/will-mulcahey"}, "is_answered": true, "view_count": 107, "accepted_answer_id": 63868591, "answer_count": 1, "score": 0, "last_activity_date": 1599984855, "creation_date": 1599966734, "last_edit_date": 1599976015, "question_id": 63866804, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/63866804/dimensions-must-equal-error-but-they-are-equal", "title": "dimensions must equal error but they are equal", "body": "<p>I added a print to the &quot;discriminator_loss&quot; function to see what was going on. at first it will tell me the shape of both are 16. later it tells me the shape of &quot;real_loss&quot; is only 15 while the other stays 16. So far I have only tried lowering the batchsize's and increasing them by 1 ect. I have provided the most relevant parts of the code. I can provide the rest of the code if needed. I have no clue why this is happening and it breaks the code.</p>\n<pre><code>with strategy.scope():\n  BATCH_SIZE = 16\n  GLOBAL_BATCH_SIZE = 32#batchsize*# of gpus\n  im_size = 256\n  latent_size = 512\nwith strategy.scope():\n  cross_entropy = tf.keras.losses.BinaryCrossentropy(\n    from_logits=True,\\\n    reduction = tf.keras.losses.Reduction.NONE)\n\n  #this is used to evaluate discriminators ability to discriminate\n  def discriminator_loss(real_output, fake_output):\n      real_loss = cross_entropy(tf.ones_like(real_output), real_output)#compares prediction to actual value of 1\n      fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)#compares rediction to actual value of 0\n      print(real_loss)\n      print(fake_loss)\n      total_loss = real_loss + fake_loss\n      total_loss = total_loss/GLOBAL_BATCH_SIZE\n      return total_loss\n\n\n  #how well was generator able to trick discriminator\n  def generator_loss(fake_output):\n      gen_loss = cross_entropy(tf.ones_like(fake_output), fake_output)#compares predictions to the expected value 1 of a real image\n      gen_loss = gen_loss / GLOBAL_BATCH_SIZE\n      return gen_loss\nwith strategy.scope():\n  EPOCHS = 80\n  noise_dim = 512\n  num_examples_to_generate = 32\n\n\n\n# We will reuse this seed overtime (so it's easier)\n# to visualize progress in the animated GIF)\nwith strategy.scope():\n  def noise(n):\n    return tf.random.normal([n, latent_size])\n\n  def noiseImage(n):\n    return tf.random.uniform([n, im_size, im_size, 1])\n  #seed = tf.random.normal([num_examples_to_generate, noise_dim])\n\n\n\n#seed used to generate image&gt;the discriminator than classifies real images from training set and a set of generated images&gt;loss is calculated and gradients are used to update the model\n# Notice the use of `tf.function`\n# This annotation causes the function to be &quot;compiled&quot;.\nwith strategy.scope():\n  #@tf.function\n  def train_step(images):\n      with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n        generated_images = generator((noise(BATCH_SIZE), noiseImage(BATCH_SIZE), np.ones([BATCH_SIZE,1])), training=True)\n\n        real_output = discriminator(images, training=True)\n        fake_output = discriminator(generated_images, training=True)\n\n        g_loss = generator_loss(fake_output)#runs generator loss\n        d_loss = discriminator_loss(real_output, fake_output)#runs disc loss\n            \n      G_grads = gen_tape.gradient(g_loss, generator.trainable_variables)\n      D_grads = disc_tape.gradient(d_loss, discriminator.trainable_variables)\n\n      generator_optimizer.apply_gradients(zip(G_grads, generator.trainable_variables))\n      discriminator_optimizer.apply_gradients(zip(D_grads, discriminator.trainable_variables))\n\n      #run g_optim twice to make sure d_loss doesn't go to zero\n      with tf.GradientTape() as gen_tape:\n        generated_imgs = generator((noise(BATCH_SIZE), noiseImage(BATCH_SIZE), np.ones([BATCH_SIZE,1])), training=True)\n        fake_output = discriminator(generated_imgs, training=True)\n        g_loss = generator_loss(fake_output)\n\n      G_grads = gen_tape.gradient(g_loss, generator.trainable_variables)\n      generator_optimizer.apply_gradients(zip(G_grads, generator.trainable_variables))\n\n      return g_loss, d_loss\n\n\n  @tf.function\n  def distributed_train_step(dist_dataset):\n      per_replica_g_losses, per_replica_d_losses = strategy.run(train_step, args=(dist_dataset,))\n      total_g_loss = strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_g_losses,axis=0)\n      total_d_loss = strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_d_losses,axis=0)\n      return total_g_loss, total_d_loss\n\n\nwith strategy.scope():\n  def train(dist_dataset, epochs):\n    for epoch in range(epochs):\n      start = time.time()\n      for image_batch in dist_dataset:\n        total_g_loss, total_d_loss = distributed_train_step(image_batch)#runs train_step function\n\n\nwith strategy.scope():\n  train(dist_dataset, EPOCHS)#in some cases can take up to 20000 epochs to train well\n</code></pre>\n<p>error and traceback</p>\n<pre><code>Traceback (most recent call last):\n  File &quot;C:\\image generator\\pixiv\\#image generator.py&quot;, line 507, in &lt;module&gt;\n    train(dist_dataset, EPOCHS)#in some cases can take up to 20000 epochs to train well\n  File &quot;C:\\image generator\\pixiv\\#image generator.py&quot;, line 441, in train\n    total_g_loss, total_d_loss = distributed_train_step(image_batch)#runs train_step function\n  File &quot;C:\\Users\\will\\miniconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py&quot;, line 580, in __call__\n    result = self._call(*args, **kwds)\n  File &quot;C:\\Users\\will\\miniconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py&quot;, line 611, in _call\n    return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable\n  File &quot;C:\\Users\\will\\miniconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py&quot;, line 2419, in __call__\n    graph_function, args, kwargs = self._maybe_define_function(args, kwargs)\n  File &quot;C:\\Users\\will\\miniconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py&quot;, line 2777, in _maybe_define_function\n    graph_function = self._create_graph_function(args, kwargs)\n  File &quot;C:\\Users\\will\\miniconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py&quot;, line 2667, in _create_graph_function\n    capture_by_value=self._capture_by_value),\n  File &quot;C:\\Users\\will\\miniconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py&quot;, line 981, in func_graph_from_py_func\n    func_outputs = python_func(*func_args, **func_kwargs)\n  File &quot;C:\\Users\\will\\miniconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py&quot;, line 441, in wrapped_fn\n    return weak_wrapped_fn().__wrapped__(*args, **kwds)\n  File &quot;C:\\Users\\will\\miniconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py&quot;, line 968, in wrapper\n    raise e.ag_error_metadata.to_exception(e)\nValueError: in user code:\n\n    C:\\image generator\\pixiv\\#image generator.py:419 distributed_train_step  *\n        per_replica_g_losses, per_replica_d_losses = strategy.run(train_step, args=(dist_dataset,))\n    C:\\image generator\\pixiv\\#image generator.py:393 train_step  *\n        d_loss = discriminator_loss(real_output, fake_output)#runs disc loss\n    C:\\image generator\\pixiv\\#image generator.py:328 discriminator_loss  *\n        total_loss = real_loss + fake_loss\n    C:\\Users\\will\\miniconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:984 binary_op_wrapper\n        return func(x, y, name=name)\n    C:\\Users\\will\\miniconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:1276 _add_dispatch\n        return gen_math_ops.add_v2(x, y, name=name)\n    C:\\Users\\will\\miniconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py:483 add_v2\n        &quot;AddV2&quot;, x=x, y=y, name=name)\n    C:\\Users\\will\\miniconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:744 _apply_op_helper\n        attrs=attr_protos, op_def=op_def)\n    C:\\Users\\will\\miniconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:595 _create_op_internal\n        compute_device)\n    C:\\Users\\will\\miniconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:3327 _create_op_internal\n        op_def=op_def)\n    C:\\Users\\will\\miniconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1817 __init__\n        control_input_ops, op_def)\n    C:\\Users\\will\\miniconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1657 _create_c_op\n        raise ValueError(str(e))\n\n    ValueError: Dimensions must be equal, but are 0 and 2 for '{{node replica_1/add}} = AddV2[T=DT_FLOAT](replica_1/binary_crossentropy_1/weighted_loss/Mul, replica_1/binary_crossentropy_2/weighted_loss/Mul)' with input shapes: [0], [2].\n</code></pre>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 56}]
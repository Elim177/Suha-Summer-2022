[{"items": [{"tags": ["python", "machine-learning", "tensorflow", "deep-learning"], "owner": {"account_id": 511732, "reputation": 3509, "user_id": 1538049, "user_type": "registered", "accept_rate": 94, "profile_image": "https://i.stack.imgur.com/jp5pz.jpg?s=256&g=1", "display_name": "Ufuk Can Bicici", "link": "https://stackoverflow.com/users/1538049/ufuk-can-bicici"}, "is_answered": true, "view_count": 115, "accepted_answer_id": 44813503, "answer_count": 1, "score": 1, "last_activity_date": 1498688807, "creation_date": 1498673485, "last_edit_date": 1498677890, "question_id": 44809749, "content_license": "CC BY-SA 3.0", "link": "https://stackoverflow.com/questions/44809749/tensorflow-the-priority-of-value-assigning-operations", "title": "Tensorflow: The priority of value assigning operations", "body": "<p>I try to understand how the Tensorflow computation graph operates, more deeply. Assume that we have the following code:</p>\n\n<pre><code>A = tf.truncated_normal(shape=(1, ), stddev=0.1)\nB = tf.Variable([0.3], dtype=tf.float32)\nC = A * B\ngrads = tf.gradients(C, [A, B])\ninit = tf.global_variables_initializer()\nsess = tf.Session()\nsess.run(init)\n\nfor i in range(1000):\n    results = sess.run([C, grads], {A: [2], B:[5]})\n</code></pre>\n\n<p>I get as the result 10 and gradients 5 for A and 2 for B, as expected. What I want to be sure is that, when we feed values to the tensors like we did for A and B, the default value generation mechanisms for them as defined in the computation graph become overwritten, is that right? </p>\n\n<p>For example, here, no normal random value is generated for A and it is overwritten by 2 and 0.3 is replaced with 5 for B, whenever we run the <code>sess.run</code> line in the for loop. How does the computation graph behaves exactly in such cases? </p>\n\n<p>For general cases, is my following understanding correct: Every time we call <code>sess.run</code>, the required nodes for calculating the values in the fetch list are determined with topological ordering and all tensors are overwritten with the values provided in the feed_dict parameter, breaking their dependence to the rest of the computation graph. (For example if tensor A waits B's value to be evaluated and if we inject a value to A in the feed_dict, A's dependence to B is broken and I believe that this is reflected in the computation graph as well, somehow). Then, according to the final form of the computation graph, the forward and backward calculations are executed.</p>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 103}]
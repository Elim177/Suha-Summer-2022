[{"items": [{"tags": ["tensorflow", "tensorflow2.0"], "owner": {"account_id": 1987773, "reputation": 1216, "user_id": 1782553, "user_type": "registered", "accept_rate": 70, "profile_image": "https://www.gravatar.com/avatar/bc4d4fbae28ecd225bd84e7e8cb6fc5e?s=256&d=identicon&r=PG", "display_name": "Jav", "link": "https://stackoverflow.com/users/1782553/jav"}, "is_answered": true, "view_count": 777, "accepted_answer_id": 67268537, "answer_count": 2, "score": 4, "last_activity_date": 1619568989, "creation_date": 1619442717, "last_edit_date": 1619512975, "question_id": 67267305, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/67267305/how-should-exponential-moving-average-be-used-in-custom-tf2-4-training-loop", "title": "How should Exponential Moving Average be used in custom TF2.4 training loop", "body": "<p>I have a custom training loop that can be simplified as follow</p>\n<pre><code>inputs = tf.keras.Input(dtype=tf.float32, shape=(None, None, 3))\nmodel = tf.keras.Model({&quot;inputs&quot;: inputs}, {&quot;loss&quot;: f(inputs)})\noptimizer = tf.keras.optimizers.SGD(learning_rate=0.1, momentum=0.9, nesterov=True)\n\nfor inputs in batches:\n    with tf.GradientTape() as tape:\n        results = model(inputs, training=True)\n    grads = tape.gradient(results[&quot;loss&quot;], model.trainable_weights)\n    optimizer.apply_gradients(zip(grads, model.trainable_weights))\n</code></pre>\n<p>The <a href=\"https://www.tensorflow.org/api_docs/python/tf/train/ExponentialMovingAverage\" rel=\"nofollow noreferrer\">TensorFlow documentation of ExponentialMovingAverage</a> is not clear on how it should be used in <a href=\"https://www.tensorflow.org/guide/keras/writing_a_training_loop_from_scratch\" rel=\"nofollow noreferrer\">from-scratch training loop</a>. As anyone worked with this?</p>\n<p>Additionally, how should the shadow variable be restored into the model if both are still in memory, and how can I check that that training variables were correctly updated?</p>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 157}]
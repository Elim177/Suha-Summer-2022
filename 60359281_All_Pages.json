[{"items": [{"tags": ["deep-learning", "generative-adversarial-network"], "owner": {"account_id": 17725514, "reputation": 15, "user_id": 12869351, "user_type": "registered", "profile_image": "https://lh3.googleusercontent.com/a-/AAuE7mDfJWSJ7inMnj6XLnUzQp68aG8QgpPY7nvzLJsk=k-s256", "display_name": "Minsik Seo", "link": "https://stackoverflow.com/users/12869351/minsik-seo"}, "is_answered": false, "view_count": 73, "answer_count": 0, "score": 1, "last_activity_date": 1582433432, "creation_date": 1582433432, "question_id": 60359281, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/60359281/what-is-the-best-conditional-generative-model-and-any-tips-for-implementation", "title": "What is the best conditional generative model? And any tips for implementation?", "body": "<p>I'm working on generative models to generate some samples for my research.\nFor some reason, I had to disentangle the latent space, so I tried to apply the ideas of infoGAN and conditional GAN to various architecture.</p>\n\n<p>I thought it was easy but, somehow, the model gave me poor results. Even the same architecture that gives good results without conditions, whenever the conditions are added, it becomes difficult to train.</p>\n\n<p>So, I wonder what is the best conditional architecture and someone can give tips for helping with my models? Some details are below:</p>\n\n<p>Images:</p>\n\n<p><a href=\"https://i.stack.imgur.com/J8Diq.png\" rel=\"nofollow noreferrer\">Generated samples with original DCGAN (non-conditional, good)</a></p>\n\n<p><a href=\"https://i.stack.imgur.com/b2tVl.png\" rel=\"nofollow noreferrer\">Generated samples with conditional DCGAN (fail)</a></p>\n\n<p><a href=\"https://i.stack.imgur.com/KT4BV.png\" rel=\"nofollow noreferrer\">Generated samples with conditional WGAN-GP (poor)</a></p>\n\n<p>Codes:</p>\n\n<p>Libraries</p>\n\n<pre><code>from functools import partial\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import Model, Sequential, Input\nfrom tensorflow.keras.layers import Dense, Conv2D, Conv2DTranspose, UpSampling2D, AveragePooling2D\nfrom tensorflow.keras.layers import Reshape, Flatten, Concatenate, BatchNormalization, Activation\nfrom tensorflow.keras.layers import ReLU, LeakyReLU\nimport numpy as np\nfrom scipy.linalg import sqrtm\nfrom utils import *\nimport time\nimport os\n</code></pre>\n\n<p>Model</p>\n\n<pre><code>class cWGAN4Rank2(object):\n    def __init__(self, z_dim=1, batch_size=64, gen_lr=1e-4, disc_lr=6e-5, lam=10., n_critic=5):\n        self.lam = lam\n        self.n_critic = n_critic\n        # Dataset\n        self.batch_size = batch_size\n        dataset, num_samples = load_rank2_dataset(False)\n        self.dataset = dataset.shuffle(num_samples).batch(batch_size)\n        elem_spec = dataset.element_spec\n        # Data shapes and dimensions\n        self.image_size = elem_spec[0].shape[0]\n        self.num_channel = elem_spec[0].shape[2]\n        self.image_shape = (self.image_size, self.image_size, self.num_channel)\n        self.z_dim = z_dim\n        # Models\n        self.D = self.build_discriminator(32, 5)\n        self.G = self.build_generator(34, 5)\n        self.I = keras.models.load_model('/data/inception4rank2.h5')\n        c = 0\n        for w in self.D.get_weights():\n            c += w.size\n        print(c)\n        c = 0\n        for w in self.G.get_weights():\n            c += w.size\n        print(c)\n        # Optimizers\n        self.D_opt = keras.optimizers.Adam(disc_lr, .5, .9)\n        self.G_opt = keras.optimizers.Adam(gen_lr, .5, .9)\n        # Test noise\n        self.num_ex = 64\n        z = tf.random.uniform(shape=(self.num_ex, self.z_dim), minval=-1, maxval=1)\n        c = tf.reshape(tf.constant(np.linspace(0,1,self.num_ex, dtype='float32')), (self.num_ex,1))\n        self.seed = tf.concat([z,c], axis=1)\n        # Records\n        self.epoch = 0\n        self.step = 0\n        self.steps = []\n        self.steps_per_epoch = []\n        self.D_loss_per_step = []\n        self.D_loss_per_epoch = []\n        self.G_loss_per_step = []\n        self.G_loss_per_epoch = []\n        self.FID_per_step = []\n        self.FID_per_epoch = []\n\n    def build_discriminator(self, filters, kernel_size):\n        c = Input(shape=(1,))\n        t = Dense(32*32)(c)\n        t = Reshape((32,32,1))(t)\n        t = Activation(tf.nn.leaky_relu)(BatchNormalization()(t))\n\n        x = Input(shape=self.image_shape, name='image_input') # 32x32x1\n        y = Conv2D(filters, kernel_size, padding='same')(x)\n        y = Activation(tf.nn.leaky_relu)(BatchNormalization()(y))\n        y = Concatenate()([y,t])\n        y = Conv2D(2*filters, kernel_size, strides=(2,2), padding='same')(y) # 16x16xn\n        y = Activation(tf.nn.leaky_relu)(BatchNormalization()(y))\n        y = Conv2D(4*filters, kernel_size, strides=(2,2), padding='same')(y) # 8x8xn\n        y = Activation(tf.nn.leaky_relu)(BatchNormalization()(y))\n        z = Dense(1)(Flatten()(y))\n        return Model([x,c], z)\n\n    def build_generator(self, filters, kernel_size):\n        x = Input(shape=(self.z_dim+1,))\n        y = Reshape((8,8,filters))(Dense(8*8*filters)(x)) # 8x8xn\n        y = Activation(tf.nn.relu)(BatchNormalization()(y))\n        y = Conv2DTranspose(2*filters, kernel_size, strides=(2,2), padding='same')(y) # 16x16xn\n        y = Activation(tf.nn.relu)(BatchNormalization()(y))\n        y = Conv2DTranspose(4*filters, kernel_size, strides=(2,2), padding='same')(y) # 32x32xn\n        y = Activation(tf.nn.relu)(BatchNormalization()(y))\n        z = Conv2D(1, kernel_size, padding='same', activation='tanh')(y)\n        return Model(x, z)\n\n    def train(self, num_epochs):\n        for e in range(num_epochs):\n            self.epoch += 1\n            t_epoch = time.time()\n            for batch in self.dataset:\n                self.step += 1\n                for _ in range(self.n_critic):\n                    D_loss = self.train_discriminator(batch)\n                self.D_loss_per_step.append(D_loss.numpy())\n                G_loss = self.train_generator()\n                self.G_loss_per_step.append(G_loss.numpy())\n\n                self.steps.append(self.step)\n            self.steps_per_epoch.append(self.step)\n            self.D_loss_per_epoch.append(D_loss)\n            self.G_loss_per_epoch.append(G_loss)\n            FID = self.fid_eval(batch)\n            self.FID_per_epoch.append(FID)\n\n            if (e+1) % 10 == 0:\n                display.clear_output(True)\n                self.visualization()\n\n            print('[{: 3d}/{: 3d}]epoch, D_loss= {:.4e}, G_loss= {:.4e}, time= {:.2f} sec'.format(e+1, num_epochs, D_loss, G_loss, time.time()-t_epoch))\n\n    @tf.function\n    def train_discriminator(self, batch):\n        X_real = 2 * batch[0] - 1\n        c_real = tf.reduce_mean(batch[0], axis=(1,2))\n        z = tf.random.uniform(shape=(self.batch_size, self.z_dim), minval=-1, maxval=1)\n        c_fake = tf.random.uniform(shape=(self.batch_size,1))\n        h = tf.concat([z, c_fake], axis=1)\n        with tf.GradientTape() as tape:\n            X_fake = self.G(h, training=True)\n            y_fake = self.D((X_fake,c_fake), training=True)\n            y_real = self.D((X_real,c_real), training=True)\n            real_loss = tf.reduce_mean(y_real)\n            fake_loss = tf.reduce_mean(y_fake)\n            D_loss = fake_loss - real_loss\n            gp = self.gradient_penalty(partial(self.D, training=True), X_real, X_fake, c_real, c_fake)\n            loss = D_loss + self.lam * gp\n        grad = tape.gradient(loss, self.D.trainable_variables)\n        self.D_opt.apply_gradients(zip(grad, self.D.trainable_variables))\n        return D_loss\n\n    @tf.function\n    def train_generator(self):\n        z = tf.random.uniform(shape=(self.batch_size, self.z_dim), minval=-1, maxval=1)\n        c_fake = tf.random.uniform(shape=(self.batch_size,1))\n        h = tf.concat([z, c_fake], axis=1)\n        with tf.GradientTape() as tape:\n            X_fake = self.G(h, training=True)\n            y_fake = self.D((X_fake,c_fake), training=True)\n            fake_loss = tf.reduce_mean(y_fake)\n            #vol_loss = .5 * tf.reduce_mean(tf.square(tf.reduce_mean((X_fake+1)/2, axis=(1,2)) - c_fake))\n            loss = -fake_loss# + vol_loss\n        grad = tape.gradient(loss, self.G.trainable_variables)\n        self.G_opt.apply_gradients(zip(grad, self.G.trainable_variables))\n        return loss\n\n    @tf.function\n    def gradient_penalty(self, f, X_real, X_fake, c_real, c_fake):\n        alpha = tf.random.uniform((self.batch_size, 1, 1, 1))\n        beta = tf.reshape(alpha, (-1,1))\n        inter = (alpha * X_real + (1 - alpha) * X_fake, beta * c_real + (1 - beta) * c_fake)\n        with tf.GradientTape() as tape:\n            tape.watch(inter)\n            pred = f(inter)\n        grad = tape.gradient(pred, inter)\n        slopes = tf.sqrt(tf.reduce_sum(tf.square(grad[0]), axis=(1,2,3)) + tf.reduce_sum(tf.square(grad[1]), axis=1))\n        return tf.reduce_mean((slopes - 1.)**2)\n\n    def fid_eval(self,batch):\n        X_real = 2 * batch[0] - 1\n        z = tf.random.uniform(shape=(self.batch_size, self.z_dim), minval=-1, maxval=1)\n        c_fake = tf.random.uniform(shape=(self.batch_size,1))\n        h = tf.concat([z, c_fake], axis=1)\n        X_fake = (self.G(h, training=False) + 1) / 2\n        a_real = self.I(X_real, training=False)\n        a_fake = self.I(X_fake, training=False)\n        mu_real, sig_real = tf.reduce_mean(a_real, axis=0), np.cov(a_real, rowvar=False)\n        mu_fake, sig_fake = tf.reduce_mean(a_fake, axis=0), np.cov(a_fake, rowvar=False)\n        ssdiff = np.sum((mu_real - mu_fake)**2)\n        covmean = sqrtm(sig_real.dot(sig_fake))\n        if np.iscomplexobj(covmean):\n            covmean = covmean.real\n        return ssdiff + np.trace(sig_real + sig_fake - 2.0 * covmean)\n\n    def visualization(self):\n        fig, ax = plt.subplots(1,3, figsize=(20,5))\n        X_test = self.G(self.seed, training=False)\n        nrow = int(np.floor(np.sqrt(self.num_ex)))\n        ncol = int(np.ceil(self.num_ex / nrow))\n        X_tile = np.zeros(shape=((self.image_size+2)*nrow,(self.image_size+2)*ncol))\n        for row in range(nrow):\n            for col in range(ncol):\n                ind = ncol * row + col\n                irow, icol = np.meshgrid(np.arange(self.image_size+2) + row*(self.image_size+2),\n                                         np.arange(self.image_size+2) + col*(self.image_size+2))\n\n                try:\n                    X_tile[irow,icol] = tf.pad(X_test[ind,:,:,0],[[1,1],[1,1]])\n                except:\n                    None\n        ax[0].imshow(1-X_tile, cmap='gray')\n        ax[1].plot(self.steps, self.D_loss_per_step, label='discriminator')\n        ax[1].plot(self.steps, self.G_loss_per_step, label='generator')\n        ax[1].legend()\n        ax[2].plot(self.steps_per_epoch, self.FID_per_epoch, label='FID')\n        ax[2].legend()\n        plt.show()\n</code></pre>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 51}]
[{"items": [{"tags": ["python", "tensorflow", "keras", "tensorflow2.0"], "owner": {"account_id": 16777256, "reputation": 361, "user_id": 12128237, "user_type": "registered", "profile_image": "https://www.gravatar.com/avatar/f56364f29ee711028529370db5673fd4?s=256&d=identicon&r=PG&f=1", "display_name": "dexter2406", "link": "https://stackoverflow.com/users/12128237/dexter2406"}, "is_answered": true, "view_count": 1206, "answer_count": 1, "score": 1, "last_activity_date": 1616656355, "creation_date": 1616586814, "last_edit_date": 1616626631, "question_id": 66780478, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/66780478/when-load-savedmodel-in-tf2-reportes-signature-wrapper-takes-0-positional-argu", "title": "When load SavedModel in TF2, reportes &quot;signature_wrapper takes 0 positional arguments but 1 were given&quot;", "body": "<p>I try to create a decoder, which takes five-Tensor tuple as input. As I saved it as <code>.h5</code> it works fine, but as I try to save(no error report), load, and do inference, it reports:</p>\n<pre><code>Traceback (most recent call last):\n  File &quot;D:/MA/Recources/monodepth2-torch/dsy.py&quot;, line 196, in &lt;module&gt;\n    build_model(inputs)\n  File &quot;D:/MA/Recources/monodepth2-torch/dsy.py&quot;, line 185, in build_model\n    outputs = decoder_pb(inputs)\n  File &quot;C:\\Users\\Dexxh\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\eager\\function.py&quot;, line 1655, in __call__\n    return self._call_impl(args, kwargs)\n  File &quot;C:\\Users\\Dexxh\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\eager\\function.py&quot;, line 1673, in _call_impl\n    return self._call_with_flat_signature(args, kwargs, cancellation_manager)\n  File &quot;C:\\Users\\Dexxh\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\eager\\function.py&quot;, line 1695, in _call_with_flat_signature\n    len(args)))\nTypeError: signature_wrapper(input_1, input_2, input_3, input_4, input_5) takes 0 positional arguments but 1 were given\n</code></pre>\n<p>My definition of the Model is as follows. The details seem no problem, because it runs fine when I load it as Keras model. And I use <code>tensorflow 2.3.1</code> in case you need.</p>\n<pre><code>class DepthDecoder(tf.keras.Model):\n    def __init__(self):\n        super(DepthDecoder, self).__init__()\n        self.num_ch_enc = [64, 64, 128, 256, 512]\n        self.num_ch_dec = [16, 32, 64, 128, 256]\n        self.scales = [0,1,2,3]  # range(4)\n        self.num_output_channels = 1\n\n        self.convs_0 = [None]*len(self.num_ch_dec)\n        self.convs_1 = [None]*len(self.num_ch_dec)\n\n        # todo: dispconv can be multiple output\n        self.dispconv_0 = self.make_conv(self.num_ch_dec[0], self.num_output_channels, activate_type=None,\n                                         pad_mode='reflect', type='disp', index=0)\n\n        for i in range(4, -1, -1):\n            # upconv_0\n            num_ch_in = self.num_ch_enc[-1] if i == 4 else self.num_ch_dec[i + 1]\n            num_ch_out = self.num_ch_dec[i]\n            self.convs_0[i] = self.make_conv(num_ch_in, num_ch_out, pad_mode='reflect', activate_type='elu',\n                                             type='conv_0', index=i)\n\n            # upconv_1\n            num_ch_in = self.num_ch_dec[i]\n            if i &gt; 0:\n                num_ch_in += self.num_ch_enc[i - 1]\n            num_ch_out = self.num_ch_dec[i]\n            self.convs_1[i] = self.make_conv(num_ch_in, num_ch_out, pad_mode='reflect', activate_type='elu',\n                                             type='conv_1', index=i)\n\n\n\n    def make_conv(self, input_channel, filter_num, activate_type=None, pad_mode='reflect',\n                  type:str=None, index=-1, input_shape:tuple=None):\n        name = None\n        if type is not None and index != -1:\n            name = ''.join([type, '_%d'%index])\n        if pad_mode == 'reflect':\n            padding = 'valid'\n        else:\n            padding = 'same'\n        conv = Conv2D(filters=filter_num, kernel_size=3, activation=activate_type,\n                      strides=1, padding=padding, use_bias=True, name=name)\n        return conv\n\n\n    def call(self, input_features, training=None, mask=None):\n        ch_axis = 3\n        x = input_features[-1]\n        for i in range(4, -1, -1):\n            x = tf.pad(x, [[0, 0], [1, 1], [1, 1], [0, 0]], mode='REFLECT')\n            x = self.convs_0[i](x)\n            x = [tf.keras.layers.UpSampling2D()(x)]\n            if i &gt; 0:\n                x += [input_features[i - 1]]\n            x = tf.concat(x, ch_axis)\n            x = tf.pad(x, [[0, 0], [1, 1], [1, 1], [0, 0]], mode='REFLECT')\n            x = self.convs_1[i](x)\n                # outputs.append(tf.math.sigmoid(x))\n        x = tf.pad(x, [[0, 0], [1, 1], [1, 1], [0, 0]], mode='REFLECT')\n        x = self.dispconv_0(x)\n        disp0 = tf.math.sigmoid(x)\n\n        return disp0\n</code></pre>\n<p>Then save and load:</p>\n<pre><code>inputs = (tf.random.uniform(shape=(1,96, 320, 64)),\n          tf.random.uniform(shape=(1,48, 160, 64)),\n          tf.random.uniform(shape=(1,24, 80, 128)),\n          tf.random.uniform(shape=(1,12, 40, 256)),\n          tf.random.uniform(shape=(1,6, 20, 512)))\n# Load\ndecoder = DepthDecoder()\noutputs = decoder.predict(inputs)\ndecoder = decoder_load_weights(decoder) # a custom weights loading from Pytorch, weights, details see below\ntf.keras.models.save_model(decoder, &quot;decoder_test&quot;)\n\n# Inference\ndecoder_import = tf.saved_model.load(&quot;decoder_test&quot;)\ndecoder_pb = decoder_import.signatures['serving_default']\noutputs = decoder_pb(inputs)\nfor k, v in outputs:\n   print(v.shape)\n\n# For completeness, here is the decoder_load_weigths() function\ndef decoder_load_weights(decoder, weights_path=None):\n    # Weights as List of ndarray, stored layerwise. Since it's fully convolutional, it's like [[#conv_0]*5,[#conv1]*5, [dispconv]], nothing else.\n    decoder_weights = np.load(weights_path, allow_pickle=True)\n    ind = 0\n    for l in decoder.layers:\n        print(l.name)\n        weights = l.get_weights()\n        if len(weights) == 0:\n            print(&quot;no weigths&quot;)\n        else:\n            print(weights[0].shape, &quot;\\t&quot;, weights[1].shape)\n            print(weights_grouped[ind][0].shape, &quot;\\t&quot;, weights_grouped[ind][1].shape)\n            new_weights = weights_grouped[ind]\n            l.set_weights(new_weights)\n            print(&quot;loading the %dnd conv layer...&quot;% ind)\n            ind += 1\n    return decoder\n</code></pre>\n<p>It's weird that it says takes <strong>0</strong> positional argument, suggesting no inputs allowed. Could you offer any insights? Thanks!!</p>\n<p>At last, let me post a snapshot of what's inside of <code>decoder_pb</code> (called <code>infer</code> in the snapshot). You can see that the <code>decoder_pb</code> indeed already has <code>Tensor</code> named <em>input_1</em>, <em>input_2</em> and so on, so the question is how can I <strong>assign my inputs to them</strong>.\nI cannot directly assign Tensors to them, because the &quot;name&quot; of the assigned Tensor is not <code>input_1</code> and <strong>EagerTensor cannot be renamed</strong>.</p>\n<p>I remember in TF1.x there's  <code>feed_dict</code> passed in <code>session</code>, don't know if  it's related...\n<a href=\"https://i.stack.imgur.com/EOoLl.jpg\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/EOoLl.jpg\" alt=\"enter image description here\" /></a></p>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 178}]
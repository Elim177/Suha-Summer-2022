[{"items": [{"tags": ["tensorflow", "tensorflow2.0"], "owner": {"account_id": 17979514, "reputation": 43, "user_id": 13066231, "user_type": "registered", "profile_image": "https://www.gravatar.com/avatar/9c2f82c4f11829dae070e18afa93816f?s=256&d=identicon&r=PG&f=1", "display_name": "nmucke", "link": "https://stackoverflow.com/users/13066231/nmucke"}, "is_answered": true, "view_count": 1127, "accepted_answer_id": 60733640, "answer_count": 1, "score": 4, "last_activity_date": 1584617446, "creation_date": 1584355962, "last_edit_date": 1584617446, "question_id": 60704587, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/60704587/training-multiple-models-defined-from-the-same-class-in-tensorflow-2-0-fails-whe", "title": "Training multiple models defined from the same class in Tensorflow 2.0 fails when using @tf.function", "body": "<p>I am using Tensorflow 2.1 to create custom models and custom training loops. My aim is to compare the accuracy of different configurations of my neural network. Specifically, in this case, I am comparing the reconstruction error of an AutoEncoder with varying latent dimension. Hence, I am training my network for one latent dimension then computing the test error and then I redo this process for another latent dimension, and so on. With this process I want to create plots like this:</p>\n\n<p>Plot example:</p>\n\n<p><img src=\"https://i.stack.imgur.com/th98k.png\" alt=\"Screnshot1\"></p>\n\n<p>To speed up the training I want to use the @tf.function decorator for the BackPropagation part of my training loop. However, when I try to train several different networks, looping over the latent dimension I get an error. See below:</p>\n\n<pre><code>ValueError: in converted code:\n\n    &lt;ipython-input-19-78bafad21717&gt;:41 grad  *\n        loss_value = tf.losses.mean_squared_error(inputs, model(inputs))\n    /tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/base_layer.py:778 __call__\n        outputs = call_fn(cast_inputs, *args, **kwargs)\n    &lt;ipython-input-19-78bafad21717&gt;:33 call  *\n        x_enc = self.encoder(inp)\n    /tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/base_layer.py:778 __call__\n        outputs = call_fn(cast_inputs, *args, **kwargs)\n    &lt;ipython-input-19-78bafad21717&gt;:9 call  *\n        x = self.dense1(inp)\n    /tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/base_layer.py:748 __call__\n        self._maybe_build(inputs)\n    /tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/base_layer.py:2116 _maybe_build\n        self.build(input_shapes)\n    /tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/layers/core.py:1113 build\n        trainable=True)\n    /tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/base_layer.py:446 add_weight\n        caching_device=caching_device)\n    /tensorflow-2.1.0/python3.6/tensorflow_core/python/training/tracking/base.py:744 _add_variable_with_custom_getter\n        **kwargs_for_getter)\n    /tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/base_layer_utils.py:142 make_variable\n        shape=variable_shape if variable_shape else None)\n    /tensorflow-2.1.0/python3.6/tensorflow_core/python/ops/variables.py:258 __call__\n        return cls._variable_v1_call(*args, **kwargs)\n    /tensorflow-2.1.0/python3.6/tensorflow_core/python/ops/variables.py:219 _variable_v1_call\n        shape=shape)\n    /tensorflow-2.1.0/python3.6/tensorflow_core/python/ops/variables.py:65 getter\n        return captured_getter(captured_previous, **kwargs)\n    /tensorflow-2.1.0/python3.6/tensorflow_core/python/eager/def_function.py:502 invalid_creator_scope\n        \"tf.function-decorated function tried to create \"\n\n    ValueError: tf.function-decorated function tried to create variables on non-first call.\n</code></pre>\n\n<p>I do not get this error when I remove @tf.function decorator. I believe if it has something to do with Tensorflow creating a computational graph when I use the decorator and this graph remains when I create another instance of my network. Thus, sparking an error since the old graph does not match the new instance of the network. But I am not sure about this at all, since I believe I am missing something fundamental about Tensorflow here!</p>\n\n<p>Below is a very simply version of my code recreating the error. I have tried to remove all the unnecessary parts of the code to make it easier to read and debug. Furthermore, I am generating a very simply training and test set just for the sake of this question. \nI have already tried the <code>tf.keras.backend.clear_session()</code> function without any luck. </p>\n\n<pre><code>import tensorflow as tf\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Encoder\nclass build_encoder(tf.keras.Model):\n  def __init__(self,latent_dim):\n      super(build_encoder, self).__init__()\n\n      self.dense1 = tf.keras.layers.Dense(32, activation='relu',use_bias=True)\n      self.dense2 = tf.keras.layers.Dense(latent_dim, activation='relu',use_bias=True)\n\n  def call(self, inp):\n      x = self.dense1(inp)\n      x = self.dense2(x)\n      return x\n\n# Decoder\nclass build_decoder(tf.keras.Model):\n  def __init__(self,):\n      super(build_decoder, self).__init__()\n\n      self.dense1 = tf.keras.layers.Dense(32, activation='relu',use_bias=True)\n      self.dense2 = tf.keras.layers.Dense(10, activation='relu',use_bias=True)\n\n  def call(self, inp):\n      x = self.dense1(inp)\n      x = self.dense2(x)\n      return x\n\n# Full Autoencoder\nclass Autoencoder(tf.keras.Model):\n  def __init__(self,latent_dim=5):\n      super(Autoencoder, self).__init__()\n\n      self.encoder = build_encoder(latent_dim)\n      self.decoder = build_decoder()\n\n  def call(self, inp):\n      x_enc = self.encoder(inp)\n      x_dec = self.decoder(x_enc)\n      return x_dec\n\n#### Here is the backpropagation with @tf.function decorator ####\n@tf.function\ndef grad(model, inputs):\n    with tf.GradientTape() as tape:\n        loss_value = tf.losses.mean_squared_error(inputs, model(inputs))\n    return loss_value, tape.gradient(loss_value, model.trainable_variables)\n\n# Training loop function\ndef train(x_train, model, num_epochs, batch_size,optimizer):\n\n    train_loss = []\n\n    for epoch in range(num_epochs):\n        tf.random.shuffle(x_train)\n        for i in range(0, len(x_train), batch_size):\n            x_inp = x_train[i: i + batch_size]\n            loss_value, grads = grad(model, x_inp)\n            optimizer.apply_gradients(zip(grads, model.trainable_variables))\n\n        train_loss.append(tf.reduce_mean(tf.losses.mean_squared_error(x_train, model(x_train))).numpy())\n\n        if epoch % 100 == 0:\n            print(\"Epoch: {}, Train loss: {:.9f}\".format(epoch, train_loss[epoch]))\n\n    return train_loss\n\n#### Generating simple training and test data\nnum_train = 10000\nnum_test = 1000\n\nx_train = s = np.random.uniform(0,1,(num_train,10)).astype(np.float32)\nx_train[:,6:10] = 0\n\nx_test = s = np.random.uniform(0,1,(num_test,10)).astype(np.float32)\nx_test[:,6:10] = 0\n###\n\nbatch_size = 8\nnum_epochs = 10000\n\ntest_loss = []\n\n# Looping over the latent dimensions\nfor latent_dim in range(1,10):\n\n  model = Autoencoder(latent_dim=3) # Creating an instance of my Autoencoder\n  optimizer = tf.keras.optimizers.Adam(learning_rate=0.00005) # Defining an optimizer\n  train_loss = train(x_train, model=model, num_epochs=num_epochs, batch_size=batch_size, optimizer=optimizer) # Training the network\n\n  test_loss.append(tf.reduce_mean(tf.losses.mean_squared_error(x_test, model(x_test))).numpy())\n\nplt.figure()\nplt.plot(test_loss,linewidth=1.5)\nplt.grid(True)\nplt.show()\n</code></pre>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 69}]
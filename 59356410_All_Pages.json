[{"items": [{"tags": ["python-3.x", "tensorflow", "deep-learning", "tensorflow2.0", "tf.keras"], "owner": {"account_id": 4441934, "reputation": 1952, "user_id": 3616293, "user_type": "registered", "accept_rate": 35, "profile_image": "https://www.gravatar.com/avatar/cf7556b4227065cec9496375d64fea3d?s=256&d=identicon&r=PG&f=1", "display_name": "Arun", "link": "https://stackoverflow.com/users/3616293/arun"}, "is_answered": true, "view_count": 484, "accepted_answer_id": 59356545, "answer_count": 1, "score": 1, "last_activity_date": 1576520074, "creation_date": 1576498244, "last_edit_date": 1576520074, "question_id": 59356410, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/59356410/tensorflow-2-0-build-function", "title": "TensorFlow 2.0 &#39;build&#39; function", "body": "<p>I was reading about creating neural networks using TensorFlow 2.0 in conjunction with 'GradientTape' API and came across the following code:</p>\n\n<pre><code>model = tf.keras.Sequential((\ntf.keras.layers.Reshape(target_shape=(28 * 28,), input_shape=(28, 28)),\ntf.keras.layers.Dense(100, activation='relu'),\ntf.keras.layers.Dense(100, activation='relu'),\ntf.keras.layers.Dense(10)))\n\nmodel.build()\noptimizer = tf.keras.optimizers.Adam()\n</code></pre>\n\n<p>In this code, what's the use/function of 'model.build()'? Is it compiling the designed neural network?</p>\n\n<p>The rest of the code is:</p>\n\n<pre><code>compute_loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n\ncompute_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n\n\ndef train_one_step(model, optimizer, x, y):\n  with tf.GradientTape() as tape:\n    logits = model(x)\n    loss = compute_loss(y, logits)\n\n  grads = tape.gradient(loss, model.trainable_variables)\n  optimizer.apply_gradients(zip(grads, model.trainable_variables))\n\n  compute_accuracy(y, logits)\n  return loss\n\n\n@tf.function\ndef train(model, optimizer):\n  train_ds = mnist_dataset()\n  step = 0\n  loss = 0.0\n  accuracy = 0.0\n  for x, y in train_ds:\n    step += 1\n    loss = train_one_step(model, optimizer, x, y)\n    if step % 10 == 0:\n      tf.print('Step', step, ': loss', loss, '; accuracy', compute_accuracy.result())\n  return step, loss, accuracy\n\nstep, loss, accuracy = train(model, optimizer)\nprint('Final step', step, ': loss', loss, '; accuracy', compute_accuracy.result())\n</code></pre>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 253}]
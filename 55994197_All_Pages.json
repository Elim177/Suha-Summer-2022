[{"items": [{"tags": ["tensorflow", "machine-learning", "deep-learning", "lstm"], "owner": {"account_id": 15877076, "reputation": 13, "user_id": 11455975, "user_type": "registered", "profile_image": "https://lh4.googleusercontent.com/-59iyrEBb9to/AAAAAAAAAAI/AAAAAAAAAAA/ACHi3rfXhn7n9dZyk8frfqD93ajQM0-R8Q/mo/photo.jpg?sz=256", "display_name": "nightly", "link": "https://stackoverflow.com/users/11455975/nightly"}, "is_answered": true, "view_count": 1990, "accepted_answer_id": 57042195, "answer_count": 1, "score": 1, "last_activity_date": 1613633849, "creation_date": 1557074572, "last_edit_date": 1557075613, "question_id": 55994197, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/55994197/calculate-jacobian-matrix-in-tensorflow-v-2-with-gradienttape", "title": "Calculate Jacobian Matrix in TensorFlow v.2 with GradientTape()", "body": "<p>I am currently trying to calculate the Jacobian Matrix in my training loop using <code>GradientTape()</code> and <code>batch_jacobian</code> in TensorFlow 2. Sadly I only obtain <code>None</code> values...</p>\n\n<p>My current attempt looks like this:</p>\n\n<pre class=\"lang-py prettyprint-override\"><code>for step, (batch_x, batch_y) in enumerate(train_data):\n\n            with tf.GradientTape(persistent=True) as g:\n                g.watch(batch_x)\n                g.watch(batch_y)\n                logits = self.retrained(batch_x, is_training=True)\n                loss = lstm.cross_entropy_loss(logits, batch_y)\n                acc = lstm.accuracy(logits, batch_y)\n            avg_loss += loss\n            avg_acc += acc\n\n            gradients = g.gradient(loss, self.retrained.trainable_variables)\n            J = g.batch_jacobian(logits, batch_x, experimental_use_pfor=False)\n            print(J.numpy())\n            self.optimizer.apply_gradients(zip(gradients, self.retrained.trainable_variables))\n</code></pre>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 292}]
[{"items": [{"tags": ["tensorflow-federated"], "owner": {"account_id": 22185030, "reputation": 137, "user_id": 16428078, "user_type": "registered", "profile_image": "https://www.gravatar.com/avatar/17e9bf8464ed809eaf2c797eaaa93086?s=256&d=identicon&r=PG&f=1", "display_name": "ozgur", "link": "https://stackoverflow.com/users/16428078/ozgur"}, "is_answered": true, "view_count": 143, "accepted_answer_id": 68428318, "answer_count": 1, "score": 1, "last_activity_date": 1626612141, "creation_date": 1626554695, "last_edit_date": 1626612141, "question_id": 68424157, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/68424157/how-to-get-rid-of-placementsserver-or-clients-so-that-i-can-transform-float32", "title": "How to get rid of placements(SERVER or CLIENTS) so that I can transform float32@SERVER to float32?", "body": "<p>I am trying to do learning rate decay challange of <em>Building Your Own Federated Learning Algorithm</em> tutorial. I have used the following code</p>\n<pre><code>import nest_asyncio\nnest_asyncio.apply()\n\nimport collections\nimport attr\nimport functools\nimport numpy as np\nimport tensorflow as tf\nimport tensorflow_federated as tff\n\nnp.random.seed(0)\n\nemnist_train, emnist_test = tff.simulation.datasets.emnist.load_data()\n\nNUM_CLIENTS = 10\nBATCH_SIZE = 20\ninitial_lr = 0.01\ndecay_rate = 0.0005\nminimum_lr = initial_lr/2\n\ndef preprocess(dataset):\n    def batch_format_fn(element):\n        return(tf.reshape(element['pixels'],[-1,784]),\n              tf.reshape(element['label'],[-1,1]))\n    return dataset.batch(BATCH_SIZE).map(batch_format_fn)\n\nclient_ids = np.random.choice(emnist_train.client_ids,\n                              size=NUM_CLIENTS, replace=False)\n\nfederated_train_data = [preprocess(emnist_train.create_tf_dataset_for_client(x))\n                       for x in client_ids]\n\ndef create_keras_model():\n    return tf.keras.models.Sequential([\n        tf.keras.layers.InputLayer(input_shape=(784,)),\n        tf.keras.layers.Dense(10, kernel_initializer='zeros'),\n        tf.keras.layers.Softmax(),\n    ])\n\ndef model_fn():\n    keras_model = create_keras_model()\n    return tff.learning.from_keras_model(\n        keras_model,\n        input_spec=federated_train_data[0].element_spec,\n        loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n        metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n\n@tf.function\ndef client_update(model, dataset, server_weights, client_optimizer):\n    client_weights = model.trainable_variables\n    tf.nest.map_structure(lambda x,y: x.assign(y),\n                         client_weights, server_weights)\n    \n    for batch in dataset:\n        with tf.GradientTape() as tape:\n            outputs = model.forward_pass(batch)\n        grads = tape.gradient(outputs.loss, client_weights)\n        grads = tf.clip_by_global_norm(grads, 5.0)[0]\n        grads_and_vars = zip(grads, client_weights)\n        client_optimizer.apply_gradients(grads_and_vars)\n    \n    return client_weights\n\n@tf.function\ndef server_update(model, mean_client_weights):\n    model_weights = model.trainable_variables\n    tf.nest.map_structure(lambda x,y: x.assign(y),\n                         model_weights, mean_client_weights)\n    \n    return model_weights\n\n@tff.tf_computation\ndef server_init():\n    model = model_fn()\n    return model.trainable_variables\n\n@tff.federated_computation\ndef initialize_fn():\n    return [tff.federated_value(server_init(), tff.SERVER), tff.federated_value(initial_lr, tff.SERVER)]\n    #return tff.federated_value([server_init(),initial_lr], tff.SERVER)\n\nwhimsy_model = model_fn()\ntf_dataset_type = tff.SequenceType(whimsy_model.input_spec)\nstr(tf_dataset_type)\n\nmodel_weights_type = server_init.type_signature.result\nstr(model_weights_type)\n\n@tff.tf_computation(tf_dataset_type, model_weights_type,tf.float32)\ndef client_update_fn(tf_dataset, server_weights, LR):\n    model = model_fn()\n    client_optimizer=tf.keras.optimizers.SGD(learning_rate=LR)\n    return client_update(model, tf_dataset, server_weights, client_optimizer)\n\n@tff.tf_computation(model_weights_type)\ndef server_update_fn(mean_client_weights):\n    model = model_fn()\n    return server_update(model, mean_client_weights)\n\nfederated_server_type = tff.FederatedType(model_weights_type,\n                                         tff.SERVER)\nfederated_dataset_type = tff.FederatedType(tf_dataset_type,\n                                          tff.CLIENTS)\n#federated_server_type_with_LR = tff.FederatedType([model_weights_type,tff.to_type((tf.float32))],tff.SERVER)\nfederated_server_type_with_LR = [tff.FederatedType(model_weights_type,tff.SERVER),\n                                 tff.FederatedType(tff.to_type((tf.float32)),tff.SERVER)]\n\n@tf.function\ndef decay_lr(lr):\n    if lr-decay_rate &gt; minimum_lr:\n        return lr-decay_rate\n    else:\n        return minimum_lr\n\n@tff.tf_computation(tf.float32)\ndef decay_lr_fn(lr):\n    return decay_lr(lr)\n\n@tff.federated_computation(federated_server_type_with_LR, federated_dataset_type)\ndef next_fn(server_weights_and_LR, federated_dataset):\n    \n    server_weights = server_weights_and_LR[0]\n    #LR_SERVER = server_weights_and_LR[1]\n    #LR_CLIENTS = tff.federated_broadcast(server_weights_and_LR[1])\n    \n    LR = server_weights_and_LR[1]\n    LR_NEW = tff.federated_map(decay_lr_fn, LR)\n    LR_NEW_CLIENTS = tff.federated_broadcast(LR_NEW)\n    \n    # Broadcast the server weights to the clients\n    server_weights_at_client = tff.federated_broadcast(server_weights)\n    \n    \n    # Each client computes their updated weights\n    client_weights = tff.federated_map(\n        client_update_fn, (federated_dataset, server_weights_at_client, LR_NEW_CLIENTS))\n    \n    # The server averages are updated\n    mean_client_weights = tff.federated_mean(client_weights)\n    \n    # The surver update\n    server_weights = tff.federated_map(server_update_fn, mean_client_weights)\n    \n    #return server_weights_and_LR\n    return [server_weights, LR_NEW]\n\nfederated_algorithm = tff.templates.IterativeProcess(\n    initialize_fn=initialize_fn,\n    next_fn=next_fn)\n\nsorted_client_ids = sorted(emnist_test.client_ids)\nsorted_client_ids2 = sorted_client_ids[0:100]\n\ndef data(client, source=emnist_test):\n    return preprocess(source.create_tf_dataset_for_client(client))\ncentral_emnist_test = (tf.data.Dataset.from_tensor_slices(\n    [data(client) for client in sorted_client_ids2])).flat_map(lambda x: x)\n\ndef evaluate(server_state):\n    keras_model = create_keras_model()\n    keras_model.compile(\n      loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n      metrics=[tf.keras.metrics.SparseCategoricalAccuracy()]  \n    )\n    keras_model.set_weights(server_state)\n    keras_model.evaluate(central_emnist_test)\n\nserver_state = federated_algorithm.initialize()\nevaluate(server_state[0])\n\nfor round in range(15):\n    print(round)\n    #server_state_temp = federated_algorithm.next(server_state, federated_train_data)\n    #server_state = [server_state_temp[0], decaying_lr(round)]\n    server_state = federated_algorithm.next(server_state, federated_train_data)\n    print(server_state[1])\n\nevaluate(server_state[0])\n</code></pre>\n<p>This code works just fine, but I want to add the learning rate definition to server_init() function. So basically have the following</p>\n<pre><code>@tff.tf_computation\ndef server_init():\n    model = model_fn()\n    return [model.trainable_variables, initial_lr]\n\n@tff.federated_computation\ndef initialize_fn():\n    return tff.federated_value(server_init(), tff.SERVER)\n</code></pre>\n<p>But doing so leads to following problem</p>\n<pre><code>The return type of `initialize_fn` must be assignable to the first input argument of `next_fn`, but:\n`initialize_fn` returned type:\n&lt;&lt;float32[784,10],float32[10]&gt;,float32&gt;@SERVER\nand the first input argument of `next_fn` is:\n&lt;server_weights_and_LR=&lt;&lt;float32[784,10],float32[10]&gt;@SERVER,float32@SERVER&gt;,federated_dataset={&lt;float32[?,784],int32[?,1]&gt;*}@CLIENTS&gt;\n</code></pre>\n<p>The problem is  <em>return [server_weights, LR_NEW]</em> code at the end of next_fn() has <em>&lt;float32[784,10],float32[10]&gt;@SERVER,float32@SERVER&gt;</em> type. Both server_weights and LR_NEW has already @SERVER placement. Currently</p>\n<pre><code>@tff.tf_computation\ndef server_init():\n    model = model_fn()\n    return model.trainable_variables\n\n@tff.federated_computation\ndef initialize_fn():\n    return [tff.federated_value(server_init(), tff.SERVER), tff.federated_value(initial_lr, tff.SERVER)]\n</code></pre>\n<p>also returns <em>&lt;float32[784,10],float32[10]&gt;@SERVER,float32@SERVER&gt;</em></p>\n<p>But as I said I want to change that part so to do that I want to remove the placements of server_weight and LR_NEW in next_fn and apply placement to the list containing both of those. How can I do that?</p>\n<p>Also does anyone have a &quot;cleaner&quot; solution to that challenge?</p>\n<p><strong>EDIT:</strong></p>\n<p>I just want to clarify the input-output match for initialize/input and next is &quot;cyclic&quot;. So we seek a match between output of initialize and input of next but also want one between output of next and input argument.</p>\n<pre><code>The first return argument of `next_fn` must be assignable to its first input argument, but found\n`next_fn` which returns type:\n&lt;&lt;float32[784,10],float32[10]&gt;@SERVER,float32@SERVER&gt;\nwhich does not match its first input argument:\n&lt;&lt;float32[784,10],float32[10]&gt;,float32&gt;@SERVER\n</code></pre>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 101}]
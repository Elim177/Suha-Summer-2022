[{"items": [{"tags": ["python", "tensorflow", "pytorch", "gradient"], "owner": {"account_id": 11732561, "reputation": 345, "user_id": 8801862, "user_type": "registered", "profile_image": "https://graph.facebook.com/1745047785795819/picture?type=large", "display_name": "user13", "link": "https://stackoverflow.com/users/8801862/user13"}, "is_answered": true, "view_count": 263, "accepted_answer_id": 68180126, "answer_count": 1, "score": 0, "last_activity_date": 1624974849, "creation_date": 1624973210, "question_id": 68179640, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/68179640/computing-gradient-in-tensorflow-vs-pytorch", "title": "Computing gradient in Tensorflow vs PyTorch", "body": "<p>I am trying to compute the gradient for a loss of a simple linear model. However, I face the problem that while using TensorFlow the gradient is computed as 'none'. Why is this happening and how to compute the gradient using TensorFlow?</p>\n<pre><code>import numpy as np\nimport tensorflow as tf\n\ninputs = np.array([[73, 67, 43], \n                   [91, 88, 64], \n                   [87, 134, 58], \n                   [102, 43, 37], \n                   [69, 96, 70]], dtype='float32')\n\ntargets = np.array([[56, 70], \n                    [81, 101], \n                    [119, 133], \n                    [22, 37], \n                    [103, 119]], dtype='float32')\n\ninputs = tf.convert_to_tensor(inputs)\ntargets = tf.convert_to_tensor(targets)\n\nw = tf.random.normal(shape=(2, 3))\nb = tf.random.normal(shape=(2,))\nprint(w, b)\n\ndef model(x):\n  return tf.matmul(x, w, transpose_b = True) + b\n\ndef mse(t1, t2):\n  diff = t1-t2\n  return tf.reduce_sum(diff * diff) / tf.cast(tf.size(diff), 'float32')\n\nwith tf.GradientTape() as tape:\n  pred = model(inputs)\n  loss = mse(pred, targets)\n\nprint(tape.gradient(loss, [w, b]))\n</code></pre>\n<p>Here is the working code using PyTorch. The gradients are computed as expected.</p>\n<pre><code>import torch\n\ninputs = np.array([[73, 67, 43], \n                   [91, 88, 64], \n                   [87, 134, 58], \n                   [102, 43, 37], \n                   [69, 96, 70]], dtype='float32')\n\ntargets = np.array([[56, 70], \n                    [81, 101], \n                    [119, 133], \n                    [22, 37], \n                    [103, 119]], dtype='float32')\n\ninputs = torch.from_numpy(inputs)\ntargets = torch.from_numpy(targets)\n\nw = torch.randn(2, 3, requires_grad = True)\nb = torch.randn(2, requires_grad = True)\n\ndef model(x):\n  return x @ w.t() + b\n\ndef mse(t1, t2):\n  diff = t1 - t2\n  return torch.sum(diff * diff) / diff.numel()\n\npred = model(inputs)\nloss = mse(pred, targets)\nloss.backward()\n\nprint(w.grad)\nprint(b.grad)\n</code></pre>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 206}]
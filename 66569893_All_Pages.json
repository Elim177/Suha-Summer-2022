[{"items": [{"tags": ["python", "keras", "tensorflow2.0", "gradienttape"], "owner": {"account_id": 4384210, "reputation": 85, "user_id": 3574932, "user_type": "registered", "profile_image": "https://www.gravatar.com/avatar/?s=256&d=identicon&r=PG&f=1", "display_name": "mbtg", "link": "https://stackoverflow.com/users/3574932/mbtg"}, "is_answered": true, "view_count": 518, "answer_count": 1, "score": 1, "last_activity_date": 1615989781, "creation_date": 1615397274, "question_id": 66569893, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/66569893/gradient-accumulation-in-tensorflow-2-x-keras", "title": "Gradient accumulation in tensorflow 2.x / keras", "body": "<p>I'm trying to implement Gradient accumulation on TF2.x. All implementations I've found are either for TF1.x or for the old keras interface. I don't think there is an implementation out there (though I'd be very happy to be proven wrong on this).</p>\n<p>Here's what I'm working with:</p>\n<pre class=\"lang-py prettyprint-override\"><code>import tensorflow as tf\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Flatten, Dense\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\n\n\nclass SimpleTrainStepModel(Model):\n    def train_step(self, data):\n        # Unpack the data. Its structure depends on your model and\n        # on what you pass to `fit()`.\n        if len(data) == 3:\n            x, y, sample_weight = data\n        else:\n            (x, y), sample_weight = data, None\n\n\n        # FIRST GRADIENT\n        with tf.GradientTape() as tape:\n            y_pred = self(x, training = True)  # Forward pass\n            loss = self.compiled_loss(y, y_pred, sample_weight = sample_weight, regularization_losses = self.losses)\n        gradients = tape.gradient(loss, self.trainable_variables)\n        self.compiled_metrics.update_state(y, y_pred)\n\n        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n\n        return {m.name: m.result() for m in self.metrics}\n\n\nclass GradAccumModel(Model):\n    def fit(self, *args, batch_size = 32, grad_accum = 1, **kwargs):\n        self.train_function = None\n        if batch_size % grad_accum != 0:\n            raise ValueError('Batch size must be divisible by the Gradient accumulation steps, dummy!')\n        self.grad_accum = grad_accum\n        self.batch_size = batch_size\n        return super(GradAccumModel, self).fit(*args,\n                                               batch_size = self.batch_size,\n                                               #validation_batch_size = validation_batch_size,#self.batch_size//grad_accum if validation_batch_size is None else validation_batch_size,\n                                               **kwargs)\n\n    def train_step(self, data):\n        # Unpack the data. Its structure depends on your model and\n        # on what you pass to `fit()`.\n        if len(data) == 3:\n            x, y, sample_weight = data\n        else:\n            (x, y), sample_weight = data, None\n\n        step = self.batch_size // self.grad_accum\n\n        # def _slice_nested(obj, i, j):\n        #     if type(obj) is list:\n        #         return [o[i:j] for o in obj]\n        #     else:\n        #         return obj[i:j]\n\n        # FIRST GRADIENT\n        with tf.GradientTape() as tape:\n            y_pred = self(x[:step], training = True)  # Forward pass\n            loss = self.compiled_loss(y[:step], y_pred, sample_weight = sample_weight, regularization_losses = self.losses)\n        gradients = tape.gradient(loss, self.trainable_variables)\n        self.compiled_metrics.update_state(y[:step], y_pred)\n\n        i = tf.constant(step)\n        # tf.print('TF - HERE!')\n        def cond(i, *args):\n            return i &lt; self.batch_size\n        def body(i, grad):\n            # tf.print('\\tTF - HERE!')\n            with tf.GradientTape() as tape:\n                y_pred = self(x[i:i + step], training = True) # Forward pass\n                loss = self.compiled_loss(y[i:i + step], y_pred, sample_weight = sample_weight, regularization_losses = self.losses)\n            _grad = tape.gradient(loss, self.trainable_variables)\n\n            for g,_g in zip(grad, _grad):\n                g += _g\n\n            self.compiled_metrics.update_state(y[i:i + step], y_pred)\n            return [i + step, grad]\n\n        i, gradients = tf.while_loop(cond, body, [i, gradients], parallel_iterations = 1)\n\n\n        # for g in gradients:        # I tried with and without division co calculate the mean\n        #     g *= 1/self.grad_accum #\n\n\n        # Update weights\n        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n        # Update metrics (includes the metric that tracks the loss)\n\n        # Return a dict mapping metric names to current value\n        return {m.name: m.result() for m in self.metrics}\n\n\nif __name__ == '__main__':\n    (x_train, y_train), (x_valid, y_valid) = tf.keras.datasets.mnist.load_data()\n\n    for MODEL, ga_kwarg, colour in list(zip([Model, SimpleTrainStepModel, GradAccumModel, GradAccumModel],\n                                            [{}, {}, {'grad_accum': 1}, {'grad_accum': 6}],\n                                            ['blue', 'green', 'yellow', 'red'])):\n\n        for _ in tqdm(range(10)):\n            # tf.random.set_seed(0)\n            x = Input((28, 28))\n            y = x\n            y = Flatten()(y)\n            y = Dense(128, activation = 'sigmoid')(y)\n            y = Dense(10, activation = 'softmax')(y)\n\n            model = MODEL(x, y)\n            model.compile(loss = tf.keras.losses.SparseCategoricalCrossentropy(),\n                          optimizer = tf.keras.optimizers.Adam(1e-4),\n                          metrics = ['acc'])\n\n            hist = model.fit(x_train, y_train, validation_data = (x_valid, y_valid), verbose = 0, batch_size = 6000, epochs = 100, **ga_kwarg)\n            plt.plot(hist.history['val_acc'], color = colour, alpha = .25)\n\n    plt.title('')\n    plt.xscale('symlog')\n    plt.yscale('logit')\n    plt.show()\n\n</code></pre>\n<p>I've been able to verify that it does actually save gpu memory. However, the end result is not the same as the normal <code>Model.fit</code>.</p>\n<p><a href=\"https://i.stack.imgur.com/1L7gE.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/1L7gE.png\" alt=\"Validation\" /></a></p>\n<p><a href=\"https://i.stack.imgur.com/afdWD.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/afdWD.png\" alt=\"Close-up\" /></a></p>\n<p>As you can see, the first three <code>Model.fit</code>s are well clustered and give the same results. But when the the <code>while</code> cycle comes into play the training is quite different.</p>\n<p>Anyone have any idea why this is happening?</p>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 190}]
[{"items": [{"tags": ["python", "gradient", "tensorflow2.0", "backpropagation"], "owner": {"account_id": 3227135, "reputation": 747, "user_id": 2723224, "user_type": "registered", "accept_rate": 100, "profile_image": "https://www.gravatar.com/avatar/?s=256&d=identicon&r=PG&f=1", "display_name": "aveevu", "link": "https://stackoverflow.com/users/2723224/aveevu"}, "is_answered": true, "view_count": 2959, "accepted_answer_id": 61196834, "answer_count": 3, "score": 8, "last_activity_date": 1621787248, "creation_date": 1583865113, "last_edit_date": 1585848652, "question_id": 60623869, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/60623869/gradcam-with-guided-backprop-for-transfer-learning-in-tensorflow-2-0", "title": "Gradcam with guided backprop for transfer learning in Tensorflow 2.0", "body": "<p>I get an error using gradient visualization with transfer learning in TF 2.0. The gradient visualization works on a model that does not use transfer learning. </p>\n\n<p>When I run my code I get the error:</p>\n\n<pre><code>    assert str(id(x)) in tensor_dict, 'Could not compute output ' + str(x)\nAssertionError: Could not compute output Tensor(\"block5_conv3/Identity:0\", shape=(None, 14, 14, 512), dtype=float32)\n</code></pre>\n\n<p>When I run the code below it errors. I think there's an issue with the naming conventions or connecting inputs and outputs from the base model, vgg16, to the layers I'm adding. Really appreciate your help!</p>\n\n<pre><code>\"\"\"\nBroken example when grad_model is created. \n\"\"\"\n!pip uninstall tensorflow\n!pip install tensorflow==2.0.0\nimport cv2\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras import layers\nimport matplotlib.pyplot as plt\n\nIMAGE_PATH = '/content/cat.3.jpg'\nLAYER_NAME = 'block5_conv3'\nmodel_layer = 'vgg16'\nCAT_CLASS_INDEX = 281\n\nimsize = (224,224,3)\n\nimg = tf.keras.preprocessing.image.load_img(IMAGE_PATH, target_size=(224, 224))\nplt.figure()\nplt.imshow(img)\nimg = tf.io.read_file(IMAGE_PATH)\nimg = tf.image.decode_jpeg(img)\nimg = tf.cast(img, dtype=tf.float32)\n# img = tf.keras.preprocessing.image.img_to_array(img)\nimg = tf.image.resize(img, (224,224))\nimg = tf.reshape(img, (1, 224,224,3))\n\ninput = layers.Input(shape=(imsize[0], imsize[1], imsize[2]))\nbase_model = tf.keras.applications.VGG16(include_top=False, weights='imagenet',\n                                          input_shape=(imsize[0], imsize[1], imsize[2]))\n# base_model.trainable = False\nflat = layers.Flatten()\ndropped = layers.Dropout(0.5)\nglobal_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n\nfc1 = layers.Dense(16, activation='relu', name='dense_1')\nfc2 = layers.Dense(16, activation='relu', name='dense_2')\nfc3 = layers.Dense(128, activation='relu', name='dense_3')\nprediction = layers.Dense(2, activation='softmax', name='output')\nfor layr in base_model.layers:\n    if ('block5' in layr.name):\n\n        layr.trainable = True\n    else:\n        layr.trainable = False\n\nx = base_model(input)\nx = global_average_layer(x)\nx = fc1(x)\nx = fc2(x)\nx = prediction(x)\n\nmodel = tf.keras.models.Model(inputs = input, outputs = x)\nmodel.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n                  loss='binary_crossentropy',\n                  metrics=['accuracy'])\n</code></pre>\n\n<p>This portion of the code is where the error lies. I'm not sure what is the correct way to label inputs and outputs.</p>\n\n<pre><code># Create a graph that outputs target convolution and output\ngrad_model = tf.keras.models.Model(inputs = [model.input, model.get_layer(model_layer).input], \n                                   outputs=[model.get_layer(model_layer).get_layer(LAYER_NAME).output,\n                                            model.output])\n\nprint(model.get_layer(model_layer).get_layer(LAYER_NAME).output)\n# Get the score for target class\n\n# Get the score for target class\nwith tf.GradientTape() as tape:\n    conv_outputs, predictions = grad_model(img)\n    loss = predictions[:, 1]\n</code></pre>\n\n<p>The section below is for plotting a heatmap of gradcam.</p>\n\n<pre><code>print('Prediction shape:', predictions.get_shape())\n# Extract filters and gradients\noutput = conv_outputs[0]\ngrads = tape.gradient(loss, conv_outputs)[0]\n\n# Apply guided backpropagation\ngate_f = tf.cast(output &gt; 0, 'float32')\ngate_r = tf.cast(grads &gt; 0, 'float32')\nguided_grads = gate_f * gate_r * grads\n\n# Average gradients spatially\nweights = tf.reduce_mean(guided_grads, axis=(0, 1))\n\n# Build a ponderated map of filters according to gradients importance\ncam = np.ones(output.shape[0:2], dtype=np.float32)\n\nfor index, w in enumerate(weights):\n    cam += w * output[:, :, index]\n\n# Heatmap visualization\ncam = cv2.resize(cam.numpy(), (224, 224))\ncam = np.maximum(cam, 0)\nheatmap = (cam - cam.min()) / (cam.max() - cam.min())\n\ncam = cv2.applyColorMap(np.uint8(255 * heatmap), cv2.COLORMAP_JET)\n\noutput_image = cv2.addWeighted(cv2.cvtColor(img.astype('uint8'), cv2.COLOR_RGB2BGR), 0.5, cam, 1, 0)\n\nplt.figure()\nplt.imshow(output_image)\nplt.show()\n</code></pre>\n\n<p>I also asked this to the tensorflow team on github at <a href=\"https://github.com/tensorflow/tensorflow/issues/37680\" rel=\"noreferrer\">https://github.com/tensorflow/tensorflow/issues/37680</a>.</p>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 2}]
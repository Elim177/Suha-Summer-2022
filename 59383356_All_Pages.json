[{"items": [{"tags": ["python", "tensorflow", "keras", "conv-neural-network", "tensorflow2.0"], "owner": {"account_id": 7147246, "reputation": 3840, "user_id": 5462551, "user_type": "registered", "accept_rate": 70, "profile_image": "https://www.gravatar.com/avatar/647be55cadd0e8edac86c55a337b264c?s=256&d=identicon&r=PG&f=1", "display_name": "noamgot", "link": "https://stackoverflow.com/users/5462551/noamgot"}, "is_answered": true, "view_count": 2825, "accepted_answer_id": 59391550, "answer_count": 1, "score": 5, "last_activity_date": 1576676093, "creation_date": 1576623952, "last_edit_date": 1576676093, "question_id": 59383356, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/59383356/accessing-layers-input-output-using-tensorflow-2-0-model-sub-classing", "title": "Accessing layer&#39;s input/output using Tensorflow 2.0 Model Sub-classing", "body": "<p>Working on a university exercise, I used the model sub-classing API of TF2.0. Here's my code (it's the Alexnet architecture, if you wonder...):</p>\n\n<pre><code>class MyModel(Model):\n    def __init__(self):\n        super(MyModel, self).__init__()\n        # OPS\n        self.relu = Activation('relu', name='ReLU')\n        self.maxpool = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='valid', name='MaxPool')\n        self.softmax = Activation('softmax', name='Softmax')\n\n        # Conv layers\n        self.conv1 = Conv2D(filters=96, input_shape=(224, 224, 3), kernel_size=(11, 11), strides=(4, 4), padding='same',\n                            name='conv1')\n        self.conv2a = Conv2D(filters=128, kernel_size=(5, 5), strides=(1, 1), padding='same', name='conv2a')\n        self.conv2b = Conv2D(filters=128, kernel_size=(5, 5), strides=(1, 1), padding='same', name='conv2b')\n        self.conv3 = Conv2D(filters=384, kernel_size=(3, 3), strides=(1, 1), padding='same', name='conv3')\n        self.conv4a = Conv2D(filters=192, kernel_size=(3, 3), strides=(1, 1), padding='same', name='conv4a')\n        self.conv4b = Conv2D(filters=192, kernel_size=(3, 3), strides=(1, 1), padding='same', name='conv4b')\n        self.conv5a = Conv2D(filters=128, kernel_size=(3, 3), strides=(1, 1), padding='same', name='conv5a')\n        self.conv5b = Conv2D(filters=128, kernel_size=(3, 3), strides=(1, 1), padding='same', name='conv5b')\n\n        # Fully-connected layers\n\n        self.flatten = Flatten()\n\n        self.dense1 = Dense(4096, input_shape=(100,), name='FC_4096_1')\n        self.dense2 = Dense(4096, name='FC_4096_2')\n        self.dense3 = Dense(1000, name='FC_1000')\n\n        # Network definition\n\n    def call(self, x, **kwargs):\n        x = self.conv1(x)\n        x = self.relu(x)\n        x = tf.nn.local_response_normalization(x, depth_radius=2, alpha=2e-05, beta=0.75, bias=1.0)\n        x = self.maxpool(x)\n\n        x = tf.concat((self.conv2a(x[:, :, :, :48]), self.conv2b(x[:, :, :, 48:])), 3)\n        x = self.relu(x)\n        x = tf.nn.local_response_normalization(x, depth_radius=2, alpha=2e-05, beta=0.75, bias=1.0)\n        x = self.maxpool(x)\n\n        x = self.conv3(x)\n        x = self.relu(x)\n        x = tf.concat((self.conv4a(x[:, :, :, :192]), self.conv4b(x[:, :, :, 192:])), 3)\n        x = self.relu(x)\n        x = tf.concat((self.conv5a(x[:, :, :, :192]), self.conv5b(x[:, :, :, 192:])), 3)\n        x = self.relu(x)\n        x = self.maxpool(x)\n\n        x = self.flatten(x)\n\n        x = self.dense1(x)\n        x = self.relu(x)\n        x = self.dense2(x)\n        x = self.relu(x)\n        x = self.dense3(x)\n        return self.softmax(x)\n</code></pre>\n\n<p>My goal is to access an arbitrary layer's output (in order to maximize a specific neuron's activation, if you have to know exactly :) ). The problem is that trying to access any layer's output, I get an attribute error. For example:</p>\n\n<pre><code>model = MyModel()\nprint(model.get_layer('conv1').output)\n# =&gt; AttributeError: Layer conv1 has no inbound nodes.\n</code></pre>\n\n<p>I found some questions with this error here in SO, and all of them claim that I have to define the input shape in the first layer, but as you can see - it's already done (see the definition of <code>self.conv1</code> in the <code>__init__</code> function)!</p>\n\n<p>I did find that if I define a <code>keras.layers.Input</code> object, I do manage to get the output of <code>conv1</code>, but trying to access deeper layers fails, for example:</p>\n\n<pre><code>model = MyModel()\nI = tf.keras.Input(shape=(224, 224, 3))\nmodel(I)\nprint(model.get_layer('conv1').output)\n# prints Tensor(\"my_model/conv1/Identity:0\", shape=(None, 56, 56, 96), dtype=float32)\nprint(model.get_layer('FC_1000').output)\n# =&gt; AttributeError: Layer FC_1000 has no inbound nodes.\n</code></pre>\n\n<p>I googled every exception that I got on the way, but found no answer. How can I access any layer's input/output (or input/output _shape attributes, by the way) in this case?</p>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 21}]
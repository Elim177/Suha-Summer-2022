[{"items": [{"tags": ["python", "tensorflow", "keras", "conv-neural-network"], "owner": {"account_id": 17122606, "reputation": 21, "user_id": 12390502, "user_type": "registered", "profile_image": "https://www.gravatar.com/avatar/3b039010c8dd19b7dac4864e0800323d?s=256&d=identicon&r=PG&f=1", "display_name": "philipp456", "link": "https://stackoverflow.com/users/12390502/philipp456"}, "is_answered": false, "view_count": 479, "answer_count": 1, "score": 2, "last_activity_date": 1586170033, "creation_date": 1586168590, "question_id": 61057620, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/61057620/error-unconnected-gradients-while-implementing-grad-cam-in-keras", "title": "Error unconnected gradients while implementing Grad-Cam in keras", "body": "<p>I am trying to create a heatmap that displays where my CNN is looking in order to classify the image. For the classification tasks, I am deciding between faulty parts and non-faulty parts (hence only Binary classification).\nI was trying to replicate this <a href=\"https://www.pyimagesearch.com/2020/03/09/grad-cam-visualize-class-activation-maps-with-keras-tensorflow-and-deep-learning/\" rel=\"nofollow noreferrer\">code</a>. However, what I saw is that they used the whole Inception network without changing the top layer. My problem now is that I don't know how to correctly connect the layers so that I can use the gradient function to backpropagate the loss from the end of my model (Dense Layer with one neuron) to the last convolutional layer in the inception network (\"mixed10\"). So far I get an AssertionError with the message of unconnected gradients </p>\n\n<p>The model I trained: </p>\n\n<pre><code>def create_model():\n\nmodel_inception= InceptionV3(include_top=False, weights='imagenet',input_shape=(299,299,3))\n\nmodel_inception.trainable=False\n\nmodel = Sequential()\nmodel.add(model_inception)\nmodel.add(GlobalAveragePooling2D())\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(1, activation='sigmoid'))\n\nmodel.compile(optimizer='rmsprop',\n              loss='binary_crossentropy', metrics=['accuracy'])\n\nreturn model\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/PEyWs.png\" rel=\"nofollow noreferrer\">Model Summary</a></p>\n\n<p>Grad_CAM Code:</p>\n\n<pre><code>layer_name = 'mixed10'\nimage = np.expand_dims(X_valid[0], 0)\n\n#input layter to inception\ninput_lay = model.get_layer(index=0).layers[0].input\n\n#Heatmap creatd from ConvLayer\nconv_output_lay = model.get_layer(index=0).get_layer(layer_name).output\n\n#Output Layer of the network\noutput_lay = model.get_layer(index=-1).output\n\n#Connect conv_output with model.input\nincept_part_till_conv = Model(input_lay,conv_output_lay)\nconv_output = incept_part_till_conv(model.input)\n\ngradModel = Model(\ninputs=[model.input],\noutputs=[conv_output, \n    model.output])\n\n# record operations for automatic differentiation\nwith tf.GradientTape() as tape:\n    # cast the image tensor to a float-32 data type, pass the\n    # image through the gradient model, and grab the loss\n    # associated with the specific class index\n    inputs = tf.cast(image, tf.float32)\n    (convOutputs, predictions) = gradModel(inputs)\n    loss = predictions[:]\n\n    # use automatic differentiation to compute the gradients\n    grads = tape.gradient(loss, convOutputs)\n</code></pre>\n\n<p>Then I get the error message. If someone could give me some tips on how I can make it work, that would be really great. Thanks!</p>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 98}]
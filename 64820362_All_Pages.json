[{"items": [{"tags": ["python", "tensorflow", "machine-learning", "time-series", "forecasting"], "owner": {"account_id": 1898217, "reputation": 7385, "user_id": 1714692, "user_type": "registered", "accept_rate": 43, "profile_image": "https://www.gravatar.com/avatar/bd72cbc200eb7c9aa507624f154b21a7?s=256&d=identicon&r=PG", "display_name": "Francesco Boi", "link": "https://stackoverflow.com/users/1714692/francesco-boi"}, "is_answered": false, "view_count": 61, "answer_count": 0, "score": 0, "last_activity_date": 1605268114, "creation_date": 1605268114, "question_id": 64820362, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/64820362/how-to-use-a-tensorflow-forecasting-model-trained-on-batches-for-single-predicti", "title": "How to use a Tensorflow forecasting model trained on batches for single predictions?", "body": "<p>I am trying to train a model for univariate time series forecasting in Tensorflow. First I create a <code>tf.data.Dataset</code> from the dataframe using a window of 10 where the last value in each window is the ground truth value to be predicted. I then shuffle and split the dataset into a train/validation/test dataset using a 70%/15%/15% proportion respectively. I batch the train and validation sets with a batch size of 32.</p>\n<pre><code>df = pd.read_csv('MY.csv', index_col=0, parse_dates=True)\n#extract the column we are interested in\nsingle_col = df[['Close']]\n\n#Convert to TFDataset\nWINDOW_SIZE = 10\ndataset = tf.data.Dataset.from_tensor_slices((single_col_df.values))\nd = dataset.window(WINDOW_SIZE, shift=1, drop_remainder=True)\nd2 = d.flat_map(lambda window: window.batch(WINDOW_SIZE+1))\n#create data and ground truth\nd3 = d2.map(lambda window: (window[:-1], window[-1:]))\n\n#get the total data and shuffle\nlen_ds = 0\nfor item in d2:\n  len_ds +=1\nd_shuffled = d3.shuffle(buffer_size=len_ds)\n\n# split train/test\ntrain_size = int(0.7 * len_ds)\nval_size = int(0.15 * len_ds)    \ntest_size = int(0.15 * len_ds)\ntrain_dataset = d_shuffled.take(train_size)\ntest_dataset = d_shuffled.skip(train_size)\nval_dataset = test_dataset.skip(test_size)\ntest_dataset = test_dataset.take(test_size)\ntrain_dataset = train_dataset.batch(32).prefetch(2)\nval_dataset = val_dataset.batch(32)\n</code></pre>\n<p>Now I define, compile and train the model. I am assuming the <code>input_shape</code> of the first GRU layer should be <code>[WINDOW_SIZE, 1]</code>, i.e., the number of past samples to be used for a new forecast and $1$ because it is a univariate model.</p>\n<pre><code># DEFINE THE MODEL ARCHITECTURE\nMODEL_ARCH = [\n  tf.keras.layers.GRU(32, return_sequences=True, input_shape=[WINDOW_SIZE, 1]),\n  tf.keras.layers.GRU(32,),\n  tf.keras.layers.Dense(10, activation='tanh'),\n  tf.keras.layers.Dense(1, activation='tanh'),\n  tf.keras.layers.Lambda(lambda x: x*100)\n\n]\n\n# TRAIN THE MODEL\nmodel = tf.keras.models.Sequential(MODEL_ARCH)\n\noptimizer = tf.keras.optimizers.Adagrad(lr=1e-3)\nmodel.compile(loss='mse', optimizer=optimizer) #accuracy is a categorical metric: don't use it\n\nhistory = model.fit(train_dataset, epochs=100, validation_data=val_dataset)\n</code></pre>\n<p>The problem arises when evaluating or predicting the model: I want to evaluate/predict single values instead of batches. Running <code>model.evaluate(test_dataset)</code> returns an error, I think because the training was performed on batches of 32, but <code>test_data</code> has not been batched. To do that instead I am forced to do:</p>\n<pre><code>model.evaluate(test_data.batch(1), batch_size=1)\n</code></pre>\n<p>But this returns a different result every time it is run. The problem I think is the fact that the after training the model with a given bath size, I then cannot use it for single prediction. I tried also to redefine the model and copy the weights as suggested by other posts, but it did not solve. The problem might involve also the input shape I set for the first layer, i.e. <code>[WINDOW_SIZE, 1]</code> since.</p>\n<p><strong>OPTIONAL TIP</strong></p>\n<p>Does anyone have a better way to find out the length of a <code>tf.data.Dataset</code> structure instead of looping through its elements as I did?</p>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 262}]
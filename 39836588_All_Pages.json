[{"items": [{"tags": ["python", "optimization", "graph", "tensorflow", "placeholder"], "owner": {"user_type": "does_not_exist", "display_name": "user4706825"}, "is_answered": false, "view_count": 535, "answer_count": 1, "score": 0, "last_activity_date": 1489006751, "creation_date": 1475513524, "last_edit_date": 1495542713, "question_id": 39836588, "content_license": "CC BY-SA 3.0", "link": "https://stackoverflow.com/questions/39836588/optimize-a-graph-built-by-two-imported-graphs-tensorflow", "title": "Optimize a graph built by two imported graphs Tensorflow", "body": "<p>I need to use the output from a graph as the input to another one for a deep learning project, and then optimize all the variables of the two graphs. The input of each graph is a placeholder.</p>\n\n<p>My problem is very similar to the one discussed here: <a href=\"https://stackoverflow.com/questions/33748552/tensorflow-how-to-replace-a-node-in-a-calculation-graph\">Tensorflow: How to replace a node in a calculation graph?</a></p>\n\n<p>Unfortunately, the question was not resolved due to an error that I am getting as well as pointed out at that time. I'll post my case</p>\n\n<p>This is a sample program which actually do trivial computations</p>\n\n<pre><code>with tf.Graph().as_default() as g_1:\n    input_1 = tf.placeholder(tf.float32, shape=[3,3], name=\"input\")\n    weight1 = tf.Variable(tf.truncated_normal([3, 3], stddev=0.1), name=\"weight\")\n    y = tf.matmul(input_1,weight1)\n    # NOTE: using identity to get a known name for the output tensor.\n    output1 = tf.identity(y, name=\"output\")\n\ngdef_1 = g_1.as_graph_def()\n\nwith tf.Graph().as_default() as g_2:  # NOTE: g_2 not g_1       \n    input_2 = tf.placeholder(tf.float32, shape=[3,3], name=\"input\")\n    weight2 = tf.Variable(tf.truncated_normal([3, 3], stddev=0.1), name=\"weight\")\n    z = tf.matmul(input_2, weight2)\n    output2 = tf.identity(z, name=\"output\")\n\ngdef_2 = g_2.as_graph_def()\n</code></pre>\n\n<p>Then I import the two graphs in another graph:</p>\n\n<pre><code>with tf.Graph().as_default() as g_combined:\n    x = tf.placeholder(tf.float32, shape=[3,3], name=\"input_matrix\")\n\n    # Import gdef_1, which performs f(x).\n    # \"input:0\" and \"output:0\" are the names of tensors in gdef_1.\n    y, = tf.import_graph_def(gdef_1, input_map={\"input:0\": x},\n                           return_elements=[\"output:0\"])\n\n    # Import gdef_2, which performs g(y)\n    z, = tf.import_graph_def(gdef_2, input_map={\"input:0\": y},\n                           return_elements=[\"output:0\"])\n\n    cost = tf.reduce_sum(tf.square(z-x))\n    variables = [op.outputs[0] for op in tf.get_default_graph().get_operations() if op.type == \"Variable\"]\n    print (variables)\n    optimizer = tf.train.AdamOptimizer(0.01).minimize(cost,var_list = variables)\n</code></pre>\n\n<p>This is the solution suggested in the previously linked question, but it gives the following error:</p>\n\n<pre><code>TypeError: Argument is not a tf.Variable: Tensor(\"import/weight:0\", dtype=float32_ref)\n</code></pre>\n\n<p>The variable <code>variables</code> contains:</p>\n\n<pre><code>[&lt;tf.Tensor 'import/weight:0' shape=&lt;unknown&gt; dtype=float32_ref&gt;, &lt;tf.Tensor 'import_1/weight:0' shape=&lt;unknown&gt; dtype=float32_ref&gt;]\n</code></pre>\n\n<p>Does anyone know how to make it work? Or how to optimize the entire structure, considering that I need an intermediate result to feed a placeholder?</p>\n\n<p>Thank you very much</p>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 116}]
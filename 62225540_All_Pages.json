[{"items": [{"tags": ["python", "machine-learning", "deep-learning", "conv-neural-network", "tensorflow2.0"], "owner": {"account_id": 370690, "reputation": 121, "user_id": 718798, "user_type": "registered", "profile_image": "https://www.gravatar.com/avatar/8a44265c4b8454e7b3599ea79ea2685d?s=256&d=identicon&r=PG", "display_name": "cpps", "link": "https://stackoverflow.com/users/718798/cpps"}, "is_answered": true, "view_count": 99, "answer_count": 1, "score": 2, "last_activity_date": 1591449882, "creation_date": 1591399964, "last_edit_date": 1591449594, "question_id": 62225540, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/62225540/problem-in-implementing-a-cnn-with-tensorflow-2-0-for-digit-recognition", "title": "Problem in implementing a CNN with Tensorflow 2.0 for digit recognition", "body": "<p>I'm trying to implement a CNN in order to recognize single numbers coming from ttf files(RGB, in 3 channels). It does not learn and always stuck at some point. What I m doing wrong? Is the structure right? All examples I found are implemented with Keras or with Tensorflow 1.x. I tried multiples options for batchs, filters, learning rates... </p>\n\n<pre><code># image\nimage_channels = 3\nimage_width = 30\nimage_height = 30\nimage_flatten = image_width * image_height\n# batch\nbatch_size = 200\n# Training parameters.\nlearning_rate = 0.005\ntraining_epoch = 45000\ndisplay_step = 10\n# Network parameters.\nnumber_of_filters = 64\nneurons_layer_1 = 1024\nneurons_layer_2 = 512\nneurons_output = 10\ndropout_rate = 0.4\n\nweights = {\n    'W1': tf.Variable(tf.random.truncated_normal([3, 3, 3, number_of_filters], dtype=tf.float32, stddev=0.1),\n                      name='Weights_1'),\n    'W2': tf.Variable(tf.random.truncated_normal([14 * 14 * number_of_filters, neurons_layer_1], stddev=0.1),\n                      name='Weights_2'),\n    'W3': tf.Variable(tf.random.truncated_normal([neurons_layer_1, neurons_layer_2], stddev=0.1), name='Weights_3'),\n    'W4': tf.Variable(tf.random.truncated_normal([neurons_layer_2, neurons_output], stddev=0.1), name='Weights_3')\n}\nbiases = {\n    'b1': tf.Variable(tf.constant(0.1, shape=[number_of_filters]), name='bias_1'),\n    'b2': tf.Variable(tf.constant(0.1, shape=[neurons_layer_1]), name='bias_2'),\n    'b3': tf.Variable(tf.constant(0.1, shape=[neurons_layer_2]), name='bias_2'),\n    'b4': tf.Variable(tf.constant(0.1, shape=[neurons_output]), name='bias_3')\n}\n\n# Create model.\ndef neural_net(inputdata, debug=False):\n    if debug:\n        print(\"--------------- starting step:\")\n    # ## EXTRACTING FEATURES\n    result_conv2d_1 = tf.nn.conv2d(inputdata, weights['W1'], strides=[1, 2, 2, 1], padding='VALID') + biases['b1']\n    result_relu_1 = tf.nn.relu(result_conv2d_1)\n    result_maxpool_1 = tf.nn.max_pool(result_relu_1, ksize=[1, 1, 1, 1], strides=[1, 1, 1, 1], padding='VALID')\n    if debug:\n        print(\"result_conv2d_1--&gt;\",result_conv2d_1.shape)\n        print(\"result_relu_1  --&gt;\",result_relu_1.shape)\n        print(\"maxpool1.shape --&gt; \", result_maxpool_1.shape)\n\n    # flat\n    flatten = tf.reshape(result_maxpool_1, shape=(tf.shape(result_maxpool_1)[0], -1))\n    if debug:\n        print(\"flatten.shape  --&gt; \", flatten.shape)\n\n    # ## CLASIFFICATION\n    # layer 1 - dense / fully connected\n    layer1 = tf.nn.relu(tf.add(tf.matmul(flatten, weights['W2']), biases['b2']))\n    # dropout\n    #layer_drop = tf.nn.dropout(layer1, rate=dropout_rate)\n    # layer 2 - dense / fully connected\n    layer2 = tf.nn.relu(tf.add(tf.matmul(layer1, weights['W3']), biases['b3']))\n    # layer 2 - dense / fully connected\n    layer3 = tf.nn.relu(tf.add(tf.matmul(layer2, weights['W4']), biases['b4']))\n    result = tf.nn.softmax(layer3)\n\n    return result\n\n# Cross-Entropy loss function.\ndef cross_entropy(predicted, desired):\n    desired2 = tf.one_hot(desired, depth=neurons_output)\n    cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=desired2, logits=predicted, name=\"cross_entropy\")\n    mean = tf.reduce_mean(cross_entropy, name=\"cross_entropy_mean\")\n    return mean\n\n\n# Accuracy metric.\ndef accuracy(y_pred, y_true):\n    # Predicted class is the index of highest score in prediction vector (i.e. argmax).\n    correct_prediction = tf.equal(tf.argmax(y_pred, 1), tf.cast(y_true, tf.int64))\n    return tf.reduce_mean(tf.cast(correct_prediction, tf.float32), axis=-1)\n\n\noptimizer = tf.optimizers.Adam(learning_rate)\n\n# Optimization process.\ndef run_optimization(inputdata, expected, debug=False):\n    # Wrap computation inside a GradientTape for automatic differentiation.\n    with tf.GradientTape() as g:\n        predicted = neural_net(inputdata, debug)\n        loss = cross_entropy(predicted, expected)\n        #print(f'\\r          loss: {loss}', end=\"\")\n    # Variables to update, i.e. train able variables.\n    trainable_variables = list(weights.values()) + list(biases.values())\n    # Compute gradients.\n    gradients = g.gradient(loss, trainable_variables)\n    # Update W and b following gradients.\n    optimizer.apply_gradients(zip(gradients, trainable_variables))    \n\n\ndatafile = open(\"W:/machinelearning/dataset_ttf_single/ttf_single_full.p\", \"rb\")\nwith datafile:\n    for step in range(training_steps):\n        # Run the optimization to update W and b values.\n        batch_images, batch_labels = load_batch_dataset(datafile, batch_size)\n        run_optimization(batch_images, batch_labels, False)\n        if step % display_step == 0:\n            predicted = neural_net(batch_images)\n            loss = cross_entropy(predicted, batch_labels)\n            acc = accuracy(predicted, batch_labels)\n            print(\"\\nstep: %i, loss: %f, accuracy: %f\" % (step, loss, acc))\ndatafile.close()\n</code></pre>\n\n<p>The results are usually like this:</p>\n\n<pre><code>step: 330, loss: 2.341150, accuracy: 0.120000\n\nstep: 340, loss: 2.396150, accuracy: 0.065000\n\nstep: 350, loss: 2.361150, accuracy: 0.100000\n\nstep: 360, loss: 2.376150, accuracy: 0.085000\n\nstep: 370, loss: 2.371150, accuracy: 0.090000\n\nstep: 380, loss: 2.331150, accuracy: 0.130000\n\nstep: 390, loss: 2.326150, accuracy: 0.135000\n</code></pre>\n\n<p>It stacks between 0.10 and 0.15 usually. I followed an example of CNN MNIST in Tensorflow 2.0, it works but I'm not able to do it with different images not coming from MNIST. I'm sure the optimizers and the CNN are not perfect but I'm trying to start from the beginning creating a little piece of CNN and then improve it, I want to learn how it works, but something easy like this and very similar to MNIST, I'm stuck on it.</p>\n\n<p>Someone can give me some clue about what is going on? Thanks!</p>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 179}]
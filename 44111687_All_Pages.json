[{"items": [{"tags": ["python", "machine-learning", "tensorflow", "recurrent-neural-network"], "owner": {"user_type": "does_not_exist", "display_name": "user7187569"}, "is_answered": true, "view_count": 942, "accepted_answer_id": 44134322, "answer_count": 1, "score": 1, "last_activity_date": 1495541017, "creation_date": 1495452423, "question_id": 44111687, "content_license": "CC BY-SA 3.0", "link": "https://stackoverflow.com/questions/44111687/tensorflow-reshape-issue-valueerror-cannot-feed-value-of-shape-1-2-for-tens", "title": "Tensorflow reshape issue, ValueError: Cannot feed value of shape (1, 2) for Tensor u&#39;Placeholder:0&#39;, which has shape &#39;(?, 1, 2)&#39;", "body": "<p>I get this error message: \nValueError: Cannot feed value of shape (1, 2) for Tensor u'Placeholder:0', which has shape '(?, 1, 2)'</p>\n\n<p>My training and test data have 2 features </p>\n\n<pre><code>[[10, 10],[1,2],[3,2]...]\n</code></pre>\n\n<p>and my target data are like this:</p>\n\n<pre><code>[[0, 1], [1, 0], [1, 0]...]\n</code></pre>\n\n<p>Here is my code:</p>\n\n<pre><code>training_data = np.vstack(training_data)\ntraining_target = np.vstack(training_target)\ntest_data = np.vstack(test_data)\ntest_target = np.vstack(test_target)\n\nlearning_rate = 0.001\n\nn_input = 2  \nn_steps = 1  \nn_hidden = 128  \nn_classes = 2  \n\n# tf Graph input\nx = tf.placeholder(\"float\", [None, n_steps, n_input])\ny = tf.placeholder(\"float\", [None, n_classes])\n\n# Define weights\nweights = {\n    'out': tf.Variable(tf.random_normal([n_hidden, n_classes]))\n}\nbiases = {\n    'out': tf.Variable(tf.random_normal([n_classes]))\n}\n\ndef RNN(x, weights, biases):\n    x = tf.unstack(x, n_steps, 1)\n\n    # Define a lstm cell with tensorflow\n    lstm_cell = rnn.BasicLSTMCell(n_hidden, forget_bias=1.0)\n\n    # Get lstm cell output\n    outputs, states = rnn.static_rnn(lstm_cell, x, dtype=tf.float32)\n\n    # Linear activation, using rnn inner loop last output\n    return tf.matmul(outputs[-1], weights['out']) + biases['out']\n\npred = RNN(x, weights, biases)\n\n# Define loss and optimizer\ncost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\noptimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n\n# Evaluate model\ncorrect_pred = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\naccuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n\n# Initializing the variables\ninit = tf.global_variables_initializer()\n\n# Launch the graph\nwith tf.Session() as sess:\n    sess.run(init)\n    step = 1\n\n    for i in range(len(training_data)):\n        batch_x = training_data[i]\n        batch_y = training_target[i]\n        print(batch_x)\n        print(batch_y)\n        batch_x = tf.reshape(batch_x, [1, 2]).eval()\n        print(batch_x)\n        sess.run(optimizer, feed_dict={x: batch_x, y: batch_y})\n        acc = sess.run(accuracy, feed_dict={x: batch_x, y: batch_y})\n        loss = sess.run(cost, feed_dict={x: batch_x, y: batch_y})\n        print(\"Iter \" + str(step) + \", Minibatch Loss= \" + \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \"{:.5f}\".format(acc))\n\n    print(\"Optimization Finished!\")\n\n    print(\"Testing Accuracy:\", sess.run(accuracy, feed_dict={x: test_data, y: test_target}))\n</code></pre>\n\n<p>I need help with reshaping, I didn't implement yet next batch function, just trying to get this working.</p>\n\n<p>Didn't include a part where I am loading CSV files,... etc.</p>\n\n<p>Any comment on the code is great, thank you.</p>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 106}]
[{"items": [{"tags": ["python", "opencv", "tensorflow", "gpu", "tensorflow-gpu"], "owner": {"user_type": "does_not_exist", "display_name": "user6092898"}, "is_answered": false, "view_count": 218, "answer_count": 0, "score": 0, "last_activity_date": 1511582690, "creation_date": 1511582690, "question_id": 47482493, "content_license": "CC BY-SA 3.0", "link": "https://stackoverflow.com/questions/47482493/using-entire-gpu-during-realtime-inference", "title": "Using entire gpu during realtime inference", "body": "<p>Im using the following code to do realtime inference from mobilenet</p>\n\n<pre><code>os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n\ncamera = cv2.VideoCapture(0)\n\ncamera.set(3, 1280)\n\ncamera.set(4, 1024)\n\n# Loads label file, strips off carriage return\nlabel_lines = [line.rstrip() for line\n               in tf.gfile.GFile('tf_model/output_labels.txt')]\n\ngpu_options = tf.GPUOptions(allow_growth=True,per_process_gpu_memory_fraction=0.9)\nsess_config = tf.ConfigProto(gpu_options=gpu_options, log_device_placement=False,allow_soft_placement = True)\nsess_config.gpu_options.per_process_gpu_memory_fraction = 0.9\nsess_config.gpu_options.allow_growth=True\n\n\ndef grabVideoFeed():\n    grabbed, frame = camera.read()\n    return frame if grabbed else None\n\n\ndef initialSetup():\n    with tf.device('/gpu:0'):\n        with tf.gfile.FastGFile('tf_model/output_graph.pb', 'rb') as f:\n            graph_def = tf.GraphDef()\n            graph_def.ParseFromString(f.read())\n            tf.import_graph_def(graph_def, name='')\n\n\ninitialSetup()\n\nwith tf.Session(config= sess_config) as sess:\n    softmax_tensor = sess.graph.get_tensor_by_name('final_result:0')\n\n    while True:\n        frame = grabVideoFeed()\n        //do the rest of classification\n</code></pre>\n\n<p>Though I have tried to use gpu, it is still not using the entire gpu. gpu usage is only 8%. how can I be able to sort this out? </p>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 91}]
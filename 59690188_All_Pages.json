[{"items": [{"tags": ["python", "tensorflow", "keras", "neural-network", "tensorflow2.0"], "owner": {"account_id": 15116032, "reputation": 30058, "user_id": 10908375, "user_type": "registered", "profile_image": "https://i.stack.imgur.com/L7f8w.jpg?s=256&g=1", "display_name": "Nicolas Gervais", "link": "https://stackoverflow.com/users/10908375/nicolas-gervais"}, "is_answered": true, "view_count": 4630, "answer_count": 3, "score": 1, "last_activity_date": 1619182455, "creation_date": 1578698319, "last_edit_date": 1619182455, "question_id": 59690188, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/59690188/how-do-i-make-a-multi-output-tensorflow-2-custom-training-loop-for-both-regressi", "title": "How do I make a multi-output Tensorflow 2 custom training loop for both regression and classification?", "body": "<p>I made a minimally reproducible example with the Iris dataset. I made an entire neural network that predicts the last column of the Iris features. I also want to output the target (category). So, the network must minimize two different loss functions (continuous, and categorical). All is set for the continuous target in the next example. But, how do I turn it into a multi-output problem?</p>\n\n<pre><code>import tensorflow as tf\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras import Model\nfrom sklearn.datasets import load_iris\ntf.keras.backend.set_floatx('float64')\niris, target = load_iris(return_X_y=True)\n\nX = iris[:, :3]\ny = iris[:, 3]\nz = target\n\nds = tf.data.Dataset.from_tensor_slices((X, y, z)).batch(8)\n\nclass MyModel(Model):\n    def __init__(self):\n        super(MyModel, self).__init__()\n        self.d0 = Dense(16, activation='relu')\n        self.d1 = Dense(32, activation='relu')\n        self.d2 = Dense(1)\n\n    def call(self, x):\n        x = self.d0(x)\n        x = self.d1(x)\n        x = self.d2(x)\n        return x\n\nmodel = MyModel()\n\nloss_object = tf.keras.losses.MeanAbsoluteError()\noptimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n\nloss = tf.keras.metrics.Mean(name='categorical loss')\nerror = tf.keras.metrics.MeanAbsoluteError()\n\n@tf.function\ndef train_step(inputs, target):\n    with tf.GradientTape() as tape:\n        output = model(inputs)\n        run_loss = loss_object(target, output)\n\n    gradients = tape.gradient(run_loss, model.trainable_variables)\n    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n\n    loss(run_loss)\n    error(target, output)\n\n\nfor epoch in range(50):\n    for xx, yy, zz in ds: # what to do with zz, the categorical target?\n        train_step(xx, yy)\n\n    template = 'Epoch {:&gt;2}, MAE: {:&gt;5.2f}'\n    print(template.format(epoch+1,\n                        loss.result()))\n\n    loss.reset_states()\n    error.reset_states()\n</code></pre>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 250}]
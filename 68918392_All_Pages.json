[{"items": [{"tags": ["optimization", "generative-adversarial-network"], "owner": {"account_id": 22532966, "reputation": 11, "user_id": 16724702, "user_type": "registered", "profile_image": "https://www.gravatar.com/avatar/0da9632684c37d0de799018687f0549d?s=256&d=identicon&r=PG", "display_name": "zahra", "link": "https://stackoverflow.com/users/16724702/zahra"}, "is_answered": false, "view_count": 23, "answer_count": 0, "score": 0, "last_activity_date": 1629875592, "creation_date": 1629875592, "question_id": 68918392, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/68918392/gan-model-no-gradients-provided-for-any-variable", "title": "Gan model: No gradients provided for any variable", "body": "<p>I create Gan model for produce image captioning.\nin this code I want update generator parameter.\nin this code &quot;G&quot; is generator , and &quot;D&quot; is discriminator model\nmy code is:</p>\n<pre><code>def trainFunc():\n# Define the optimizers and the train operations\ndef create_fake_date(input):\n        in_text = 'startseq'\n        for i in range(1, max_length):\n            sequence = tokenizer.texts_to_sequences([in_text])[0]\n            sequence = pad_sequences([sequence], maxlen=max_length)\n            yhat=G([input,sequence])[0]\n            word = tf.math.argmax(yhat)\n            word = word_for_idV2(word, tokenizer)\n            in_text += ' ' + word\n            if word == 'endseq':\n                break\n        fake_data = tokenizer.texts_to_sequences([in_text])[0]\n        fake_data = pad_sequences([fake_data], maxlen=max_length)\n        return fake_data\n            \n\ndef train_step_generaor():\n    \n    opt = tf.keras.optimizers.Adam(1e-5)\n    g_loss_value=lambda:-1*tf.reduce_sum(tf.math.log(tf.math.multiply(output, D([input,create_fake_date(input)]))))\n    var_list_fn = lambda: G.trainable_weights\n    \n    for name in train:\n        print(name)\n        feature=train_features[name].reshape(1,train_features[name].shape[0],\n                                      train_features[name].shape[1],\n                                      train_features[name].shape[2])\n        for desc in train_descriptions[name]:\n            real_data = tf.convert_to_tensor(tokenizer.texts_to_sequences([desc]),dtype=tf.float32)\n            data=[feature,real_data]\n            for input,output in data:\n                 opt.minimize(g_loss_value, var_list_fn)\n\n\ntrain_step_generaor()\n\ntrainFunc()\n</code></pre>\n<p>but when i train this model I got this Error:</p>\n<pre><code>No gradients provided for any variable: ['conv2d/kernel:0', 'conv2d/bias:0', 'conv2d_1/kernel:0', 'conv2d_1/bias:0', 'conv2d_2/kernel:0', 'conv2d_2/bias:0', 'conv2d_3/kernel:0', 'conv2d_3/bias:0', 'embedding/embeddings:0', 'lstm/kernel:0', 'lstm/recurrent_kernel:0', 'lstm/bias:0', 'lstm_1/kernel:0', 'lstm_1/recurrent_kernel:0', 'lstm_1/bias:0', 'dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'lstm_2/kernel:0', 'lstm_2/recurrent_kernel:0', 'lstm_2/bias:0', 'decoder_output/kernel:0', 'decoder_output/bias:0'].\n</code></pre>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 10}]
[{"items": [{"tags": ["tensorflow", "keras", "cosine-similarity", "cross-entropy"], "owner": {"account_id": 12829196, "reputation": 3190, "user_id": 9280994, "user_type": "registered", "profile_image": "https://www.gravatar.com/avatar/378f51f8fdf92e078e0fd52507fed62f?s=256&d=identicon&r=PG&f=1", "display_name": "Jonathan R", "link": "https://stackoverflow.com/users/9280994/jonathan-r"}, "is_answered": true, "view_count": 1180, "accepted_answer_id": 58507052, "answer_count": 1, "score": 0, "last_activity_date": 1571756188, "creation_date": 1571751422, "last_edit_date": 1571751726, "question_id": 58505587, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/58505587/keras-binarycrossentropy-loss-gives-nan-for-angular-distance-between-two-vectors", "title": "Keras BinaryCrossentropy loss gives NaN for angular distance between two vectors", "body": "<p>I want to train a siamese-LSTM such that the angular distance of two outputs is 1 (low similarity) if the corresponding label is 0 and 0 (high similarity) if the label is 1.</p>\n\n<p>I took the formular for angular distance from here: <a href=\"https://en.wikipedia.org/wiki/Cosine_similarity\" rel=\"nofollow noreferrer\">https://en.wikipedia.org/wiki/Cosine_similarity</a></p>\n\n<p>This is my model code:</p>\n\n<pre><code># inputs are unicode encoded int arrays from strings\n# similar string should yield low angular distance\nleft_input = tf.keras.layers.Input(shape=[None, 1], dtype='float32')\nright_input = tf.keras.layers.Input(shape=[None, 1], dtype='float32')\nlstm = tf.keras.layers.LSTM(10)\nleft_embedding = lstm(left_input)\nright_embedding = lstm(right_input)\n# cosine_layer is the operation to get cosine similarity\ncosine_layer = tf.keras.layers.Dot(axes=1, normalize=True)\ncosine_similarity = cosine_layer([left_embedding, right_embedding])\n# next two lines calculate angular distance but with inversed labels\narccos = tf.math.acos(cosine_similarity)\nangular_distance = arccos / math.pi # not 1. - (arccos / math.pi)\nmodel = tf.keras.Model([left_input, right_input], [angular_distance])\nmodel.compile(loss='binary_crossentropy', optimizer='sgd')\nprint(model.summary())\n</code></pre>\n\n<p>The model summary looks fine to me, also when testing with fixed input values I got correct values for my cosine similarity etc.:</p>\n\n<pre><code>Model: \"model_37\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_95 (InputLayer)           [(None, None, 1)]    0                                            \n__________________________________________________________________________________________________\ninput_96 (InputLayer)           [(None, None, 1)]    0                                            \n__________________________________________________________________________________________________\nlstm_47 (LSTM)                  (None, 10)           480         input_95[0][0]                   \n                                                                 input_96[0][0]                   \n__________________________________________________________________________________________________\ndot_47 (Dot)                    (None, 1)            0           lstm_47[0][0]                    \n                                                                 lstm_47[1][0]                    \n__________________________________________________________________________________________________\ntf_op_layer_Acos_52 (TensorFlow [(None, 1)]          0           dot_47[0][0]                     \n__________________________________________________________________________________________________\ntf_op_layer_truediv_37 (TensorF [(None, 1)]          0           tf_op_layer_Acos_52[0][0]        \n__________________________________________________________________________________________________\ntf_op_layer_sub_20 (TensorFlowO [(None, 1)]          0           tf_op_layer_truediv_37[0][0]     \n__________________________________________________________________________________________________\ntf_op_layer_sub_21 (TensorFlowO [(None, 1)]          0           tf_op_layer_sub_20[0][0]         \n__________________________________________________________________________________________________\ntf_op_layer_Abs (TensorFlowOpLa [(None, 1)]          0           tf_op_layer_sub_21[0][0]         \n==================================================================================================\nTotal params: 480\nTrainable params: 480\nNon-trainable params: 0\n__________________________________________________________________________________________________\nNone\n</code></pre>\n\n<p>But upon training I always get a loss of NaN</p>\n\n<pre><code>model.fit([np.array(x_left_train), np.array(x_right_train)], np.array(y_train).reshape((-1,1)), batch_size=1, epochs=2, validation_split=0.1)\n\nTrain on 14400 samples, validate on 1600 samples\nEpoch 1/2\n  673/14400 [&gt;.............................] - ETA: 5:42 - loss: nan\n</code></pre>\n\n<p>Is this not the correct way to get the similarity between two vectors and training my network to produce those vectors?</p>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 30}]
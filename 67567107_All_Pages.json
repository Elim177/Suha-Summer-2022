[{"items": [{"tags": ["python", "tensorflow", "keras"], "owner": {"account_id": 14181828, "reputation": 41, "user_id": 10245130, "user_type": "registered", "profile_image": "https://www.gravatar.com/avatar/3574bcc1e27082f316d971821f8b4f8f?s=256&d=identicon&r=PG&f=1", "display_name": "R.Ahuja", "link": "https://stackoverflow.com/users/10245130/r-ahuja"}, "is_answered": false, "view_count": 75, "answer_count": 0, "score": 0, "last_activity_date": 1621254126, "creation_date": 1621243524, "last_edit_date": 1621254126, "question_id": 67567107, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/67567107/saving-sub-class-models-on-tf-2-x", "title": "Saving Sub Class Models on TF 2.x", "body": "<p>I have trained a Sub-Class Retinanet model for Object detection. Now I want to save this model so that I can send it to someone who does not have access to model architecture, in case of Sequential model we just save the model as &quot;.h5&quot; file and we can send it to anyone we want. Is there any such. thing for custom models in TF 2.x? The code snippet for the custom class model is as follows:</p>\n<pre><code>def get_backbone():\n    &quot;&quot;&quot;Builds ResNet50 with pre-trained imagenet weights&quot;&quot;&quot;\n    backbone = keras.applications.ResNet50(\n        include_top=False, input_shape=[None, None, 3]\n    )\n    c3_output, c4_output, c5_output = [\n        backbone.get_layer(layer_name).output\n        for layer_name in [&quot;conv3_block4_out&quot;, &quot;conv4_block6_out&quot;, &quot;conv5_block3_out&quot;]\n    ]\n    return keras.Model(\n        inputs=[backbone.inputs], outputs=[c3_output, c4_output, c5_output]\n    )\n\nclass FeaturePyramid(keras.layers.Layer):\n    &quot;&quot;&quot;Builds the Feature Pyramid with the feature maps from the backbone.\n\n    Attributes:\n      num_classes: Number of classes in the dataset.\n      backbone: The backbone to build the feature pyramid from.\n        Currently supports ResNet50 only.\n    &quot;&quot;&quot;\n\n    def __init__(self, backbone=None, **kwargs):\n        super(FeaturePyramid, self).__init__(name=&quot;FeaturePyramid&quot;, **kwargs)\n        self.backbone = backbone if backbone else get_backbone()\n        self.conv_c3_1x1 = keras.layers.Conv2D(256, 1, 1, &quot;same&quot;)\n        self.conv_c4_1x1 = keras.layers.Conv2D(256, 1, 1, &quot;same&quot;)\n        self.conv_c5_1x1 = keras.layers.Conv2D(256, 1, 1, &quot;same&quot;)\n        self.conv_c3_3x3 = keras.layers.Conv2D(256, 3, 1, &quot;same&quot;)\n        self.conv_c4_3x3 = keras.layers.Conv2D(256, 3, 1, &quot;same&quot;)\n        self.conv_c5_3x3 = keras.layers.Conv2D(256, 3, 1, &quot;same&quot;)\n        self.conv_c6_3x3 = keras.layers.Conv2D(256, 3, 2, &quot;same&quot;)\n        self.conv_c7_3x3 = keras.layers.Conv2D(256, 3, 2, &quot;same&quot;)\n        self.upsample_2x = keras.layers.UpSampling2D(2)\n\n    def call(self, images, training=False):\n        c3_output, c4_output, c5_output = self.backbone(images, training=training)\n        p3_output = self.conv_c3_1x1(c3_output)\n        p4_output = self.conv_c4_1x1(c4_output)\n        p5_output = self.conv_c5_1x1(c5_output)\n        p4_output = p4_output + self.upsample_2x(p5_output)\n        p3_output = p3_output + self.upsample_2x(p4_output)\n        p3_output = self.conv_c3_3x3(p3_output)\n        p4_output = self.conv_c4_3x3(p4_output)\n        p5_output = self.conv_c5_3x3(p5_output)\n        p6_output = self.conv_c6_3x3(c5_output)\n        p7_output = self.conv_c7_3x3(tf.nn.relu(p6_output))\n        return p3_output, p4_output, p5_output, p6_output, p7_output\ndef build_head(output_filters, bias_init):\n    &quot;&quot;&quot;Builds the class/box predictions head.\n\n    Arguments:\n      output_filters: Number of convolution filters in the final layer.\n      bias_init: Bias Initializer for the final convolution layer.\n\n    Returns:\n      A keras sequential model representing either the classification\n        or the box regression head depending on `output_filters`.\n    &quot;&quot;&quot;\n    head = keras.Sequential([keras.Input(shape=[None, None, 256])])\n    kernel_init = tf.initializers.RandomNormal(0.0, 0.01)\n    for _ in range(4):\n        head.add(\n            keras.layers.Conv2D(256, 3, padding=&quot;same&quot;, kernel_initializer=kernel_init)\n        )\n        head.add(keras.layers.ReLU())\n    head.add(\n        keras.layers.Conv2D(\n            output_filters,\n            3,\n            1,\n            padding=&quot;same&quot;,\n            kernel_initializer=kernel_init,\n            bias_initializer=bias_init,\n        )\n    )\n    return head\nclass RetinaNet(keras.Model):\n    &quot;&quot;&quot;A subclassed Keras model implementing the RetinaNet architecture.\n\n    Attributes:\n      num_classes: Number of classes in the dataset.\n      backbone: The backbone to build the feature pyramid from.\n        Currently supports ResNet50 only.\n    &quot;&quot;&quot;\n\n    def __init__(self, num_classes, backbone=None, **kwargs):\n        super(RetinaNet, self).__init__(name=&quot;RetinaNet&quot;, **kwargs)\n        self.fpn = FeaturePyramid(backbone)\n        self.num_classes = num_classes\n\n        prior_probability = tf.constant_initializer(-np.log((1 - 0.01) / 0.01))\n        self.cls_head = build_head(9 * num_classes, prior_probability)\n        self.box_head = build_head(9 * 4, &quot;zeros&quot;)\n\n    def call(self, image, training=False):\n        features = self.fpn(image, training=training)\n        N = tf.shape(image)[0]\n        cls_outputs = []\n        box_outputs = []\n        for feature in features:\n            box_outputs.append(tf.reshape(self.box_head(feature), [N, -1, 4]))\n            cls_outputs.append(\n                tf.reshape(self.cls_head(feature), [N, -1, self.num_classes])\n            )\n        cls_outputs = tf.concat(cls_outputs, axis=1)\n        box_outputs = tf.concat(box_outputs, axis=1)\n        return tf.concat([box_outputs, cls_outputs], axis=-1)\n    def get_config(self):\n        return {&quot;a&quot;: self.fpn, &quot;b&quot;: self.num_classes, &quot;c&quot;: self.cls_head,\n                &quot;d&quot;: self.box_head}\n    @classmethod\n    def from_config(cls, config):\n        return cls(**config)\nresnet50_backbone = get_backbone()\nloss_fn = RetinaNetLoss(num_classes)\nmodel = RetinaNet(num_classes, resnet50_backbone)\n\noptimizer = tf.optimizers.SGD(learning_rate=learning_rate_fn, momentum=0.9)\nmodel.compile(loss=loss_fn, optimizer=optimizer)\n\ncallbacks_list = [\n    tf.keras.callbacks.ModelCheckpoint(\n        filepath=os.path.join(model_dir, &quot;weights&quot; + &quot;_epoch_{epoch}&quot;),\n        monitor=&quot;loss&quot;,\n        save_best_only=False,\n        save_weights_only=True,\n        verbose=1,\n    )\n]\n\nwith tf.device('/gpu:0'):\n  model.fit(\n      train_dataset.take(100),\n      validation_data=val_dataset.take(50),\n      epochs=epochs,\n      callbacks=callbacks_list,\n      verbose=1,\n  )\n'\n</code></pre>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 143}]
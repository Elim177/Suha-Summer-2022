[{"items": [{"tags": ["python", "tensorflow", "optimization"], "owner": {"account_id": 17093612, "reputation": 21, "user_id": 12369141, "user_type": "registered", "profile_image": "https://www.gravatar.com/avatar/4ca11d6d8d407502fb95b6abf42be8d1?s=256&d=identicon&r=PG&f=1", "display_name": "Fabio", "link": "https://stackoverflow.com/users/12369141/fabio"}, "is_answered": true, "view_count": 1364, "answer_count": 1, "score": 1, "last_activity_date": 1579981365, "creation_date": 1578840611, "last_edit_date": 1579979805, "question_id": 59704981, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/59704981/tensorflow-slow-performances-using-tf-data-dataset", "title": "Tensorflow slow performances using tf.data.Dataset", "body": "<p>I have implemented a simple trainer class in tensorflow. I am running some experiments to check code performances, but I am having problems understanding what is happening under the hood of <strong>tf.data.Dataset</strong> and <strong>tf.function</strong>.</p>\n\n<p>In the following I am going present the tests that I have ran and in the end there will be some questions about the results that I got.</p>\n\n<p>Configuration: Intel i3 cpu, tensorflow-cpu 2.1</p>\n\n<pre><code>class Trainer:\n    def __init__(self, model, optimizer, loss):\n        self.model = model\n        self.loss_function = loss\n        self.optimizer = optimizer\n\n    @tf.function\n    def train_step(self, inputs, targets):\n        with tf.GradientTape() as tape:\n            predictions = self.model(inputs)\n            loss = self.loss_function(targets, predictions)\n        gradients = tape.gradient(loss, self.model.trainable_variables)\n        self.optimizer.apply_gradients(zip(gradients, self.model.trainable_variables))\n        return loss\n\n    # fit using dataset\n    @tf.function\n    def fit0(self, dataset, epochs):\n        for epoch in tf.range(epochs):\n            for input_batch, target_batch in dataset:\n                self.train_step(input_batch, target_batch)\n\n    # fit using list of tensors\n    @tf.function\n    def fit1(self, inputs, targets, epochs):\n        for epoch in tf.range(epochs):\n            for input_batch, target_batch in zip(inputs, targets):\n                self.train_step(input_batch, target_batch)\n</code></pre>\n\n<p>In the following <strong>train_step</strong> will always be wrapped in <strong>tf.function</strong>.</p>\n\n<p><strong>fit0</strong>, <strong>fit1</strong> will be tested with and without <strong>tf.function</strong>.</p>\n\n<p>Here the code that I run the tests with:</p>\n\n<pre><code>input_size = 10000\nbatch_size = 100\nq = input_size // batch_size\n\n# create random inputs (x) and outputs (y)\nx = tf.random.normal((input_size, 1), dtype=tf.float32)\ny = tf.random.normal((input_size, 1), dtype=tf.float32)\n\nsplits = tf.fill([q, ], batch_size)\n\n# create a list of tensors rappresenting batches\nx_list = tf.split(x, splits)\ny_list = tf.split(y, splits)\n\n# create datasets in the different ways\ndataset0 = tf.data.Dataset.from_tensor_slices((x, y)).batch(batch_size)\ndataset1 = tf.data.Dataset.from_tensor_slices((tf.stack(x_list), tf.stack(y_list)))\n\n# model definition\nmodel = tf.keras.Sequential([\n    tf.keras.layers.Dense(20, activation='tanh', input_shape=(1,)),\n    tf.keras.layers.Dense(1, activation='linear')])\n\n# trainer initialization\ntrainer = Trainer(model=model, optimizer=tf.keras.optimizers.Adam(), loss=tf.keras.losses.MeanSquaredError())\n\n# first run to perform initializations\ntime0 = time.time()\ntrainer.fit0(dataset=dataset0, epochs=tf.constant(1, dtype=tf.int32))\ntime0 = time.time() - time0\n\ntime1 = time.time()\ntrainer.fit0(dataset=dataset1, epochs=tf.constant(1, dtype=tf.int32))\ntime1 = time.time() - time1\n\ntime2 = time.time()\ntrainer.fit1(inputs=x_list, targets=y_list, epochs=tf.constant(1, dtype=tf.int32))\ntime2 = time.time() - time2\n\nprint(\"first fit0 with dataset0 took {} seconds\".format(time0))\nprint(\"first fit0 with dataset1 took {} seconds\".format(time1))\nprint(\"first fit1 with tensorlist took {} seconds\".format(time2))\n\n# measure performances\ntime0 = time.time()\ntrainer.fit0(dataset=dataset0, epochs=tf.constant(100, dtype=tf.int32))\ntime0 = time.time() - time0\n\ntime1 = time.time()\ntrainer.fit0(dataset=dataset1, epochs=tf.constant(100, dtype=tf.int32))\ntime1 = time.time() - time1\n\ntime2 = time.time()\ntrainer.fit1(inputs=x_list, targets=y_list, epochs=tf.constant(100, dtype=tf.int32))\ntime2 = time.time() - time2\n\nprint(\"fit0 with dataset0 took {} seconds\".format(time0))\nprint(\"fit0 with dataset1 took {} seconds\".format(time1))\nprint(\"fit1 with tensorlist took {} seconds\".format(time2))\n</code></pre>\n\n<p>Here the test results:</p>\n\n<p>The first test is with 100 batches of 100 samples each.</p>\n\n<blockquote>\n  <p>input_size = 10000<br>\n  batch_size = 100  </p>\n  \n  <p>without @tf.function:<br>\n  first fit0 with dataset0 took 0.9953532218933105 seconds<br>\n  first fit0 with dataset1 took 0.07995295524597168 seconds<br>\n  first fit1 with tensorlist took 0.05196571350097656 seconds<br>\n  fit0 with dataset0 took 10.46957802772522 seconds<br>\n  fit0 with dataset1 took 7.822799205780029 seconds<br>\n  fit1 with tensorlist took 4.650130748748779 seconds  </p>\n  \n  <p>with @tf.function:<br>\n  first fit0 with dataset0 took 1.4042332172393799 seconds<br>\n  first fit0 with dataset1 took 0.46071624755859375 seconds<br>\n  first fit1 with tensorlist took 7.3524699211120605 seconds<br>\n  fit0 with dataset0 took 15.077088832855225 seconds<br>\n  fit0 with dataset1 took 9.136569738388062 seconds<br>\n  fit1 with tensorlist took 2.1366817951202393 seconds</p>\n</blockquote>\n\n<p>The second one is with 1 batch of 100000 samples.</p>\n\n<blockquote>\n  <p>input_size = 100000<br>\n  batch_size = 100000  </p>\n  \n  <p>without @tf.function:<br>\n  first fit0 with dataset0 took 1.1792669296264648 seconds<br>\n  first fit0 with dataset1 took 0.027983427047729492 seconds<br>\n  first fit1 with tensorlist took 0.020987749099731445 seconds<br>\n  fit0 with dataset0 took 28.71895956993103 seconds<br>\n  fit0 with dataset1 took 2.730872869491577 seconds<br>\n  fit1 with tensorlist took 2.194814682006836 seconds  </p>\n  \n  <p>with @tf.function:<br>\n  first fit0 with dataset0 took 1.5979444980621338 seconds<br>\n  first fit0 with dataset1 took 0.4557182788848877 seconds<br>\n  first fit1 with tensorlist took 0.3708038330078125 seconds<br>\n  fit0 with dataset0 took 36.43854784965515 seconds<br>\n  fit0 with dataset1 took 9.819332122802734 seconds<br>\n  fit1 with tensorlist took 2.1136972904205322 seconds  </p>\n</blockquote>\n\n<p>Questions:</p>\n\n<ol>\n<li>Why does <strong>tf.data.Dataset</strong> provide worst performances when wrapped with <strong>tf.function</strong>?</li>\n<li>Even if dataset0 and dataset1 are functionally equivalent. What are the under-the-hood differences between the two? Why is dataset1 performing better than dataset0?</li>\n<li><strong>fit1</strong> with <strong>tf.function</strong> got the best long-run performances.  \n\n<ul>\n<li>Is it possible to achieve the same performance using <strong>tf.data.Dataset</strong>?  </li>\n<li>Why is it taking so much time for the initialization?<br>\nWhen using 100 batches the first run took 7.3524699211120605 seconds and this time increase by increasing the number of batches.<br>\nI guess is because autograph is creating a bigger graph, unrolling the computation of the different batches. I do not see any opportunity for parallelization though, because each batch is dependent on the result of the previous one.</li>\n</ul></li>\n</ol>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 35}]
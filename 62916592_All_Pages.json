[{"items": [{"tags": ["tensorflow", "deep-learning", "loss-function"], "owner": {"account_id": 13492482, "reputation": 437, "user_id": 9734248, "user_type": "registered", "profile_image": "https://www.gravatar.com/avatar/c8fd8584be5278402a0034f62976afbe?s=256&d=identicon&r=PG&f=1", "display_name": "DY92", "link": "https://stackoverflow.com/users/9734248/dy92"}, "is_answered": true, "view_count": 363, "accepted_answer_id": 62917321, "answer_count": 1, "score": 0, "last_activity_date": 1594823521, "creation_date": 1594821401, "last_edit_date": 1594822668, "question_id": 62916592, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/62916592/loss-function-for-sequences-in-tensorflow-2-0", "title": "Loss function for sequences (in Tensorflow 2.0)", "body": "<p>I am working on the problem of sentence translation from english into german.\nSo the final output is a german sequence and I need to check how good are my predictions.</p>\n<p>I have found in tensorflow tutorial the following loss function:</p>\n<pre><code>loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n\ndef loss_function(real, pred):\n    mask = tf.math.logical_not(tf.math.equal(real, 0))\n    loss_ = loss_object(real, pred)\n\n    mask = tf.cast(mask, dtype=loss_.dtype)\n    loss_ *= mask\n\n    return tf.reduce_mean(loss_)\n</code></pre>\n<p>But I don't know what this function does. I know(maybe I am wrong) that we cannot use SparseCategoricalCrossentropy for  sequences in a straightforward manner and we have to do some kind of manipulations.\nBut for example in the code above I see, that SparseCategoricalCrossentropy was used in straightforward manner on a sequence output. Why?</p>\n<p>What does <code>mask</code> variable do?\nCan you explain the code?</p>\n<p><strong>EDIT:</strong> tutorial- <a href=\"https://www.tensorflow.org/tutorials/text/nmt_with_attention\" rel=\"nofollow noreferrer\">https://www.tensorflow.org/tutorials/text/nmt_with_attention</a></p>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 5}]
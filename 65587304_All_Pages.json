[{"items": [{"tags": ["keras", "dataset", "generator", "tensorflow2.0", "python-3.8"], "owner": {"account_id": 17631532, "reputation": 35, "user_id": 13429645, "user_type": "registered", "profile_image": "https://www.gravatar.com/avatar/2c74e5addc4be4fec982164e1af212c7?s=256&d=identicon&r=PG&f=1", "display_name": "Poofy38", "link": "https://stackoverflow.com/users/13429645/poofy38"}, "is_answered": false, "view_count": 107, "answer_count": 0, "score": 0, "last_activity_date": 1609954476, "creation_date": 1609884602, "last_edit_date": 1609954476, "question_id": 65587304, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/65587304/your-input-ran-out-of-data-always-at-step-of-epochs", "title": "&quot;Your input ran out of data&quot; always at step # of epochs", "body": "<p>I have been trying to make my first data generator for a model.fit() with Keras. The dataset I'm trying to make has two inputs, an image and a float value. All of my image names and values are stored in a csv file. I believe I made my generator incorrectly because <strong>no matter what my batch size is, I always get the error &quot;Your input ran out of data&quot; at the step equal to my epochs</strong>. So if my epochs are set to 100 my model will run until it reaches step 100. My dataset is about 100000 images/values big. If anyone could help me find a solution that would be great.<br />\nI am currently using:<br />\npython 3.8<br />\ntf-gpu 2.4.0rc1<br />\nkeras 2.4.3<br />\npandas 1.1.4</p>\n<p>Code:</p>\n<pre><code>IMG_SIZE = 400\nVersion = 1\nbatch_size = 64\nval = .05\n\nval_aug = ImageDataGenerator(rescale=1/255)\naug = ImageDataGenerator(\n        rescale=1/255, \n        rotation_range=30, \n        width_shift_range=0.1, \n        height_shift_range=0.1, \n        shear_range=0.2, \n        zoom_range=0.2, \n        channel_shift_range=25, \n        horizontal_flip=True, \n        fill_mode='constant')\n\n\ndf = pd.read_csv('F:/DATA/Vote/Vote_Age.csv')\n\ndf = df.sample(frac = 1)\ncut = int(len(df) * val)\n\ntrain_df = df[cut:]\nval_df = df[0:cut]\nprint(f'Training dataset: {len(train_df)}')\nprint(f'Val dataset: {len(val_df)}')\n\ntrain_steps = int(len(train_df) / batch_size)\nval_steps = int(len(val_df) / batch_size)\n\ndef data(df, generator, batch_size, IMG_SIZE):\n        z = 0\n        while True:\n                df = df.sample(frac = 1)\n                for i in range(int(len(df) / batch_size)):\n                        images, ages, votes = [], [], []\n                        for x in range(batch_size):\n                                csv_row = df.iloc[(z), :]\n                                z += 1\n                                image_path = f'F:/DATA/Vote/Images/{int(csv_row[0])}.jpg'\n                                image = cv2.resize(cv2.imread(image_path), (int(IMG_SIZE), int(IMG_SIZE)))\n                                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n                                image = image.reshape(-1, IMG_SIZE, IMG_SIZE, 3)\n                                generator.fit(image)\n                                image = generator.flow(image, batch_size=1)\n                                image = image.next()\n                                image = image.reshape(IMG_SIZE, IMG_SIZE, 3)\n\n                                images.append(image)\n                                ages.append(csv_row[1])\n                                votes.append(int(csv_row[2]))\n\n                        images = np.array(images)\n                        ages = np.array(ages)\n                        votes = np.array(votes)\n                \n                        return [[images, ages], [votes]]\n\n#########\n#Model was very big and unnecessary to include\n#########\n\ntrain_dataset = train_data(train_df, batch_size, IMG_SIZE)\nval_dataset = val_data(val_df, batch_size, IMG_SIZE)\n\nmodel.fit(\n    x = train_dataset[0],\n    y = train_dataset[1],\n    validation_data=(val_dataset[0], val_dataset[1]),\n    steps_per_epoch=train_steps,\n    validation_steps=val_steps,\n    callbacks=earlyStop,\n    epochs=100, batch_size=batch_size,\n    workers=multiprocessing.cpu_count(),\n    verbose=1)\n\nmodel.save(f'F:/DATA/Vote/Models/YiffModel{Version}')\n</code></pre>\n<p>Ouput:</p>\n<pre><code>...\n  83/1484 [&gt;.............................] - ETA: 4:46 - loss: 7578.7731\n  84/1484 [&gt;.............................] - ETA: 4:46 - loss: 7575.5172\n  85/1484 [&gt;.............................] - ETA: 4:46 - loss: 7572.2818\n  86/1484 [&gt;.............................] - ETA: 4:46 - loss: 7569.0662\n  87/1484 [&gt;.............................] - ETA: 4:46 - loss: 7565.8702\n  88/1484 [&gt;.............................] - ETA: 4:45 - loss: 7562.6932\n  89/1484 [&gt;.............................] - ETA: 4:45 - loss: 7559.5349\n  90/1484 [&gt;.............................] - ETA: 4:45 - loss: 7556.3948\n  91/1484 [&gt;.............................] - ETA: 4:45 - loss: 7553.2726\n  92/1484 [&gt;.............................] - ETA: 4:44 - loss: 7550.1679\n  93/1484 [&gt;.............................] - ETA: 4:44 - loss: 7547.0802\n  94/1484 [&gt;.............................] - ETA: 4:44 - loss: 7544.0094\n  95/1484 [&gt;.............................] - ETA: 4:44 - loss: 7540.9549\n  96/1484 [&gt;.............................] - ETA: 4:43 - loss: 7537.9164\n  97/1484 [&gt;.............................] - ETA: 4:43 - loss: 7534.8937\n  98/1484 [&gt;.............................] - ETA: 4:43 - loss: 7531.8863\n  99/1484 [=&gt;............................] - ETA: 4:43 - loss: 7528.8939\n 100/1484 [=&gt;............................] - ETA: 4:43 - loss: 7525.9163\nWARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 148400 batches). You may need to use the repeat() function when building your dataset.\nWARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 78 batches). You may need to use the repeat() function when building your dataset.\n\n1484/1484 [==============================] - 30s 15ms/step - loss: 7250.9988 - val_loss: 13595.9355\nC:\\Users\\Tristan\\anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:2325: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n  warnings.warn('`Model.state_updates` will be removed in a future version. '\n2021-01-05 15:37:04.425018: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\nC:\\Users\\Tristan\\anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:1402: UserWarning: `layer.updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n  warnings.warn('`layer.updates` will be removed in a future version. '\nWARNING:tensorflow:FOR KERAS USERS: The object that you are saving contains one or more Keras models or layers. If you are loading the SavedModel with `tf.keras.models.load_model`, continue reading (otherwise, you may ignore the following instructions). Please change your code to save with `tf.keras.models.save_model` or `model.save`, and confirm that the file &quot;keras.metadata&quot; exists in the export directory. In the future, Keras will only load the SavedModels that have this file. In other words, `tf.saved_model.save` will no longer write SavedModels that can be recovered as Keras models (this will apply in TF 2.5).\n\nFOR DEVS: If you are overwriting _tracking_metadata in your class, this property has been used to save metadata in the SavedModel. The metadta field will be deprecated soon, so please move the metadata to a different file.\nlibpng warning: iCCP: known incorrect sRGB profile\n</code></pre>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 235}]
[{"items": [{"tags": ["python-3.x", "tensorflow", "deep-learning", "tf.keras"], "owner": {"user_type": "does_not_exist", "display_name": "user9614033"}, "is_answered": true, "view_count": 69, "answer_count": 1, "score": 0, "last_activity_date": 1605768359, "creation_date": 1605706040, "question_id": 64894027, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/64894027/implementing-wide-and-deep-neural-network-using-functional-api", "title": "Implementing Wide and Deep Neural Network using Functional API", "body": "<p>I am trying to build a Wide and Deep Neural Network using Keras Functional API. I am getting a value to shape mismatch error. I don't understand where I am wrong. I am implementing this on the Fashion MNIST dataset.The X_train shape is (60000,28,28) and Y_train is (60000,). I am guessing that the error is because of the line : input_ = keras.layers.... but I don't understand how to resolve it.</p>\n<p>Code :</p>\n<pre><code># Building a Non Sequnetial Model using Functional API One Use of it is in Wide and Deep Neural Networks\ninput_ = keras.layers.Input(shape=X_train.shape[1:])  # This will return shape of the input [28,28],remeber we dont have to set it to the number of neurons in the layer\n\nhidden1 = keras.layers.Dense(100,activation = &quot;relu&quot;)(input_)  # We have to call it as a function\nhidden2 = keras.layers.Dense(100,activation = &quot;relu&quot;)(hidden1)\nconcat_layer = keras.layers.concatenate([input_,hidden2])\noutput = keras.layers.Dense(10,activation=&quot;softmax&quot;)(concat_layer)\nmodel = keras.models.Model(inputs=[input_], outputs=[output])\n\nmodel.compile(loss = keras.losses.sparse_categorical_crossentropy,optimizer = keras.optimizers.SGD(lr = 0.8),metrics= [&quot;accuracy&quot;])\nTensorboard_cb = keras.callbacks.TensorBoard(Path_Tensor)\nmodel.fit(X_train,Y_train,validation_split=0.2,epochs=100,callbacks=[Tensorboard_cb])\n</code></pre>\n<p>Error :</p>\n<pre><code>Epoch 1/100\n---------------------------------------------------------------------------\nValueError                                Traceback (most recent call last)\n&lt;ipython-input-97-675a2b302d27&gt; in &lt;module&gt;\n----&gt; 1 model.fit(X_train,Y_train,validation_split=0.2,epochs=100,callbacks=[Tensorboard_cb])\n\nc:\\users\\na462\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py in _method_wrapper(self, *args, **kwargs)\n    106   def _method_wrapper(self, *args, **kwargs):\n    107     if not self._in_multi_worker_mode():  # pylint: disable=protected-access\n--&gt; 108       return method(self, *args, **kwargs)\n    109 \n    110     # Running inside `run_distribute_coordinator` already.\n\nc:\\users\\na462\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\n   1096                 batch_size=batch_size):\n   1097               callbacks.on_train_batch_begin(step)\n-&gt; 1098               tmp_logs = train_function(iterator)\n   1099               if data_handler.should_sync:\n   1100                 context.async_wait()\n\nc:\\users\\na462\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py in __call__(self, *args, **kwds)\n    778       else:\n    779         compiler = &quot;nonXla&quot;\n--&gt; 780         result = self._call(*args, **kwds)\n    781 \n    782       new_tracing_count = self._get_tracing_count()\n\nc:\\users\\na462\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py in _call(self, *args, **kwds)\n    821       # This is the first call of __call__, so we have to initialize.\n    822       initializers = []\n--&gt; 823       self._initialize(args, kwds, add_initializers_to=initializers)\n    824     finally:\n    825       # At this point we know that the initialization is complete (or less\n\nc:\\users\\na462\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py in _initialize(self, args, kwds, add_initializers_to)\n    695     self._concrete_stateful_fn = (\n    696         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n--&gt; 697             *args, **kwds))\n    698 \n    699     def invalid_creator_scope(*unused_args, **unused_kwds):\n\nc:\\users\\na462\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\function.py in _get_concrete_function_internal_garbage_collected(self, *args, **kwargs)\n   2853       args, kwargs = None, None\n   2854     with self._lock:\n-&gt; 2855       graph_function, _, _ = self._maybe_define_function(args, kwargs)\n   2856     return graph_function\n   2857 \n\nc:\\users\\na462\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\function.py in _maybe_define_function(self, args, kwargs)\n   3211 \n   3212       self._function_cache.missed.add(call_context_key)\n-&gt; 3213       graph_function = self._create_graph_function(args, kwargs)\n   3214       self._function_cache.primary[cache_key] = graph_function\n   3215       return graph_function, args, kwargs\n\nc:\\users\\na462\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\function.py in _create_graph_function(self, args, kwargs, override_flat_arg_shapes)\n   3073             arg_names=arg_names,\n   3074             override_flat_arg_shapes=override_flat_arg_shapes,\n-&gt; 3075             capture_by_value=self._capture_by_value),\n   3076         self._function_attributes,\n   3077         function_spec=self.function_spec,\n\nc:\\users\\na462\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\n    984         _, original_func = tf_decorator.unwrap(python_func)\n    985 \n--&gt; 986       func_outputs = python_func(*func_args, **func_kwargs)\n    987 \n    988       # invariant: `func_outputs` contains only Tensors, CompositeTensors,\n\nc:\\users\\na462\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py in wrapped_fn(*args, **kwds)\n    598         # __wrapped__ allows AutoGraph to swap in a converted function. We give\n    599         # the function a weak reference to itself to avoid a reference cycle.\n--&gt; 600         return weak_wrapped_fn().__wrapped__(*args, **kwds)\n    601     weak_wrapped_fn = weakref.ref(wrapped_fn)\n    602 \n\nc:\\users\\na462\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py in wrapper(*args, **kwargs)\n    971           except Exception as e:  # pylint:disable=broad-except\n    972             if hasattr(e, &quot;ag_error_metadata&quot;):\n--&gt; 973               raise e.ag_error_metadata.to_exception(e)\n    974             else:\n    975               raise\n\nValueError: in user code:\n\n    c:\\users\\na462\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:806 train_function  *\n        return step_function(self, iterator)\n    c:\\users\\na462\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:796 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    c:\\users\\na462\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    c:\\users\\na462\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    c:\\users\\na462\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    c:\\users\\na462\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:789 run_step  **\n        outputs = model.train_step(data)\n    c:\\users\\na462\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:749 train_step\n        y, y_pred, sample_weight, regularization_losses=self.losses)\n    c:\\users\\na462\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\compile_utils.py:204 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    c:\\users\\na462\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:149 __call__\n        losses = ag_call(y_true, y_pred)\n    c:\\users\\na462\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:253 call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    c:\\users\\na462\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    c:\\users\\na462\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:1567 sparse_categorical_crossentropy\n        y_true, y_pred, from_logits=from_logits, axis=axis)\n    c:\\users\\na462\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    c:\\users\\na462\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py:4783 sparse_categorical_crossentropy\n        labels=target, logits=output)\n    c:\\users\\na462\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    c:\\users\\na462\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py:4176 sparse_softmax_cross_entropy_with_logits_v2\n        labels=labels, logits=logits, name=name)\n    c:\\users\\na462\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    c:\\users\\na462\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py:4091 sparse_softmax_cross_entropy_with_logits\n        logits.get_shape()))\n\n    ValueError: Shape mismatch: The shape of labels (received (32, 1)) should equal the shape of logits except for the last dimension (received (32, 28, 10)).\n</code></pre>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 36}]
[{"items": [{"tags": ["machine-learning", "tensorflow2.0", "gradient-descent"], "owner": {"account_id": 5381416, "reputation": 649, "user_id": 4286538, "user_type": "registered", "profile_image": "https://www.gravatar.com/avatar/79b2c03e63e36b5a3ff2a516754075fe?s=256&d=identicon&r=PG&f=1", "display_name": "MrWombat", "link": "https://stackoverflow.com/users/4286538/mrwombat"}, "is_answered": true, "view_count": 385, "answer_count": 1, "score": 0, "last_activity_date": 1610466353, "creation_date": 1580225924, "question_id": 59952204, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/59952204/tensorflow-2-second-order-derivative-after-applied-gradients-in-eager-execution", "title": "Tensorflow 2 second order derivative after applied gradients in eager execution", "body": "<p>I am trying to implement Model Agnostic Meta Learning (MAML) in Tensorflow 2. \nFor this algorithm a second order derivative is calculated in the form: </p>\n\n<pre><code>for multiple sets, each with an individual model:\n  1. Determine the loss for a training set\n  2. Determine the gradients for this loss w.r.t. the model\n  3. Apply the gradients (theta' &lt;- theta-alpha*gradients)\n\n4. Determine the loss for an evaluation set for each of the updated models\n5. Determine the gradient of the sum of the losses (4) w.r.t. the global model\n</code></pre>\n\n<p>I am trying to implement this in tensorflow 2 with <code>GradientTape</code> but the second gradient is always an array of <code>None</code>s.</p>\n\n<p>My implementation looks like this:</p>\n\n<pre class=\"lang-py prettyprint-override\"><code>with tf.GradientTape() as meta_update_tape:\n    # inner loop (for all tasks)\n    for bi in range(batch_size):\n\n       # the training and evaluation batches\n       x_i, y_i, x_i_prime, y_i_prime = dataset.batch_with_eval()\n\n       # reset the weights to to current global weights before training for this batch\n       model_copy = copy_model_weights(source=model, target=model_copy)\n\n       # Compute loss using theta_global for D_i\n       with tf.GradientTape() as inner_update_tape:\n           inner_loss, _, _ = compute_loss(model_copy, x_i, y_i)\n\n       gradients_inner_update = inner_update_tape.gradient(inner_loss, model_copy.trainable_variables)\n\n       # update model parameters (apply theta_i_prime)\n       # inner_optimizer.apply_gradients(zip(gradients_inner_update, model_copy.trainable_variables))\n       conv_layers  = [i for i,var in enumerate(model_copy.trainable_variables) if var.name.startswith('conv2d')]\n       for layer in conv_layers:\n           model_copy.trainable_variables[layer].assign(tf.subtract(model.trainable_variables[layer], tf.multiply(0.4, gradients_inner_update[layer])))\n\n       # calculate loss with theta_i_prime with eval set\n       loss_eval, accuracy_eval, _ = compute_loss(model_copy, x_i_prime, y_i_prime)\n\n       batch_losses.append(loss_eval)\n\n   sum_losses = tf.reduce_sum(batch_losses) / tf.cast(batch_size, dtype=tf.float32)\n\n# calculate gradient over all losses w.r.t global theta (trainable variables for global model)\ngradients_meta_update = meta_update_tape.gradient(sum_losses, model.trainable_variables)\n\n# gradients_meta_update is [None, None, None, ...]\n\n</code></pre>\n\n<p>I've tried: </p>\n\n<ul>\n<li>to run it without the loop (just one batch)</li>\n<li>to have the sum of the losses outside the outer tape</li>\n<li>to apply the gradients for the inner update with a SGD optimizer (this is what I would prefer to do)</li>\n<li>not to apply the inner gradient at all </li>\n<li>have the inner tape with the option <code>persistent=True</code></li>\n<li>watch the <code>model.trainable_variables</code> in the outer tape explicitly</li>\n</ul>\n\n<p>I'm running out of ideas and the documentation does not help me, so I appreciate every suggestion.\nThank you!</p>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 93}]
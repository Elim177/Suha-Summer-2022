[{"items": [{"tags": ["python", "tensorflow", "dataset", "artificial-intelligence", "cnc"], "owner": {"user_type": "does_not_exist", "display_name": "user16021918"}, "is_answered": true, "view_count": 83, "answer_count": 1, "score": 0, "last_activity_date": 1623835814, "creation_date": 1623826131, "last_edit_date": 1623835814, "question_id": 67997697, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/67997697/cnn-structure-extension-error-errornegative-dimension-size-caused-by-subtracti", "title": "CNN structure extension error (Error:Negative dimension size caused by subtracting 2 from 1 for &#39;{{node max_pooling2d_2)", "body": "<p>I would like to extend the CNN structure to the C-C-P-C-C-P-C-C-P structure. However, I get the following error: I can't do anything because it doesn't work, how can I fix this problem? Any help would be greatly appreciated.</p>\n<p>Is there something wrong with my code? Is there any other way? How to solve it?</p>\n<pre><code>import numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.datasets import cifar10\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D,MaxPooling2D,Flatten,Dense,Dropout\nfrom tensorflow.keras.optimizers import Adam\n\n# CIFAR-10 \ub370\uc774\ud130\uc14b\uc744 \uc77d\uace0 \uc2e0\uacbd\ub9dd\uc5d0 \uc785\ub825\ud560 \ud615\ud0dc\ub85c \ubcc0\ud658\n(x_train,y_train),(x_test,y_test)=cifar10.load_data()\nx_train=x_train.astype(np.float32)/255.0\nx_test=x_test.astype(np.float32)/255.0\ny_train=tf.keras.utils.to_categorical(y_train,10)\ny_test=tf.keras.utils.to_categorical(y_test,10)\n\n# \uc2e0\uacbd\ub9dd \ubaa8\ub378 \uc124\uacc4\ncnn=Sequential()\ncnn.add(Conv2D(32,(3,3),activation='relu',input_shape=(32,32,3)))\ncnn.add(Conv2D(32,(3,3),activation='relu'))\ncnn.add(MaxPooling2D(pool_size=(2,2)))\ncnn.add(Dropout(0.25))\ncnn.add(Conv2D(64,(3,3),activation='relu'))\ncnn.add(Conv2D(64,(3,3),activation='relu'))\ncnn.add(MaxPooling2D(pool_size=(2,2)))\ncnn.add(Dropout(0.25))\ncnn.add(Conv2D(64,(3,3),activation='relu'))\ncnn.add(Conv2D(64,(3,3),activation='relu'))\ncnn.add(MaxPooling2D(pool_size=(2,2)))\ncnn.add(Flatten())\ncnn.add(Dense(512,activation='relu'))\ncnn.add(Dropout(0.5))\ncnn.add(Dense(10,activation='softmax'))\n\n# \uc2e0\uacbd\ub9dd \ubaa8\ub378 \ud559\uc2b5\ncnn.compile(loss='categorical_crossentropy',optimizer=Adam(),metrics=['accuracy'])\nhist=cnn.fit(x_train,y_train,batch_size=128,epochs=30,validation_data=(x_test,y_test),verbose=2)\n\n# \uc2e0\uacbd\ub9dd \ubaa8\ub378 \uc815\ud655\ub960 \ud3c9\uac00\nres=cnn.evaluate(x_test,y_test,verbose=0)\nprint(&quot;\uc815\ud655\ub960\uc740&quot;,res[1]*100)\n\nimport matplotlib.pyplot as plt\n\n# \uc815\ud655\ub960 \uadf8\ub798\ud504\nplt.plot(hist.history['accuracy'])\nplt.plot(hist.history['val_accuracy'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train','Validation'], loc='best')\nplt.grid()\nplt.show()\n\n# \uc190\uc2e4 \ud568\uc218 \uadf8\ub798\ud504\nplt.plot(hist.history['loss'])\nplt.plot(hist.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train','Validation'],loc='best')\nplt.grid()\nplt.show()\n\n# Train data\uc758 20%\ub97c validation set\uc73c\ub85c \uc124\uc815\n# \uc131\ub2a5 \ud3c9\uac00\ub294 test data\ub9cc \uc774\uc6a9\nsplit_percent = 0.2\nsplit_index = int(x_train.shape[0]*(1-split_percent))\nx_t = x_train[:split_index]  #x_train\ny_t = y_train[:split_index]  #y_train\nx_v = x_train[split_index:]  #x_val\ny_v = y_train[split_index:]  #y_val\n</code></pre>\n<p>ERROR :</p>\n<pre><code>Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n170500096/170498071 [==============================] - 17s 0us/step\n---------------------------------------------------------------------------\nInvalidArgumentError                      Traceback (most recent call last)\n/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py in _create_c_op(graph, node_def, inputs, control_inputs, op_def)\n   1879   try:\n-&gt; 1880     c_op = pywrap_tf_session.TF_FinishOperation(op_desc)\n   1881   except errors.InvalidArgumentError as e:\n\nInvalidArgumentError: Negative dimension size caused by subtracting 2 from 1 for '{{node max_pooling2d_2/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=&quot;NHWC&quot;, explicit_paddings=[], ksize=[1, 2, 2, 1], padding=&quot;VALID&quot;, strides=[1, 2, 2, 1]](Placeholder)' with input shapes: [?,1,1,64].\n\nDuring handling of the above exception, another exception occurred:\n\nValueError                                Traceback (most recent call last)\n15 frames\n/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py in _create_c_op(graph, node_def, inputs, control_inputs, op_def)\n   1881   except errors.InvalidArgumentError as e:\n   1882     # Convert to ValueError for backwards compatibility.\n-&gt; 1883     raise ValueError(str(e))\n   1884 \n   1885   return c_op\n\nValueError: Negative dimension size caused by subtracting 2 from 1 for '{{node max_pooling2d_2/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=&quot;NHWC&quot;, explicit_paddings=[], ksize=[1, 2, 2, 1], padding=&quot;VALID&quot;, strides=[1, 2, 2, 1]](Placeholder)' with input shapes: [?,1,1,64].\n</code></pre>\n<p>This is the code I added.</p>\n<pre><code># C-C-P-C-C-P\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.datasets import cifar10\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D,MaxPooling2D,Flatten,Dense,Dropout\nfrom tensorflow.keras.optimizers import Adam\n\n# CIFAR-10 \ub370\uc774\ud130\uc14b\uc744 \uc77d\uace0 \uc2e0\uacbd\ub9dd\uc5d0 \uc785\ub825\ud560 \ud615\ud0dc\ub85c \ubcc0\ud658\n(x_train,y_train),(x_test,y_test)=cifar10.load_data()\nx_train=x_train.astype(np.float32)/255.0\nx_test=x_test.astype(np.float32)/255.0\ny_train=tf.keras.utils.to_categorical(y_train,10)\ny_test=tf.keras.utils.to_categorical(y_test,10)\n\n# \uc2e0\uacbd\ub9dd \ubaa8\ub378 \uc124\uacc4\ncnn=Sequential()\ncnn.add(Conv2D(32,(3,3),activation='relu',input_shape=(32,32,3)))\ncnn.add(Conv2D(32,(3,3),activation='relu'))\ncnn.add(MaxPooling2D(pool_size=(2,2)))\ncnn.add(Dropout(0.25))\ncnn.add(Conv2D(64,(3,3),activation='relu'))\ncnn.add(Conv2D(64,(3,3),activation='relu'))\ncnn.add(MaxPooling2D(pool_size=(2,2)))\ncnn.add(Flatten())\ncnn.add(Dropout(0.25))\ncnn.add(Dense(10,activation='softmax'))\n\n# \uc2e0\uacbd\ub9dd \ubaa8\ub378 \ud559\uc2b5\ncnn.compile(loss='categorical_crossentropy',optimizer=Adam(),metrics=['accuracy'])\nhist=cnn.fit(x_train,y_train,batch_size=128,epochs=30,validation_data=(x_test,y_test),verbose=2)\n\n# \uc2e0\uacbd\ub9dd \ubaa8\ub378 \uc815\ud655\ub960 \ud3c9\uac00\nres=cnn.evaluate(x_test,y_test,verbose=0)\nprint(&quot;\uc815\ud655\ub960\uc740&quot;,res[1]*100)\n\nimport matplotlib.pyplot as plt\n\n# \uc815\ud655\ub960 \uadf8\ub798\ud504\nplt.plot(hist.history['accuracy'])\nplt.plot(hist.history['val_accuracy'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train','Validation'], loc='best')\nplt.grid()\nplt.show()\n\n# \uc190\uc2e4 \ud568\uc218 \uadf8\ub798\ud504\nplt.plot(hist.history['loss'])\nplt.plot(hist.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train','Validation'],loc='best')\nplt.grid()\nplt.show()\n\n# Train data\uc758 20%\ub97c validation set\uc73c\ub85c \uc124\uc815\n# \uc131\ub2a5 \ud3c9\uac00\ub294 test data\ub9cc \uc774\uc6a9\nsplit_percent = 0.2\nsplit_index = int(x_train.shape[0]*(1-split_percent))\nx_t = x_train[:split_index]  #x_train\ny_t = y_train[:split_index]  #y_train\nx_v = x_train[split_index:]  #x_val\ny_v = y_train[split_index:]  #y_val\n\n\n\n\n# C-C-P-C-C-P-C-C-P \uad6c\uc870\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.datasets import cifar10\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D,MaxPooling2D,Flatten,Dense,Dropout\nfrom tensorflow.keras.optimizers import Adam\n\n# CIFAR-10 \ub370\uc774\ud130\uc14b\uc744 \uc77d\uace0 \uc2e0\uacbd\ub9dd\uc5d0 \uc785\ub825\ud560 \ud615\ud0dc\ub85c \ubcc0\ud658\n(x_train,y_train),(x_test,y_test)=cifar10.load_data()\nx_train=x_train.astype(np.float32)/255.0\nx_test=x_test.astype(np.float32)/255.0\ny_train=tf.keras.utils.to_categorical(y_train,10)\ny_test=tf.keras.utils.to_categorical(y_test,10)\n\n# \uc2e0\uacbd\ub9dd \ubaa8\ub378 \uc124\uacc4\ncnn=Sequential()\ncnn.add(Conv2D(32,(3,3),activation='relu',input_shape=(32,32,3)))\ncnn.add(Conv2D(32,(3,3),activation='relu'))\ncnn.add(MaxPooling2D(pool_size=(2,2)))\ncnn.add(Dropout(0.25))\ncnn.add(Conv2D(64,(3,3),activation='relu'))\ncnn.add(Conv2D(64,(3,3),activation='relu'))\ncnn.add(MaxPooling2D(pool_size=(2,2)))\ncnn.add(Dropout(0.25))\ncnn.add(Conv2D(64,(3,3),activation='relu'))\ncnn.add(Conv2D(64,(3,3),activation='relu'))\ncnn.add(MaxPooling2D(pool_size=(1,1)))\ncnn.add(Flatten())\ncnn.add(Dense(512,activation='relu'))\ncnn.add(Dropout(0.5))\ncnn.add(Dense(10,activation='softmax'))\n\n# \uc2e0\uacbd\ub9dd \ubaa8\ub378 \ud559\uc2b5\ncnn.compile(loss='categorical_crossentropy',optimizer=Adam(),metrics=['accuracy'])\nhist=cnn.fit(x_train,y_train,batch_size=128,epochs=30,validation_data=(x_test,y_test),verbose=2)\n\n# \uc2e0\uacbd\ub9dd \ubaa8\ub378 \uc815\ud655\ub960 \ud3c9\uac00\nres=cnn.evaluate(x_test,y_test,verbose=0)\nprint(&quot;\uc815\ud655\ub960\uc740&quot;,res[1]*100)\n\nimport matplotlib.pyplot as plt\n\n# \uc815\ud655\ub960 \uadf8\ub798\ud504\nplt.plot(hist.history['accuracy'])\nplt.plot(hist.history['val_accuracy'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train','Validation'], loc='best')\nplt.grid()\nplt.show()\n\n# \uc190\uc2e4 \ud568\uc218 \uadf8\ub798\ud504\nplt.plot(hist.history['loss'])\nplt.plot(hist.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train','Validation'],loc='best')\nplt.grid()\nplt.show()\n\n# Train data\uc758 20%\ub97c validation set\uc73c\ub85c \uc124\uc815\n# \uc131\ub2a5 \ud3c9\uac00\ub294 test data\ub9cc \uc774\uc6a9\nsplit_percent = 0.2\nsplit_index = int(x_train.shape[0]*(1-split_percent))\nx_t = x_train[:split_index]  #x_train\ny_t = y_train[:split_index]  #y_train\nx_v = x_train[split_index:]  #x_val\ny_v = y_train[split_index:]  #y_val\n</code></pre>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 124}]
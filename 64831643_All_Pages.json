[{"items": [{"tags": ["python", "tensorflow", "keras"], "owner": {"account_id": 16597457, "reputation": 11, "user_id": 11994015, "user_type": "registered", "profile_image": "https://graph.facebook.com/367829170813641/picture?type=large", "display_name": "Gajesh Ladhar", "link": "https://stackoverflow.com/users/11994015/gajesh-ladhar"}, "is_answered": false, "view_count": 110, "answer_count": 0, "score": 1, "last_activity_date": 1605337160, "creation_date": 1605337160, "question_id": 64831643, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/64831643/gradient-tape-is-much-slower-than-keras-fit-method", "title": "Gradient Tape is much slower than keras fit method", "body": "<p>I have trained a simple Dense Layer on gradient tap and keras api both, but gradient tape has stuck on local minima but fit() method decresed loss till global minima, both have same optimizer and same learning rate and same loss function.\nCan someone explain why this happens?</p>\n<pre><code># Model Architecture...\ndense1=tf.keras.layers.Dense(units=40)\ndense2=tf.keras.layers.Dense(units=1)\n</code></pre>\n<p>And Model Hyperparameters</p>\n<pre><code># Model Hyperparameter...\nepochs=10\nbatch_size=64\ndef loss_fn(y_true, y_pred):\n  return tf.keras.backend.sqrt(tf.keras.backend.mean(tf.keras.backend.square(y_pred - y_true))) \noptimizer=tf.keras.optimizers.Adam(0.001)\ntrain_gen=train_data_gen(batch_size)\n</code></pre>\n<p>Gradient tape :</p>\n<pre><code>@tf.function\ndef train_model():\n  x,y=next(train_gen)\n  with tf.GradientTape() as tape :\n    predictions=dense2(dense1(x))\n    vars=tape.watched_variables()\n    loss=loss_fn(y,predictions)\n    grads=tape.gradient(loss,vars)\n    optimizer.apply_gradients(zip(grads,vars))\n  return loss\n</code></pre>\n<p>Epochs on gradient tape :</p>\n<pre><code># Training....\n\nfor epoch in range(epochs):\n  losses=[]\n  for batch in range(5000) :\n    loss=train_model()\n    losses+=[loss]\n  print(&quot;Epoch : &quot;+str(epoch+1)+&quot;\\nLoss : &quot;+str(np.mean(losses)))\n</code></pre>\n<p>Now in Keras Api :</p>\n<pre><code>input_=tf.keras.Input(shape=(20))\nt=dense1(input_)\nt=dense2(t)\nmodel=tf.keras.models.Model([input_],[t])\n\nmodel.compile(optimizer=tf.keras.optimizers.Adam(0.001),loss=loss_fn)\n\nmodel.fit_generator(train_gen,steps_per_epoch=5000,epochs=10)\n</code></pre>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 140}]
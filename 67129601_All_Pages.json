[{"items": [{"tags": ["python", "tensorflow", "machine-learning", "keras", "nlp"], "owner": {"account_id": 17912389, "reputation": 476, "user_id": 13014194, "user_type": "registered", "profile_image": "https://i.stack.imgur.com/ceTVa.png?s=256&g=1", "display_name": "Darien Schettler", "link": "https://stackoverflow.com/users/13014194/darien-schettler"}, "is_answered": false, "view_count": 83, "answer_count": 1, "score": 0, "last_activity_date": 1618621142, "creation_date": 1618593575, "question_id": 67129601, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/67129601/how-to-mask-split-a-tensorflow-array-after-first-occurence-of-a-value", "title": "How To Mask/Split A Tensorflow Array After First Occurence of a Value", "body": "<p>I have a very particular query and I've been trying to solve it for a week or so now.</p>\n<p>Let me give some context.</p>\n<p>I have a pipeline where I generate predictions that are integers representing words to attempt to predict a sentence. The prediction will be padded to the maximum length.</p>\n<p>i.e.</p>\n<pre><code># 0 is PAD token\n# 1 is START token\n# 2 is END token \n# 3-20 are words\nprediction   = [1, 5, 11, 2, 16, 2, 11, 15, 2, 16]\nground_truth = [1, 5, 11, 2, 17, 2, 0, 0, 0, 0]\n\n# Simplified accuracy calculation\nfull_acc = 0.50\nreal_acc = 0.90\n</code></pre>\n<p>My model is mostly, correctly predicting the string up to the END token. Because I'm masking the PAD token during training it predicts gibberish afterwards while the ground truth uses padding. To correctly calculate the elementwise accuracy I need to disregard all values after the END token. Keep in mind this is a single example... however, in practice, I want to be able to calculate accuracy across an entire batch (prediction vs. gt).</p>\n<p>We will have a prediction array of shape (64, 20) and we will have a ground truth array of shape (64,20). I want an accuracy output that is (64,). I do not want to have to do any loops or anything.</p>\n<p>Ideally, I want to mask the array after a certain value (2) occurs.</p>\n<p>i.e.</p>\n<pre><code>def mask_fn(...):\n    ...\n\n# 0 is PAD token\n# 1 is START token\n# 2 is END token \n# 3-20 are words\nprediction   = [[1, 5, 11, 2, 16, 2, 11, 15, 2, 16], ...]\nground_truth = [[1, 5, 11, 2, 17, 2, 0, 0, 0, 0], ...]\n\n# mask         = [[1, 1, 1, 1, 1, 1, 0, 0, 0, 0], ...]\n# masked_pred  = [[1, 5, 11, 2, 16, 2, 0, 0, 0, 0], ...] --&gt; tf.where(mask==1, prediction, 0)\n# ground_truth = [[1, 5, 11, 2, 17, 2, 0, 0, 0, 0], ...]\nmasked_pred = mask_fn(prediction_arr)\n\n# Simplified accuracy calculation\nreal_acc = 0.90\n</code></pre>\n<p>Hopefully, it makes sense what I am trying to do.</p>\n<p>Please, any help you can give would be greatly appreciated. Note that I show accuracy here, but I am actually calculating a more complicated metric.</p>\n<p>As such, the main thing I'm looking for is a way to get the prediction to look like the masked_pred when working with batches that could have the END token occur at different locations within each example.</p>\n<p>Thanks in advance!</p>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 127}]
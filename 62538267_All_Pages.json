[{"items": [{"tags": ["python", "performance", "tensorflow", "for-loop", "tensorflow2.0"], "owner": {"account_id": 18914215, "reputation": 403, "user_id": 13799627, "user_type": "registered", "profile_image": "https://www.gravatar.com/avatar/eb8d1cb060a1e1838653058c8088ce83?s=256&d=identicon&r=PG&f=1", "display_name": "Crysers", "link": "https://stackoverflow.com/users/13799627/crysers"}, "is_answered": true, "view_count": 1216, "accepted_answer_id": 62539945, "answer_count": 1, "score": 1, "last_activity_date": 1592931369, "creation_date": 1592925827, "question_id": 62538267, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/62538267/is-adding-values-with-tf-concat-slow-in-for-loops", "title": "Is adding values with tf.concat slow in for-loops?", "body": "<p>Im using tensorflow 2.0 and try to speed up my training by optimizing my code a little bit.</p>\n<p>I run my model batchwise and want to safe the results from each batch to have all results at the end of one epoch in one tensor.</p>\n<p>This is how my code looks like:</p>\n<pre><code>...\nfor epoch in range(start_epoch, end_epoch):\n\n    # this vector shall hold all results for one epoch\n    predictions_epoch = tf.zeros(0,)\n   \n    for batch in tf_dataset: \n        # get prediction with predictions_batch.shape[0] euqals batch_size\n        predictions_batch = model(batch)   \n        \n        # Add the batch result to the previous results\n        predictions_epoch = tf.concat(predictions_batch, predictions_epoch)\n        \n        # DO SOME OTHER STUFF LIKE BACKPROB\n        ...\n\n    # predictions_epoch.shape[0] now equals number of all samples in dataset\n    with writer.as_default():\n        tf.summary.histogram(name='predictions', data=predictions_epoch, step=epoch)\n\n</code></pre>\n<p>Lets assume, one prediction is just a scalar value. So <code>predictions_batch</code> is a tensor with shape=[batchsize,].</p>\n<p>This way of doing the concaternation just works fine.</p>\n<p>Now my question is:\nDoes this <code>tf.concat()</code> operation slow down my whole training? I also used <code>tf.stack()</code>for this purpose, but it seems like no difference in speed.</p>\n<p>I wonder, because once I worked with Matlab, adding new values to a Vector (and hence change its size) within a for-loop was extremly slow. Initializing the vector with zeros and then assign values in the loop was way more efficient regarding speed.</p>\n<p>Is this also true for tensorflow? Or is there another more 'proper' way of doing something like adding tensors together in a for-loop which is more clean or faster?\nI did not find any alternative solution online.</p>\n<p>Thanks for the help.</p>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 77}]
[{"items": [{"tags": ["python", "tensorflow", "machine-learning", "neural-network", "lstm"], "owner": {"account_id": 1162208, "reputation": 24701, "user_id": 1141493, "user_type": "registered", "accept_rate": 99, "profile_image": "https://www.gravatar.com/avatar/25452a0e44babf480d85311e5ece4421?s=256&d=identicon&r=PG", "display_name": "kiriloff", "link": "https://stackoverflow.com/users/1141493/kiriloff"}, "is_answered": true, "view_count": 1566, "accepted_answer_id": 59479102, "answer_count": 2, "score": 1, "last_activity_date": 1577282858, "creation_date": 1577279174, "question_id": 59478685, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/59478685/tensorflow-building-lstm-model-need-for-tf-keras-layers-dense", "title": "Tensorflow - building LSTM model - need for tf.keras.layers.Dense()", "body": "<p>Python 3.7 tensorflow</p>\n\n<p>I am experimenting <a href=\"https://www.tensorflow.org/tutorials/structured_data/time_series\" rel=\"nofollow noreferrer\">Time series forecasting w Tensorflow</a> </p>\n\n<p>I understand the second line creates a <code>LSTM</code> RNN i.e. a Recurrent Neural Network of type Long Short Term Memory. </p>\n\n<p>Why do we need to add a <code>Dense(1)</code> layer in the end? </p>\n\n<pre><code>single_step_model = tf.keras.models.Sequential()\nsingle_step_model.add(tf.keras.layers.LSTM(32, input_shape=x_train_single.shape[-2:]))\nsingle_step_model.add(tf.keras.layers.Dense(1))\n</code></pre>\n\n<p>Tutorial for <code>Dense()</code> says </p>\n\n<blockquote>\n  <p>Dense implements the operation: <code>output = activation(dot(input, kernel) + bias)</code> where <code>activation</code> is the element-wise activation function passed as the activation argument, <code>kernel</code> is a weights matrix created by the layer, and <code>bias</code> is a bias vector created by the layer (only applicable if use_bias is True).</p>\n</blockquote>\n\n<p>would you like to rephrase or elaborate on need for <code>Dense()</code> here ?</p>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 42}]
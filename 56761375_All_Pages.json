[{"items": [{"tags": ["python", "tensorflow"], "owner": {"account_id": 16180817, "reputation": 23, "user_id": 11682407, "user_type": "registered", "profile_image": "https://www.gravatar.com/avatar/11f407a4d3b3ba012f63be5a00f06069?s=256&d=identicon&r=PG&f=1", "display_name": "khyc", "link": "https://stackoverflow.com/users/11682407/khyc"}, "is_answered": false, "view_count": 1916, "answer_count": 2, "score": 2, "last_activity_date": 1582720949, "creation_date": 1561493680, "last_edit_date": 1561559858, "question_id": 56761375, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/56761375/tensorflow-program-stuck-in-infinite-training-loop", "title": "Tensorflow program stuck in infinite training loop", "body": "<p>I am using the code from GAN tutorial on generating MNIST digits in tensorflow.</p>\n\n<p>(Link here: <a href=\"https://www.tensorflow.org/beta/tutorials/generative/dcgan\" rel=\"nofollow noreferrer\">https://www.tensorflow.org/beta/tutorials/generative/dcgan</a>)</p>\n\n<p>Currently, the program stucks in an infinite training loop. I set the training dataset to be only one image, and set epoch = 1. I inserted print statements in the loop. In the train() function, it only prints a and b, but doesn't print c, which means it's stuck in an infinite loop in the second for loop. </p>\n\n<p>Here I load, shuffle, and batch the data (training dataset is only one image for testing purpose) </p>\n\n<pre><code>(train_images, train_labels), (_, _) = tf.keras.datasets.mnist.load_data()\ntrain_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')\ntrain_images = (train_images - 127.5) / 127.5 # Normalize the images to [-1, 1]\ntrain_images = train_images[0:1,:,:,:]\nprint(train_images.shape)\n\nBUFFER_SIZE = 1\nBATCH_SIZE = 1\n\n# Batch and shuffle the data\ntrain_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\nprint(train_dataset)\n</code></pre>\n\n<p>These are the functions that define generator and discriminator model, losses</p>\n\n<pre><code>def make_generator_model():\n    ...\n    return model\n\ngenerator = make_generator_model()\nnoise = np.random.normal(size=(1, 100))\ngenerated_image = generator.predict(noise)\n\ndef make_discriminator_model():\n    ...\n    return model\n\ndiscriminator = make_discriminator_model()\ndecision = discriminator.predict(generated_image)\n\ncross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n\ndef discriminator_loss(real_output, fake_output):\n    ...\n    return total_loss\n\ndef generator_loss(fake_output):\n    return cross_entropy(tf.ones_like(fake_output), fake_output)\n\ngenerator_optimizer = tf.keras.optimizers.Adam(1e-4)\ndiscriminator_optimizer = tf.keras.optimizers.Adam(1e-4)\n</code></pre>\n\n<p>These are the training functions:</p>\n\n<pre><code>EPOCHS = 1\nnoise_dim = 100\nseed = tf.random.normal([num_examples_to_generate, noise_dim])\n\ndef train_step(images):\n    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n\n    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n      generated_images = generator(noise, training=True)\n      print(images.shape)\n      real_output = discriminator(images, training=True)\n      fake_output = discriminator(generated_images, training=True)\n\n      gen_loss = generator_loss(fake_output)\n      disc_loss = discriminator_loss(real_output, fake_output)\n\n    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n\n    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n\ndef train(dataset, epochs):\n    for epoch in range(epochs):\n        start = time.time()\n\n        for image_batch in dataset: #stuck in an infinite loop\n            print('a')\n            train_step(image_batch)\n            print('b')\n\n        print('c')\n        # Produce images for the GIF as we go\n        display.clear_output(wait=True)\n        generate_and_save_images(generator,epoch + 1,seed)\n        print('d')\n\n        # Save the model every 1 epochs\n        if (epoch + 1) % 1 == 0:\n            checkpoint.save(file_prefix = checkpoint_prefix)\n\n        print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n\n    # Generate after the final epoch\n    display.clear_output(wait=True)\n    generate_and_save_images(generator,epochs,seed)\n\ndef generate_and_save_images(model, epoch, test_input):\n  ...\n\ntrain(train_dataset, EPOCHS)\n</code></pre>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 52}]
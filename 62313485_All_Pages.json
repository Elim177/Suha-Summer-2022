[{"items": [{"tags": ["python", "tensorflow", "keras", "recurrent-neural-network", "multiclass-classification"], "owner": {"account_id": 17697666, "reputation": 25, "user_id": 12848021, "user_type": "registered", "profile_image": "https://graph.facebook.com/2916799961720464/picture?type=large", "display_name": "Kamel SId-Ahmed", "link": "https://stackoverflow.com/users/12848021/kamel-sid-ahmed"}, "is_answered": true, "view_count": 120, "accepted_answer_id": 62318755, "answer_count": 1, "score": 2, "last_activity_date": 1591858617, "creation_date": 1591824821, "question_id": 62313485, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/62313485/multi-dimension-y-train-on-keras", "title": "Multi Dimension Y_train on Keras", "body": "<p>i have 2 corpus for x_train and y_train, and after some treatment like this :</p>\n\n<pre><code>input_sequences = []\nlabels = []\n\nindexCA = 0\n\nfor line in corpusMSA:\n    lineCA = corpusCA[indexCA].split() # Save CA Line\n    token_list = tokenizer.texts_to_sequences([line])[0] # Tokenize line\n    for i in range(1, len(token_list)):\n        n_gram_sequence = token_list[:i+1] # Generate ngrams (n=2)\n        n_gram_label = lineCA[:i+1]\n        input_sequences.append(n_gram_sequence)\n        labels.append(n_gram_label)\n    indexCA+=1\n\n# pad sequences \nmax_sequence_len = max([len(x) for x in input_sequences])\ninput_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n\nmax_labels_len = max([len(x) for x in labels])\nlabels = np.array(pad_sequences(labels, maxlen=max_labels_len, padding='pre'))\n\n# create predictors and label\nxs = input_sequences\nys = tf.keras.utils.to_categorical(labels, num_classes=16)\n</code></pre>\n\n<p>the original shape of both dataset are (1098360, 14), but after using utils.to_categorical() methode the y_train shape become (1098360, 14, 16).</p>\n\n<p>i have 2 Bidirectional LSTM layer : </p>\n\n<pre><code>model.add(Embedding(total_words, 100, input_length=max_sequence_len))\nmodel.add(Bidirectional(LSTM(256, return_sequences=True)))\nmodel.add(Bidirectional(LSTM(128)))\nmodel.add(Dense(16, activation='softmax'))\nadam = Adam(lr=0.01)\nmodel.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\nhistory = model.fit(x_train, y_train, epochs=20, batch_size=size_batch, verbose=1, callbacks=[tensorboard])\n</code></pre>\n\n<p>and i have this error : A target array with shape (1098360, 14, 16) was passed for an output of shape (None, 16) while using as loss <code>categorical_crossentropy</code>. This loss expects targets to have the same shape as the output.</p>\n\n<p>how can i tell my model that the output shape are (None,14,16) ?</p>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 3}]
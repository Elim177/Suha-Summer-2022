[{"items": [{"tags": ["python-3.x", "tensorflow2.x", "quantization-aware-training"], "owner": {"account_id": 4441934, "reputation": 1952, "user_id": 3616293, "user_type": "registered", "accept_rate": 35, "profile_image": "https://www.gravatar.com/avatar/cf7556b4227065cec9496375d64fea3d?s=256&d=identicon&r=PG&f=1", "display_name": "Arun", "link": "https://stackoverflow.com/users/3616293/arun"}, "is_answered": false, "view_count": 71, "answer_count": 0, "score": 1, "last_activity_date": 1594551024, "creation_date": 1594551024, "question_id": 62860122, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/62860122/quantization-aware-training-with-tf-gradienttape-gives-error-in-tensorflow2-0", "title": "Quantization Aware Training with tf.GradientTape gives Error in TensorFlow2.0", "body": "<p>I am using TensorFlow-2.2, tensorflow_model_optimization and Python 3.8. I am trying to quantize and train a LeNet-300-100 Dense neural network which contains sparsity of 91.3375%. This means that 91.3375% of the weights are zero. I was following the <a href=\"https://www.tensorflow.org/model_optimization/guide/quantization/training_example\" rel=\"nofollow noreferrer\">Quantization TF tutorial</a> and I wanted to train such a sparse network which has been quantized using <em>tf.GradientTape</em> rather than <em>q_aware_model.fit()</em>.</p>\n<p>If you look into the <a href=\"https://github.com/arjun-majumdar/Lottery_Ticket_Hypothesis-TensorFlow_2/blob/master/Quantization_LTH_LeNet_300_100_MNIST.ipynb\" rel=\"nofollow noreferrer\">example code</a>, the relevant code snippets are:</p>\n<pre><code>quantize_model = tfmot.quantization.keras.quantize_model\n\n# q_aware stands for for quantization aware.\nq_aware_model = quantize_model(model)\n\n\n# 'quantize_model' requires recompilation-\nq_aware_model.compile(\n    optimizer = tf.keras.optimizers.Adam(lr = 0.0012),\n    loss=tf.keras.losses.categorical_crossentropy,\n    metrics=['accuracy']\n)\n\n\n# Define 'train_one_step()' and 'test_step()' functions here-\n@tf.function\ndef train_one_step(model, mask_model, optimizer, x, y):\n    '''\n    Function to compute one step of gradient descent optimization\n    '''\n    with tf.GradientTape() as tape:\n        # Make predictions using defined model-\n        y_pred = model(x)\n\n        # Compute loss-\n        loss = loss_fn(y, y_pred)\n        \n    # Compute gradients wrt defined loss and weights and biases-\n    grads = tape.gradient(loss, model.trainable_variables)\n    \n    # type(grads)\n    # list\n    \n    # List to hold element-wise multiplication between-\n    # computed gradient and masks-\n    grad_mask_mul = []\n    \n    # Perform element-wise multiplication between computed gradients and masks-\n    for grad_layer, mask in zip(grads, mask_model.trainable_weights):\n        grad_mask_mul.append(tf.math.multiply(grad_layer, mask))\n    \n    # Apply computed gradients to model's weights and biases-\n    optimizer.apply_gradients(zip(grad_mask_mul, model.trainable_variables))\n\n    # Compute accuracy-\n    train_loss(loss)\n    train_accuracy(y, y_pred)\n\n    return None\n    \n    \n@tf.function\ndef test_step(model, optimizer, data, labels):\n    &quot;&quot;&quot;\n    Function to test model performance\n    on testing dataset\n    &quot;&quot;&quot;\n    \n    predictions = model(data)\n    t_loss = loss_fn(labels, predictions)\n\n    test_loss(t_loss)\n    test_accuracy(labels, predictions)\n\n    return None\n\n\n\n# Train model using 'GradientTape'-\n    \n# Initialize parameters for Early Stopping manual implementation-\n# best_val_loss = 100\n# loc_patience = 0\n    \nfor epoch in range(num_epochs):\n    \n    if loc_patience &gt;= patience:\n        print(&quot;\\n'EarlyStopping' called!\\n&quot;)\n        break\n        \n    # Reset the metrics at the start of the next epoch\n    train_loss.reset_states()\n    train_accuracy.reset_states()\n    test_loss.reset_states()\n    test_accuracy.reset_states()\n            \n    \n    for x, y in train_dataset:\n        train_one_step(q_aware_model, mask_model, optimizer, x, y)\n\n\n    for x_t, y_t in test_dataset:\n        test_step(q_aware_model, optimizer, x_t, y_t)\n\n    template = 'Epoch {0}, Loss: {1:.4f}, Accuracy: {2:.4f}, Test Loss: {3:.4f}, Test Accuracy: {4:4f}'\n    \n    '''\n    # 'i' is the index for number of pruning rounds-\n    history_main[i]['accuracy'][epoch] = train_accuracy.result() * 100\n    history_main[i]['loss'][epoch] = train_loss.result()\n    history_main[i]['val_loss'][epoch] = test_loss.result()\n    history_main[i]['val_accuracy'][epoch] = test_accuracy.result() * 100\n    ''' \n\n    print(template.format(\n        epoch + 1, train_loss.result(),\n        train_accuracy.result()*100, test_loss.result(),\n        test_accuracy.result()*100)\n         )\n    \n    # Count number of non-zero parameters in each layer and in total-\n    # print(&quot;layer-wise manner model, number of nonzero parameters in each layer are: \\n&quot;)\n    model_sum_params = 0\n    \n    for layer in winning_ticket_model.trainable_weights:\n        # print(tf.math.count_nonzero(layer, axis = None).numpy())\n        model_sum_params += tf.math.count_nonzero(layer, axis = None).numpy()\n    \n    print(&quot;Total number of trainable parameters = {0}\\n&quot;.format(model_sum_params))\n\n    \n    # Code for manual Early Stopping:\n    if np.abs(test_loss.result() &lt; best_val_loss) &gt;= minimum_delta:\n        # update 'best_val_loss' variable to lowest loss encountered so far-\n        best_val_loss = test_loss.result()\n        \n        # reset 'loc_patience' variable-\n        loc_patience = 0\n        \n    else:  # there is no improvement in monitored metric 'val_loss'\n        loc_patience += 1  # number of epochs without any improvement\n</code></pre>\n<p>Gives the following error:</p>\n<blockquote>\n<p>--------------------------------------------------------------------------- InvalidArgumentError                      Traceback (most recent call\nlast)  in \n19\n20     for x, y in train_dataset:\n---&gt; 21         train_one_step(q_aware_model, mask_model, optimizer, x, y)\n22\n23</p>\n<p>~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\nin <strong>call</strong>(self, *args, **kwds)\n578         xla_context.Exit()\n579     else:\n--&gt; 580       result = self._call(*args, **kwds)\n581\n582     if tracing_count == self._get_tracing_count():</p>\n<p>~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\nin _call(self, *args, **kwds)\n642         # Lifting succeeded, so variables are initialized and we can run the\n643         # stateless function.\n--&gt; 644         return self._stateless_fn(*args, **kwds)\n645     else:\n646       canon_args, canon_kwds = \\</p>\n<p>~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\nin <strong>call</strong>(self, *args, **kwargs)    2418     with self._lock:<br />\n2419       graph_function, args, kwargs =\nself._maybe_define_function(args, kwargs)\n-&gt; 2420     return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access    2421     2422   @property</p>\n<p>~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\nin _filtered_call(self, args, kwargs)    1659       <code>args</code> and\n<code>kwargs</code>.    1660     &quot;&quot;&quot;\n-&gt; 1661     return self._call_flat(    1662         (t for t in nest.flatten((args, kwargs), expand_composites=True)    1663<br />\nif isinstance(t, (ops.Tensor,</p>\n<p>~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\nin _call_flat(self, args, captured_inputs, cancellation_manager)<br />\n1743         and executing_eagerly):    1744       # No tape is\nwatching; skip to running the function.\n-&gt; 1745       return self._build_call_outputs(self._inference_function.call(    1746<br />\nctx, args, cancellation_manager=cancellation_manager))    1747<br />\nforward_backward = self._select_forward_and_backward_functions(</p>\n<p>~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\nin call(self, ctx, args, cancellation_manager)\n591       with _InterpolateFunctionError(self):\n592         if cancellation_manager is None:\n--&gt; 593           outputs = execute.execute(\n594               str(self.signature.name),\n595               num_outputs=self._num_outputs,</p>\n<p>~/.local/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\nin quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)\n57   try:\n58     ctx.ensure_initialized()\n---&gt; 59     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n60                                         inputs, attrs, num_outputs)\n61   except core._NotOkStatusException as e:</p>\n<p>InvalidArgumentError:  var and grad do not have the same shape[10]\n[100,10]   [[node Adam/Adam/update_4/ResourceApplyAdam (defined at\n:29) ]]\n[Op:__inference_train_one_step_20360]</p>\n<p>Errors may have originated from an input operation. Input Source\noperations connected to node Adam/Adam/update_4/ResourceApplyAdam:\nMul_4 (defined at :26)<br />\nsequential/quant_dense_2/BiasAdd/ReadVariableOp/resource (defined at\n/home/arjun/.local/lib/python3.8/site-packages/tensorflow_model_optimization/python/core/quantization/keras/quantize_wrapper.py:162)</p>\n<p>Function call stack: train_one_step</p>\n</blockquote>\n<p>Is there a way to combine TF model Quantization along with tf.GradientTape?</p>\n<p>Thanks!</p>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 210}]
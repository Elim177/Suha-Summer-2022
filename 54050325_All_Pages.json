[{"items": [{"tags": ["python", "tensorflow", "keras"], "owner": {"account_id": 3948330, "reputation": 5043, "user_id": 3259896, "user_type": "registered", "accept_rate": 60, "profile_image": "https://www.gravatar.com/avatar/641c30a7b383022f22b53c8cedb04e3f?s=256&d=identicon&r=PG&f=1", "display_name": "SantoshGupta7", "link": "https://stackoverflow.com/users/3259896/santoshgupta7"}, "is_answered": true, "view_count": 3751, "accepted_answer_id": 54215447, "answer_count": 2, "score": 12, "last_activity_date": 1547636711, "creation_date": 1546677045, "last_edit_date": 1592644375, "question_id": 54050325, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/54050325/can-a-tensorflow-variable-be-trained-using-the-tensorflow-keras-functional-api-m", "title": "Can a Tensorflow variable be trained using the Tensorflow Keras functional API model? Can a Tensorflow operation be used in the functional API Model?", "body": "<p>I am wondering if Keras model compile/training with the functional API train variables defined by <code> tf.get_variable</code>? Can Keras training also incorporate Tensorflow operations?</p>\n<p>So basically I am looking to define a Keras model with Tensorflow variables and operations, then use</p>\n<pre><code>model = tf.keras.Model(inputs=inputs, outputs=predictions)\nmodel.compile(optimizer=optimizer, loss=loss)\nmodel.fit(data, labels, batch_size=batch_size, epochs=epochs)\n</code></pre>\n<p>To train the model. The reason for this is that Google's TPUs require either a Keras or TF.Estimator API, with Keras being more recommended, so I am looking to see how easily I can convert my model.</p>\n<h1>BackGround</h1>\n<p>It looks like since Tensorflow is the backend, there are ways to mix Keras/Tensorflow variables. This blog post shows how Keras variables are trained using a Tensorflow graph/session\n<a href=\"https://blog.keras.io/keras-as-a-simplified-interface-to-tensorflow-tutorial.html\" rel=\"noreferrer\">https://blog.keras.io/keras-as-a-simplified-interface-to-tensorflow-tutorial.html</a></p>\n<pre><code>from keras.layers import Dropout\nfrom keras import backend as K\n\nimg = tf.placeholder(tf.float32, shape=(None, 784))\nlabels = tf.placeholder(tf.float32, shape=(None, 10))\n\nx = Dense(128, activation='relu')(img)\nx = Dropout(0.5)(x)\nx = Dense(128, activation='relu')(x)\nx = Dropout(0.5)(x)\npreds = Dense(10, activation='softmax')(x)\n\nloss = tf.reduce_mean(categorical_crossentropy(labels, preds))\n\ntrain_step = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\nwith sess.as_default():\n    for i in range(100):\n        batch = mnist_data.train.next_batch(50)\n        train_step.run(feed_dict={img: batch[0],\n                                  labels: batch[1],\n                                  K.learning_phase(): 1})\n\nacc_value = accuracy(labels, preds)\nwith sess.as_default():\n    print acc_value.eval(feed_dict={img: mnist_data.test.images,\n                                    labels: mnist_data.test.labels,\n                                    K.learning_phase(): 0})\n</code></pre>\n<p>And also here it shows that Tensorflow variables can be used as input to a Keras model</p>\n<p><a href=\"https://stackoverflow.com/questions/44151823/how-to-set-the-input-of-a-keras-layer-of-a-functional-model-with-a-tensorflow-t?rq=1\">How to set the input of a Keras layer of a functional model, with a Tensorflow tensor?</a></p>\n<pre><code>tf_embedding_input = ...    # pre-processing output tensor\n\n# Keras model\nmodel = Sequential()\nmodel.add(Input(tensor=tf_embedding_input)) \nmodel.add(Embedding(max_features, 128, input_length=maxlen))\n</code></pre>\n<p>So I am wondering if Keras can train Tensorflow variables.</p>\n<h1>Example</h1>\n<p>I would like to train the embedding and softmax variables in the Tensorflow architecture below</p>\n<pre><code>  embeddings = tf.get_variable( 'embeddings', \n    initializer= tf.random_uniform([vocabulary_size, embedding_size], -1.0, 1.0))\n\n  softmax_weights = tf.get_variable( 'softmax_weights',\n    initializer= tf.truncated_normal([vocabulary_size, embedding_size],\n                         stddev=1.0 / math.sqrt(embedding_size)))\n  \n  softmax_biases = tf.get_variable('softmax_biases', \n    initializer= tf.zeros([vocabulary_size]),  trainable=False )\n\n  embed = tf.nn.embedding_lookup(embeddings, train_dataset) #train data set is\n\n  embed_reshaped = tf.reshape( embed, [batch_size*num_inputs, embedding_size] )\n  \n  segments= np.arange(batch_size).repeat(num_inputs)\n\n  averaged_embeds = tf.segment_mean(embed_reshaped, segments, name=None)\n\n  loss = tf.reduce_mean(\n    tf.nn.sampled_softmax_loss(weights=softmax_weights, biases=softmax_biases, inputs=averaged_embeds,\n                               labels=train_labels, num_sampled=num_sampled, num_classes=vocabulary_size))\n</code></pre>\n<p>Since Tensorflow Keras uses a Tensorflow backend, I'm guessing it's somehow possible to use and train Tensorflow variables and use Tensorflow operations in training.</p>\n<h1>Why do I want to do this?</h1>\n<p>Google's TPUs require that your architecture be implemented via the Estimator API or Keras API. Since the Keras API is more recommended,  there is probably interest in converting a regular Tensorflow Graph/Session to use the Keras API with as few alterations to their code as possible.</p>\n<p>Knowing how to incorporate Tensorflow operations and train Tensorflow variables using the Keras model compile/train would greatly help with this.</p>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 104}]
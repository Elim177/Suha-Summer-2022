[{"items": [{"tags": ["tensorflow", "tensorflow-federated"], "owner": {"account_id": 20598106, "reputation": 69, "user_id": 15119954, "user_type": "registered", "profile_image": "https://www.gravatar.com/avatar/e0510bd344a10228b95cd76e08241a2e?s=256&d=identicon&r=PG&f=1", "display_name": "JunePyo", "link": "https://stackoverflow.com/users/15119954/junepyo"}, "is_answered": true, "view_count": 208, "accepted_answer_id": 66363417, "answer_count": 1, "score": 2, "last_activity_date": 1614234353, "creation_date": 1614078021, "question_id": 66331850, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/66331850/how-do-i-create-an-fl-algorithm-that-uses-the-weights-of-a-few-clients", "title": "How do I create an FL algorithm that uses the weights of a few clients?", "body": "<p>Based on this <a href=\"https://github.com/tensorflow/federated/tree/3c0852c5fef375198f5931ce31fd97f2df9c4d05/tensorflow_federated/python/examples/simple_fedavg\" rel=\"nofollow noreferrer\">link</a> I am trying to write a new way of FL algorithm. I train all clients and send the model parameters of all clients to the server, and the server will weight average only the model parameters of 30% of all clients during the aggregation process. As a criterion for selecting model parameters of 30% of clients, I want to do a weighted average by using <code>weights_delta</code> of 30% of clients with less <code>loss_sum</code> of clients.</p>\n<p>The code below is a modified code for this <a href=\"https://github.com/tensorflow/federated/blob/3c0852c5fef375198f5931ce31fd97f2df9c4d05/tensorflow_federated/python/examples/simple_fedavg/simple_fedavg_tf.py#L191\" rel=\"nofollow noreferrer\">link</a>.</p>\n<pre><code>@tf.function\ndef client_update(model, dataset, server_message, client_optimizer):\n\nmodel_weights = model.weights\ninitial_weights = server_message.model_weights\ntff.utils.assign(model_weights, initial_weights)\n\nnum_examples = tf.constant(0, dtype=tf.int32)\nloss_sum = tf.constant(0, dtype=tf.float32)\n\nfor batch in iter(dataset):\n    with tf.GradientTape() as tape:\n        outputs = model.forward_pass(batch)\n    grads = tape.gradient(outputs.loss, model_weights.trainable)\n    grads_and_vars = zip(grads, model_weights.trainable)\n    client_optimizer.apply_gradients(grads_and_vars)\n    batch_size = tf.shape(batch['x'])[0]\n    num_examples += batch_size\n    loss_sum += outputs.loss * tf.cast(batch_size, tf.float32)        \n\nweights_delta = tf.nest.map_structure(lambda a, b: a - b,\n                                      model_weights.trainable,\n                                      initial_weights.trainable)\nclient_weight = tf.cast(num_examples, tf.float32)\n\nclient_loss = loss_sum #add\n\nreturn ClientOutput(weights_delta, client_weight, loss_sum / client_weight,client_loss) \n</code></pre>\n<p>There are the following attributes in <code>client_output</code></p>\n<pre><code>weights_delta = attr.ib()\nclient_weight = attr.ib()\nmodel_output = attr.ib()\nclient_loss = attr.ib() \n</code></pre>\n<p>After that, I made the <code>client_output</code> in the form of a sequence through\n<code>collected_output = tff.federated_collect(client_output)</code> and <code>round_model_delta = tff.federated_map(selecting_fn,(collected_output,weight_denom))</code>in <a href=\"https://github.com/tensorflow/federated/blob/b13046fa47b2eab4f38c37fc41d7fba64f192bb1/tensorflow_federated/python/examples/simple_fedavg/simple_fedavg_tff.py#L111\" rel=\"nofollow noreferrer\">here</a> .</p>\n<pre><code>   @tff.federated_computation(federated_server_state_type,\n                           federated_dataset_type)\n\n    def run_one_round(server_state, federated_dataset):\n    \n    server_message = tff.federated_map(server_message_fn, server_state)\n    server_message_at_client = tff.federated_broadcast(server_message)\n\n    client_outputs = tff.federated_map(\n        client_update_fn, (federated_dataset, server_message_at_client))\n\n    weight_denom = client_outputs.client_weight\n\n    collected_output = tff.federated_collect(client_outputs)  # add        \n    \n    round_model_delta = tff.federated_map(selecting_fn,(collected_output,weight_denom)) #add       \n\n    server_state = tff.federated_map(server_update_fn,(server_state, round_model_delta))\n\n    round_loss_metric = tff.federated_mean(client_outputs.model_output, weight=weight_denom)\n\n    return server_state, round_loss_metric\n</code></pre>\n<p>Also, the following code is added <a href=\"https://github.com/tensorflow/federated/blob/3c0852c5fef375198f5931ce31fd97f2df9c4d05/tensorflow_federated/python/examples/simple_fedavg/simple_fedavg_tff.py#L107\" rel=\"nofollow noreferrer\">here</a> to implement the <code>selecting_fn</code> function.</p>\n<pre><code>@tff.tf_computation()  # append\ndef selecting_fn(collected_output,weight_denom):\n    #TODO\n    return round_model_delta\n</code></pre>\n<p>I am not sure if it is correct to write the code in the above way.\nI tried in various ways, but mainly <code>TypeError: The value to be mapped must be a FederatedType or implicitly convertible to a FederatedType (got a &lt;&lt;model_weights=&lt;trainable=&lt;float32[5,5,1,32],float32[32] ,float32[5,5,32,64],float32[64],float32[3136,512],float32[512],float32[512,10],float32[10]&gt;,non_trainable=&lt;&gt;&gt;,optimizer_state= &lt;int64&gt;,round_num=int32&gt;@SERVER,{&lt;float32[5,5,1,32],float32[32],float32[5,5,32,64],float32[64],float32[3136,512 ],float32[512],float32[512,10],float32[10]&gt;}@CLIENTS&gt;)</code> I get this error.</p>\n<p>I wonder how the sequence type <code>collected_output</code> accesses each client's <code>client_loss(= loss_sum)</code> and sorts them, and also wonders what method to use when calculating the weighted average with <code>weight_denom</code> applied.</p>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 199}]
[{"items": [{"tags": ["tensorflow", "tensorboard"], "owner": {"account_id": 18505883, "reputation": 141, "user_id": 13482179, "user_type": "registered", "profile_image": "https://www.gravatar.com/avatar/9f91dd26c535bb5c28ae9f48d1da95ab?s=256&d=identicon&r=PG&f=1", "display_name": "Frank", "link": "https://stackoverflow.com/users/13482179/frank"}, "is_answered": false, "view_count": 1369, "answer_count": 1, "score": 2, "last_activity_date": 1591653852, "creation_date": 1589183914, "question_id": 61724827, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/61724827/how-to-visualize-the-network-graph-in-tensorflow-1-15-with-eager-mode-using-tens", "title": "How to visualize the network graph in tensorflow 1.15 with Eager mode using tensorboard?", "body": "<p>Hi~ I want to visualize the NN in Eager mode in tf1.15 (can not switch to 2.0.0). And the implementation is based on low-level API of Tensorflow 1.15. I want to use the tensorboard to visualize it.\nI write a log tracing code but get the error:</p>\n\n<pre><code>WARNING:tensorflow:\nThe TensorFlow contrib module will not be included in TensorFlow 2.0.\nFor more information, please see:\n  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n  * https://github.com/tensorflow/addons\n  * https://github.com/tensorflow/io (for I/O related ops)\nIf you depend on functionality not listed there, please file an issue.\n\nTraceback (most recent call last):\n  File \"/home/frank/PycharmProjects/reconstruction_NN/my_test.py\", line 78, in &lt;module&gt;\n    tf.contrib.summary.trace_on(graph=True, profiler=True)\nAttributeError: module 'tensorflow.contrib.summary.summary' has no attribute 'trace_on'\n</code></pre>\n\n<h2>Environment information (required)</h2>\n\n<p>tensorboard          1.15.0<br>\ntensorflow-estimator 1.15.1<br>\ntensorflow-gpu       1.15.0<br>\nUbuntu16.04</p>\n\n<h2>Issue description</h2>\n\n<p>Code:</p>\n\n<pre><code>import tensorflow as tf\nfrom tensorflow.keras.layers import Dense, Flatten, Conv2D,Dropout\nfrom tensorflow.keras import Model\ntf.compat.v1.enable_eager_execution()\nprint(tf.__version__)\nprint(tf.executing_eagerly())\n\n\nmnist = tf.keras.datasets.mnist\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\n\nx_train, x_test = x_train / 255.0, x_test / 255.0\n\n\nbatch_size = 32\n\ntrain_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(10000).batch(batch_size)\ntest_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(batch_size)\n\n\nclass MyModel(Model):\n    def __init__(self):\n        super(MyModel, self).__init__()\n        self.flatten = Flatten()\n        self.d1 = Dense(128, activation='relu')\n        self.dropout = Dropout(0.5)\n        self.d2 = Dense(10, activation='softmax')\n\n    def call(self, x):\n        x = self.flatten(x)\n        x = self.d1(x)\n        x = self.dropout(x)\n        return self.d2(x)\n\nmodel = MyModel()\n\nloss_object = tf.keras.losses.SparseCategoricalCrossentropy()\noptimizer = tf.keras.optimizers.Adam()\n\ntrain_loss = tf.keras.metrics.Mean(name='train_loss')\ntrain_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n\ntest_loss = tf.keras.metrics.Mean(name='test_loss')\ntest_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')\n\n@tf.function\ndef train_step(images, labels):\n    with tf.GradientTape() as tape:\n        predictions = model(images)\n        loss = loss_object(labels, predictions)\n    gradients = tape.gradient(loss, model.trainable_variables)\n    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n\n    train_loss(loss)\n    train_accuracy(labels, predictions)\n\n@tf.function\ndef test_step(images, labels):\n    predictions = model(images)\n    t_loss = loss_object(labels, predictions)\n    test_loss(t_loss)\n    test_accuracy(labels, predictions)\n\n\nEPOCHS = 5\nfrom datetime import *\nstamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\nlogdir = 'logs/func/%s' % stamp\nwriter = tf.contrib.summary.create_file_writer(logdir)\ntf.summary.trace_on(graph=True, profiler=True)\n\nfor epoch in range(EPOCHS):\n\n    for images, labels in train_ds:\n\n        train_step(images, labels)\n\n    for test_images, test_labels in test_ds:\n        test_step(test_images, test_labels)\n\n    template = 'Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, Test Accuracy: {}'\n\n    print(template.format(epoch + 1, train_loss.result(),\n                              train_accuracy.result() * 100,\n                              test_loss.result(),\n                              test_accuracy.result() * 100))\nwith writer.as_default():\n  tf.summary.trace_export(\n      name=\"my_func_trace\",\n      step=0,\n      profiler_outdir=logdir)\n</code></pre>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 2}]
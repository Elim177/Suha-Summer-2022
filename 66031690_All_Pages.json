[{"items": [{"tags": ["python", "tensorflow", "keras", "subclassing", "generative-adversarial-network"], "owner": {"account_id": 17076538, "reputation": 71, "user_id": 12356030, "user_type": "registered", "profile_image": "https://i.stack.imgur.com/xdA0x.jpg?s=256&g=1", "display_name": "Revess", "link": "https://stackoverflow.com/users/12356030/revess"}, "is_answered": true, "view_count": 142, "answer_count": 1, "score": 0, "last_activity_date": 1612378498, "creation_date": 1612369833, "question_id": 66031690, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/66031690/how-to-stop-this-error-in-multi-gpu-custom-gan", "title": "How to stop this error in multi gpu custom GAN?", "body": "<p>I recently upgraded my rig and added a 1070 ti alongside my 1080 ti to speed up training. For regular models I am able to train way faster thanks to this. Rather I am trying to train a GAN algorithm that works on a single GPU, but I cannot get it to work on a multi GPU setup.\nI override tf.keras.Model and use a custom train_step, with some other functionalities. For the life of me, I cannot get this to run properly without getting the following error:</p>\n<pre><code>tensorflow.python.framework.errors_impl.InvalidArgumentError: 3 root error(s) found.\n  (0) Invalid argument:  Incompatible shapes: [8] vs. [16]\n         [[node add (defined at Users\\&lt;User&gt;\\OneDrive\\Documenten\\HKU\\Year 4\\PDP_and_SN\\Supportive Narrative\\Research\\Alpha_2\\lib\\NN.py:120) ]]\n         [[replica_1/sequential_1/batch_normalization_10/Greater/_96]]\n  (1) Invalid argument:  Incompatible shapes: [8] vs. [16]\n         [[node add (defined at Users\\&lt;User&gt;\\OneDrive\\Documenten\\HKU\\Year 4\\PDP_and_SN\\Supportive Narrative\\Research\\Alpha_2\\lib\\NN.py:120) ]]\n         [[Adam_1/AddN/_140]]\n  (2) Invalid argument:  Incompatible shapes: [8] vs. [16]\n         [[node add (defined at Users\\&lt;User&gt;\\OneDrive\\Documenten\\HKU\\Year 4\\PDP_and_SN\\Supportive Narrative\\Research\\Alpha_2\\lib\\NN.py:120) ]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_18178]\n</code></pre>\n<p>I use the following to create my model:</p>\n<pre><code>class GAN_Model(tf.keras.Model):\n    def __init__(self, generator, discriminator, latent_dim, batch_size):\n        super(GAN_Model, self).__init__()\n        self.discriminator = discriminator\n        self.generator = generator\n        self.latent_dim = latent_dim\n        self.batch_size = batch_size\n    \n    def compile(self, discriminator_optimizer, generator_optimizer, loss_function):\n        super(GAN_Model, self).compile()\n        self.discriminator_optimizer = discriminator_optimizer\n        self.generator_optimizer = generator_optimizer\n        self.loss_function = loss_function\n\n    def generator_loss(self, cross_entropy,fake_output):\n        return cross_entropy(tf.ones_like(fake_output), fake_output)\n\n    def discriminator_loss(self, cross_entropy, real_output, fake_output):\n        real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n        fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n        total_loss = real_loss + fake_loss\n        return total_loss\n\n    def train_step(self, real_audio):\n        random_latent_vectors = tf.random.normal(shape=(self.batch_size, self.latent_dim))\n\n        with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n            generated_images = self.generator(random_latent_vectors, training = True)\n            real_output = self.discriminator(real_audio[0], training = True)\n            fake_output = self.discriminator(generated_images, training = True)\n\n            g_loss = self.generator_loss(self.loss_function, fake_output)\n            d_loss = self.discriminator_loss(self.loss_function, real_output, fake_output)\n        \n        gradients_of_generator = gen_tape.gradient(g_loss, self.generator.trainable_variables)\n        gradients_of_discriminator = disc_tape.gradient(d_loss, self.discriminator.trainable_variables)\n\n        self.generator_optimizer.apply_gradients(zip(gradients_of_generator, self.generator.trainable_variables))\n        self.discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, self.discriminator.trainable_variables))\n        return {&quot;d_loss&quot;: d_loss, &quot;g_loss&quot;: g_loss, &quot;prediction&quot;: generated_images}\n\nmirrored_strategy = tf.distribute.MirroredStrategy(devices=[&quot;/gpu:0&quot;, &quot;/gpu:1&quot;],cross_device_ops=tf.distribute.HierarchicalCopyAllReduce())\n\nwith mirrored_strategy.scope():\n    generator = make_generator(latent_dim)\n    discriminator = make_discriminator(spectral_size)\n    g_opt = tf.keras.optimizers.Adam(0.0001,beta_1=0.5)\n    d_opt = tf.keras.optimizers.Adam(0.00012,beta_1=0.5)\n    loss_fn = tf.keras.losses.BinaryCrossentropy(from_logits=True,reduction=tf.keras.losses.Reduction.NONE)\n    gan = GAN_Model(generator,discriminator,latent_dim,batch_size)\n    gan.compile(\n        d_opt,\n        g_opt,\n        loss_fn,\n    )\n    ckpt = tf.train.Checkpoint(generator_optimizer=g_opt,\n                                discriminator_optimizer=d_opt,\n                                generator=generator,\n                                disciminator=discriminator)\n    manager = tf.train.CheckpointManager(ckpt, &quot;.\\\\data\\\\checkpoints\\\\&quot; + str(model_name), max_to_keep=15)\n\n    if restore_model:\n        ckpt.restore(manager.latest_checkpoint)\n        \ndataset = tf.data.experimental.load(dataset_dir,(tf.TensorSpec(shape=(spectral_size[0],spectral_size[1],spectral_size[2]), dtype=tf.double), tf.TensorSpec(shape=(2), dtype=tf.double)),compression=&quot;GZIP&quot;).batch(batch_size)\nprint(dataset)\n\nhistory = gan.fit(dataset, epochs=epochs, callbacks=[generate_and_save_audio(manager,model_name)])\n</code></pre>\n<p>The code is more extended than this, but somewhere here should be the essense of the problem.\nThanks!</p>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 219}]
[{"items": [{"tags": ["python", "numpy", "tensorflow"], "owner": {"account_id": 16773421, "reputation": 163, "user_id": 12125348, "user_type": "registered", "profile_image": "https://www.gravatar.com/avatar/ff9964bc5c0f2f40ed50188f3dc05e67?s=256&d=identicon&r=PG&f=1", "display_name": "V. Z", "link": "https://stackoverflow.com/users/12125348/v-z"}, "is_answered": true, "view_count": 59, "accepted_answer_id": 64714115, "answer_count": 1, "score": 0, "last_activity_date": 1604663339, "creation_date": 1604661894, "question_id": 64713721, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/64713721/feeding-multiple-inputs-and-outputs-in-the-tensor-model", "title": "Feeding multiple inputs and outputs in the tensor model?", "body": "<p>I have created multiple layer model, and now I would like to teach it with hundreds of values, so it can predict outputs from different inputs. But how should I implement those inputs? I tried now to make some array in array. And feed inputs and outputs one by one using training function. But it seems that on the second time its reteaching itself and it predicts only second answer rightly.  Maybe I dont understand the concept?</p>\n<pre><code>import tensorflow as tf\nimport numpy as np\n\nprint(&quot;TensorFlow version: {}&quot;.format(tf.__version__))\nprint(&quot;Eager execution: {}&quot;.format(tf.executing_eagerly()))\n\nx = np.array([[[10, 10, 30, 20], [20, 10, 20, 10],]])\n\ny = np.array([[[10, 10, 100, 10], [100, 10, 10, 10],]])\n\n\nclass Model(object):\n    def __init__(self, x, y):\n        # get random values.\n        self.W = tf.Variable(tf.random.normal((len(x), len(x[0][0]))))\n        self.b = tf.Variable(tf.random.normal((len(y),)))\n        self.W1 = tf.Variable(tf.random.normal((len(x), len(x[0][0]))))\n        self.b1 = tf.Variable(tf.random.normal((len(y),)))\n        self.W2 = tf.Variable(tf.random.normal((len(x), len(x[0][0]))))\n        self.b2 = tf.Variable(tf.random.normal((len(y),)))\n\n    def __call__(self, x):\n        out1 = tf.multiply(x, self.W) + self.b\n        out2 = tf.multiply(out1, self.W1) + self.b1\n        last_layer = tf.multiply(out2, self.W2) + self.b2\n        # Input_Leyer = self.W * x + self.b\n        return last_layer\n\n\ndef loss(predicted_y, desired_y):\n    return tf.reduce_sum(tf.square(predicted_y - desired_y))\n\n\noptimizer = tf.optimizers.Adam(0.1)\n\n\n# noinspection PyPep8Naming\ndef train(model, inputs, outputs):\n    with tf.GradientTape() as t:\n        current_loss = loss(model(inputs), outputs)\n    grads = t.gradient(current_loss, [model.W, model.b, model.W1, model.b1, model.W2, model.b2])\n    optimizer.apply_gradients(zip(grads, [model.W, model.b, model.W1, model.b1, model.W2, model.b2]))\n\n    print(current_loss)\n\n\nmodel = Model(x, y)\n\n\nfor i in range(5000):\n    train(model, x[0][0], y[0][0])\nfor i in range(10000):\n    train(model, x[0][1], y[0][1])\n\n\n\nfor i in range(3):\n    InputX = np.array([\n        [input(), input(), input(), input()],\n    ])\n    #returning = tf.math.multiply(InputX, model.W, name=None )\n    first = tf.multiply(InputX, model.W)\n    second = tf.multiply(first, model.W1)\n    returning = tf.multiply(second, model.W2)\n\n    print(&quot;I predict:&quot;, returning)\n</code></pre>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 262}]
[{"items": [{"tags": ["python", "tensorflow", "keras", "error-handling", "neural-network"], "owner": {"account_id": 15016059, "reputation": 55, "user_id": 12784078, "user_type": "registered", "profile_image": "https://graph.facebook.com/311487019708243/picture?type=large", "display_name": "Abhiram C D", "link": "https://stackoverflow.com/users/12784078/abhiram-c-d"}, "is_answered": false, "view_count": 1550, "answer_count": 0, "score": 3, "last_activity_date": 1628507218, "creation_date": 1628507218, "question_id": 68711028, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/68711028/how-to-solve-attributeerror-kerastensor-object-has-no-attribute-id", "title": "How to solve &quot; AttributeError: &#39;KerasTensor&#39; object has no attribute &#39;_id&#39; &quot;?", "body": "<p>I was training a network using RSS data. The network is trained after preprocessing the data.  But I am getting the error :</p>\n<pre><code>AttributeError: 'KerasTensor' object has no attribute '_id'\n</code></pre>\n<p>My model is shown below.</p>\n<pre><code>class DANN(Model):\n    def __init__(self):\n        super().__init__()\n\n        #Feature Extractor\n        self.feature_extractor_layer0 = Input(shape=(num_batch, num_features))\n        self.feature_extractor_layer1 = Dense(100, activation='relu')\n        self.feature_extractor_layer2 = Dense(100, activation='relu')\n\n        self.feature_extractor_layer3 = Dense(100, activation='relu')\n        self.feature_extractor_layer4 = Dropout(0.5)\n        self.feature_extractor_layer5 = Dense(100, activation='relu')\n        self.feature_extractor_layer6 = Dense(100, activation='relu')\n        \n        #Label Predictor\n        self.label_predictor_layer0 = Dense(100, activation='relu')\n        self.label_predictor_layer1 = Dense(100, activation='relu')\n        self.label_predictor_layer2 = Dense(2, activation=None)\n\n    def call(self, x):\n        #Feature Extractor\n        x = Input(shape=(num_features,))\n        x = self.feature_extractor_layer1(x)\n        x = self.feature_extractor_layer2(x)\n        \n        x = self.feature_extractor_layer3(x)\n        x = self.feature_extractor_layer4(x)\n        x = self.feature_extractor_layer5(x)\n        x = self.feature_extractor_layer6(x)\n\n        label_pred = self.label_predictor_layer0(x)\n        label_pred = self.label_predictor_layer1(label_pred)\n        label_pred = self.label_predictor_layer2(label_pred)\n    \n        return label_pred\n\n#creating a model object\n\nmodel = DANN()\n</code></pre>\n<p>My training loop is,</p>\n<pre><code>#initializing parameters before training the model\n\nlr = 1e-3\noptimizer = tf.optimizers.SGD()\n\nloss_fn_label = keras.losses.mean_squared_error\n\nmax_batches = len(dx_source)\nsource_label_loss = []\n\n#training loop\nfor epoch in range(num_epochs):\n    print(&quot;\\nStart of epoch %d&quot; % (epoch,))\n\n    for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n\n        with tf.GradientTape() as tape:\n\n            logits = model(x_batch_train, training=True)  # Logits for this minibatch\n\n            loss_value = loss_fn_label(y_batch_train, logits)\n\n\n        grads = tape.gradient(loss_value, model.trainable_weights)\n\n        optimizer.apply_gradients(zip(grads, model.trainable_weights))\n\n        while ep == ls[ls_i]:\n          sys.stdout.write(&quot;\u2588&quot;)\n          ls_i = ls_i+1\n          break\n        ep = ep+1\n  \n    sys.stdout.write(&quot;|&quot;)\n  \n    print(f'\\ts_label_loss: {loss_s_label:.4f}')\n    \n    source_label_loss.append(loss_s_label)\n</code></pre>\n<p>Please help me to solve his error.</p>\n<pre><code>dx_source_tensor = tf.convert_to_tensor(X_train_source, dtype=tf.float32)\ndy_source_tensor = tf.convert_to_tensor(Y_train_source, dtype=tf.float32)\n\ntrain_dataset_source = tf.data.Dataset.from_tensor_slices((dx_source_tensor, dy_source_tensor))\n\ndx_source_test_tensor = tf.convert_to_tensor(X_test_source, dtype=tf.float32)\ndy_source_test_tensor = tf.convert_to_tensor(Y_test_source, dtype=tf.float32)\n\ntest_dataset_source = tf.data.Dataset.from_tensor_slices((dx_source_test_tensor, dy_source_test_tensor))\n\n#training dataset\n\ntrain_source = tf.data.Dataset.from_tensor_slices(train_dataset_source).batch(num_batch)\n \n#testing dataset\n \ntest_source = tf.data.Dataset.from_tensor_slices(test_dataset_source).batch(num_batch)\n</code></pre>\n<p>This is how I have given the dataset input. This code was working for the MNIST dataset. But not showing the result for a normal row-by-row data frame. If you know any other methods to train these types of models. That is also acceptable for me. Thank you!</p>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 87}]
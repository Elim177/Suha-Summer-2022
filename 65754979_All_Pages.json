[{"items": [{"tags": ["tensorflow", "keras", "watch", "gradient-descent", "mnist"], "owner": {"account_id": 20470295, "reputation": 1, "user_id": 15020895, "user_type": "registered", "profile_image": "https://lh6.googleusercontent.com/-BLMKcQtISFE/AAAAAAAAAAI/AAAAAAAAAAA/AMZuuckx0eQvdJ_CCM55hEj9Q0olfL5gBA/s96-c/photo.jpg?sz=256", "display_name": "Jose Pius Nedumkallel", "link": "https://stackoverflow.com/users/15020895/jose-pius-nedumkallel"}, "is_answered": false, "view_count": 82, "answer_count": 0, "score": 0, "last_activity_date": 1610832923, "creation_date": 1610832923, "question_id": 65754979, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/65754979/how-to-watch-gradients-in-keras-for-mnist", "title": "How to watch gradients in Keras for MNIST", "body": "<p>I want to plot the gradients for each epoch and trying to obtain the values using gradient tape. But I am getting the following error.</p>\n<pre><code>batch_size = 128\nepochs = 15\nmodel.compile(loss=&quot;categorical_crossentropy&quot;, optimizer=&quot;adam&quot;, metrics=[&quot;accuracy&quot;])\nhistory = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)\nloss_val = history.history['loss']\nwith tf.GradientTape() as tape:\n    # Forward pass.\n    tape.watch(model.trainable_weights)\n    grads = tape.gradient(loss_val, model.trainable_weights)\n&quot;&quot;&quot;\n## Evaluate the trained model\n&quot;&quot;&quot;\nscore = model.evaluate(x_test, y_test, verbose=0)\nprint(&quot;Test loss:&quot;, score[0])\nprint(&quot;Test accuracy:&quot;, score[1])\n</code></pre>\n<p>I am getting the following error:</p>\n<pre><code>AttributeError                            Traceback (most recent call last)\n&lt;ipython-input-7-f04339bdcbcf&gt; in &lt;module&gt;\n     12     # Forward pass.\n     13     tape.watch(model.trainable_weights)\n---&gt; 14     grads = tape.gradient(loss_val, model.trainable_weights)\n     15 &quot;&quot;&quot;\n     16 ## Evaluate the trained model\n\n~/.conda/envs/tf/lib/python3.6/site-packages/tensorflow_core/python/eager/backprop.py in gradient(self, target, sources, output_gradients, unconnected_gradients)\n    983     flat_targets = []\n    984     for t in nest.flatten(target):\n--&gt; 985       if not t.dtype.is_floating:\n    986         logging.vlog(\n    987             logging.WARN, &quot;The dtype of the target tensor must be &quot;\n\nAttributeError: 'numpy.dtype' object has no attribute 'is_floating'\n</code></pre>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 263}]
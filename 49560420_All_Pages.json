[{"items": [{"tags": ["python", "tensorflow", "deep-learning", "keras"], "owner": {"account_id": 1987773, "reputation": 1216, "user_id": 1782553, "user_type": "registered", "accept_rate": 70, "profile_image": "https://www.gravatar.com/avatar/bc4d4fbae28ecd225bd84e7e8cb6fc5e?s=256&d=identicon&r=PG", "display_name": "Jav", "link": "https://stackoverflow.com/users/1782553/jav"}, "is_answered": true, "view_count": 610, "accepted_answer_id": 49575013, "answer_count": 1, "score": 5, "last_activity_date": 1522415111, "creation_date": 1522339109, "last_edit_date": 1592644375, "question_id": 49560420, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/49560420/deep-learning-implementation-in-tensorflow-or-keras-give-drastic-different-resul", "title": "Deep Learning implementation in Tensorflow or Keras give drastic different results", "body": "<p><em><strong>Context:</strong> I'm using a fully convolutional network to perform image segmentation. Typically, the input is an RGB image <code>shape = [512, 256]</code> and the target is a 2 channels binary mask defining the annotated regions (2nd channel is the opposite of the fist channel).</em></p>\n<p><strong>Question:</strong> I have the same CNN implementation using Tensorflow and Keras. But the Tensorflow model doesn't start learning. Actually, the <code>loss</code> even grows with the number of epochs! What is wrong in this Tensorflow implementation that prevents it from learning?</p>\n<p><strong>Setup:</strong> The dataset is split into 3 subsets: training (78%), testing (8%) and validation (14%) sets which are fed to the network by batches of 8 images. The graphs show the evolution of the <code>loss</code> for each subsets. The images show the <code>prediction</code> after 10 epoch for two different images.</p>\n<hr />\n<p><strong>Tensorflow</strong> implementation and results</p>\n<pre><code>import tensorflow as tf\n\ntf.reset_default_graph()\nx = inputs = tf.placeholder(tf.float32, shape=[None, shape[1], shape[0], 3])\ntargets = tf.placeholder(tf.float32, shape=[None, shape[1], shape[0], 2])\n\nfor d in range(4):\n    x = tf.layers.conv2d(x, filters=np.exp2(d+4), kernel_size=[3,3], strides=[1,1], padding=&quot;SAME&quot;, activation=tf.nn.relu)\n    x = tf.layers.max_pooling2d(x, strides=[2,2], pool_size=[2,2], padding=&quot;SAME&quot;)\n    \nx = tf.layers.conv2d(x, filters=2, kernel_size=[1,1])\nlogits = tf.image.resize_images(x, [shape[1], shape[0]], align_corners=True)\nprediction = tf.nn.softmax(logits)\n\nloss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=targets, logits=logits))\noptimizer = tf.train.RMSPropOptimizer(learning_rate=0.001).minimize(loss)\n\nsess = tf.Session()\nsess.run(tf.global_variables_initializer())\n\ndef run(mode, x_batch, y_batch):\n    if mode == 'TRAIN':\n        return sess.run([loss, optimizer], feed_dict={inputs: x_batch, targets: y_batch})\n    else:\n        return sess.run([loss, prediction], feed_dict={inputs: x_batch, targets: y_batch})\n</code></pre>\n<p><a href=\"https://i.stack.imgur.com/cTbWl.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/cTbWl.png\" alt=\"Tensorflow loss evolution\" /></a>\n<a href=\"https://i.stack.imgur.com/6Gbgm.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/6Gbgm.png\" alt=\"Tensorflow prediction after 10 epochs\" /></a></p>\n<hr />\n<p><strong>Keras</strong> implementation and reslults</p>\n<pre><code>import keras as ke\n\nke.backend.clear_session()\nx = inputs = ke.layers.Input(shape=[shape[1], shape[0], 3])\n\nfor d in range(4):\n    x = ke.layers.Conv2D(int(np.exp2(d+4)), [3,3], padding=&quot;SAME&quot;, activation=&quot;relu&quot;)(x)\n    x = ke.layers.MaxPool2D(padding=&quot;SAME&quot;)(x)\n\nx = ke.layers.Conv2D(2, [1,1], padding=&quot;SAME&quot;)(x)\nlogits = ke.layers.Lambda(lambda x: ke.backend.tf.image.resize_images(x, [shape[1], shape[0]], align_corners=True))(x)\nprediction = ke.layers.Activation('softmax')(logits)\n\nmodel = ke.models.Model(inputs=inputs, outputs=prediction)\nmodel.compile(optimizer=&quot;rmsprop&quot;, loss=&quot;categorical_crossentropy&quot;)\n\ndef run(mode, x_batch, y_batch):\n    if mode == 'TRAIN':\n        loss = model.train_on_batch(x=x_batch, y=y_batch)\n        return loss, None\n    else:\n        loss = model.evaluate(x=x_batch, y=y_batch, batch_size=None, verbose=0)\n        prediction = model.predict(x=x_batch, batch_size=None)\n        return loss, prediction\n</code></pre>\n<p><a href=\"https://i.stack.imgur.com/OXMFd.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/OXMFd.png\" alt=\"Keras loss evolution\" /></a>\n<a href=\"https://i.stack.imgur.com/O0f8E.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/O0f8E.png\" alt=\"Keras prediction after 10 epochs\" /></a></p>\n<hr />\n<p>There must be a difference between the two but my understanding of the documentation lead me nowhere. I would be really interested to know where the difference lies. Thanks in advance!</p>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 281}]
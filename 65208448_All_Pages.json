[{"items": [{"tags": ["python", "tensorflow", "keras"], "owner": {"account_id": 528061, "reputation": 110, "user_id": 1864220, "user_type": "registered", "profile_image": "https://www.gravatar.com/avatar/67071a7cbdeca64a11ce6362e772e75d?s=256&d=identicon&r=PG", "display_name": "Dan", "link": "https://stackoverflow.com/users/1864220/dan"}, "is_answered": true, "view_count": 688, "accepted_answer_id": 65348695, "answer_count": 1, "score": 1, "last_activity_date": 1608240998, "creation_date": 1607470059, "last_edit_date": 1607471040, "question_id": 65208448, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/65208448/how-to-use-multiple-models-in-keras-model-subclass-api", "title": "How to use multiple models in Keras model subclass API", "body": "<p>I am trying to train a fairly complex model that uses multiple frozen pre-trained models and has a custom training loop with a fairly complicated multi-task loss function. Because of these complexities, my plan was to define multiple separate Keras models within the subclassed model. I have been having problems with my setup and I've been able to simplify it to a simple example that demonstrates the problem.</p>\n<p>The code below trains a simple model called <code>MainModel</code>, which uses the Keras model subclassing API, but it is basically just a <code>Sequential([Conv1d(), Conv1d()])</code> model. When I define another model in the same class, <code>self.aux_model</code>, the original model no longer trains properly. In the example, <code>self.aux_model</code> doesn't play any role in the training, it is only defined, never used. Specifically, after each training iteration, the weight values are the same as they were at the beginning of the iteration. So, the model weights are never updated, even though the gradients have non-zero values.</p>\n<pre class=\"lang-py prettyprint-override\"><code>import numpy as np\nimport tensorflow as tf\nfrom tensorflow.python.keras.callbacks import Callback\n\nnum_epochs = 5\nsteps_per_epoch = 100\naudio_len = 16000\n\n\nclass WeightChecker:\n    &quot;&quot;&quot;Automated health checks for training Keras models.&quot;&quot;&quot;\n    def __init__(self, model):\n        self.initial_model = model\n        self.var_names = [var.name for var in model.trainable_variables]\n        self.prev_weights = model.get_weights()\n\n    def check_epoch(self, model):\n        &quot;&quot;&quot;Checks to run at the end of an epoch&quot;&quot;&quot;\n        self.check_untrained_params(model)\n\n    def check_untrained_params(self, model):\n        &quot;&quot;&quot;Compare self.model.trainable_variables to self.prev_weights&quot;&quot;&quot;\n        passed = True\n        curr_weights = model.get_weights()\n        for curr_var, prev_var, var_name in zip(curr_weights, self.prev_weights, self.var_names):\n            eq = np.equal(curr_var, prev_var).all()\n            if eq:\n                passed = False\n                print(f&quot;\\nWarning: Variable {var_name} was not updated with training. &quot;\n                      f&quot;Confirm that this layer is correctly &quot;\n                      f&quot;connected to the computation graph.&quot;)\n        self.prev_weights = [w.copy() for w in curr_weights]\n        return passed\n\n\nclass WeightCheckerCallback(Callback):\n    &quot;&quot;&quot;Check model initialization and run training checks.\n    &quot;&quot;&quot;\n    def __init__(self):\n        super().__init__()\n        self.weight_check = None\n\n    def setup_weight_checker(\n            self,\n            model: tf.keras.Model = None):\n        &quot;&quot;&quot;Initialize the callback with an input_batch and targets.&quot;&quot;&quot;\n        self.weight_check = WeightChecker(model)\n\n    def on_train_begin(self, logs=None):\n        if self.weight_check is None:\n            raise ValueError(&quot;setup_weight_checker() must be called to use WeightCheckerCallback.&quot;)\n\n    def on_epoch_end(self, epoch, logs=None):\n        self.weight_check.check_epoch(self.model)\n\n\nclass MainModel(tf.keras.Model):\n    &quot;&quot;&quot;Main Model.&quot;&quot;&quot;\n    def __init__(self):\n        super().__init__()\n        self.feature_dim = 128\n        self.aux_model = self._set_aux_model()\n\n        self.map_model = tf.keras.Sequential([tf.keras.layers.Conv1D(\n                64, 3, padding='same'\n            ),\n            tf.keras.layers.Conv1D(\n                1, 3, padding='same'\n            )])\n\n    def call(self, inputs, training=True):\n        output = self.map_model(inputs)\n        return output\n\n    def train_step(self, data):\n        mixed_audio = data[0]\n        clean_audio = data[1]\n\n        with tf.GradientTape() as tape:\n            decoded_audio = self.map_model(mixed_audio)\n            total_loss = tf.reduce_mean(tf.abs(decoded_audio - clean_audio))\n\n        grads = tape.gradient(total_loss, self.trainable_variables)\n        self.optimizer.apply_gradients(zip(grads, self.trainable_variables))\n\n        losses = {\n            'loss': total_loss,\n        }\n        return losses\n\n    @staticmethod\n    def _set_aux_model():\n        &quot;&quot;&quot;Set an auxiliary model.&quot;&quot;&quot;\n        model = tf.keras.Sequential([tf.keras.layers.Dense(1)])\n        model.build(input_shape=(None, 1))\n\n        model.trainable = False\n        return model\n\n\nclass TrainingTask:\n    &quot;&quot;&quot;A Keras model training task.&quot;&quot;&quot;\n    def __init__(self):\n        self.model, self.stateful_model = self._set_model()\n        self.callbacks = [WeightCheckerCallback()]\n\n    @staticmethod\n    def _set_model():\n        model = MainModel()\n\n        # Build the model with fake data.\n        model.compile(optimizer='adam')\n        fake_data = np.random.randn(1,\n                                    audio_len,\n                                    1)\n        fake_data = fake_data.astype(np.float32)\n        model(fake_data, training=True)\n\n        return model, None\n\n    def fit(self):\n        &quot;&quot;&quot;Custom model fit method.&quot;&quot;&quot;\n        try:\n            weight_checker_callback_index = [isinstance(cb, WeightCheckerCallback)\n                                             for cb in self.callbacks].index(True)\n        except ValueError:\n            weight_checker_callback_index = None\n        if weight_checker_callback_index is not None:\n            self.callbacks[weight_checker_callback_index].setup_weight_checker(\n                model=self.model\n            )\n\n        for callback in self.callbacks:\n            callback.set_model(self.model)\n\n        print(&quot;\\nBegin training&quot;)\n\n        for callback in self.callbacks:\n            callback.on_train_begin()\n\n        for epoch in range(num_epochs):\n\n            for callback in self.callbacks:\n                callback.on_epoch_begin(epoch)\n\n            for batch in range(steps_per_epoch):\n                x, y = next(data_gen_batch())\n\n                for callback in self.callbacks:\n                    callback.on_batch_begin(batch)\n\n                metrics = self.model.train_step([x, y])\n                batch_loss = np.mean(metrics.pop('loss'))\n\n                print(batch, epoch, batch_loss)\n\n                for callback in self.callbacks:\n                    callback.on_batch_end(batch, metrics)\n\n            print(f'Epoch: {epoch}')\n\n            numeric_metrics = dict()\n            numeric_metrics['loss'] = batch_loss\n            for callback in self.callbacks:\n                callback.on_epoch_end(epoch, numeric_metrics)\n\n\ndef data_gen():\n    &quot;&quot;&quot;Generate random data for training.&quot;&quot;&quot;\n    data = (np.random.random((audio_len, 1)), np.random.random((audio_len, 1)))\n    while True:\n        yield data\n\n\ndef data_gen_batch(batch_size=8):\n    &quot;&quot;&quot;Generate random data in batches for training.&quot;&quot;&quot;\n    data = next(data_gen())\n    data_batch = (np.stack([data[0]] * batch_size, axis=0),\n                  np.stack([data[1]] * batch_size, axis=0))\n    while True:\n        yield data_batch\n\n\nif __name__ == '__main__':\n    task = TrainingTask()\n    task.fit()\n</code></pre>\n<p>The classes <code>WeightCheckerCallback</code> and <code>WeightChecker</code> are a callback that I defined to illustrate the problem, which would otherwise result in a silent failure. In addition to some output from each training step, the code will produce the following warnings about layers of the <code>map_model</code>, which should be updating (<code>aux_model</code> only has a <code>Dense</code> layer):</p>\n<pre><code>Warning: Variable main_model/sequential_1/conv1d/kernel:0 was not updated with training. Confirm that this layer is correctly connected to the computation graph.\nWarning: Variable main_model/sequential_1/conv1d/bias:0 was not updated with training. Confirm that this layer is correctly connected to the computation graph.\n</code></pre>\n<p>However, if the <code>aux_model</code> is commented out, the warnings will not appear and the model weights will be updated as expected.</p>\n<pre class=\"lang-py prettyprint-override\"><code>        # self.aux_model = self._set_aux_model()\n</code></pre>\n<p>Obviously, there are several ways in tensorflow to get this simple Sequential model to train properly, so I'm not just looking for a workaround to get this particular example working. Rather, I'm hoping that someone can explain what is going on with this example in terms of the Tensorflow sessions and graphs involved, as well as what the best practices are for avoiding conflicts between multiple different Keras models when nesting them with the subclass API. My ultimate goal is to train a more complex system of models using a similar framework.</p>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 27}]
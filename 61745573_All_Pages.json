[{"items": [{"tags": ["tensorflow2.0"], "owner": {"account_id": 18559013, "reputation": 11, "user_id": 13523418, "user_type": "registered", "profile_image": "https://www.gravatar.com/avatar/d6db3c607cc6da152f82c7e4efbb47a3?s=256&d=identicon&r=PG&f=1", "display_name": "Leo2020", "link": "https://stackoverflow.com/users/13523418/leo2020"}, "is_answered": false, "view_count": 524, "answer_count": 0, "score": 1, "last_activity_date": 1589266424, "creation_date": 1589266424, "question_id": 61745573, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/61745573/regularization-with-customized-training-in-tf-keras-tf2-0", "title": "regularization with customized training in tf.keras (TF2.0)", "body": "<p>I have a keras model with regularization initialized with kernel_regularizer. In the customized training loop, where GradientTape is used, does optimizer.apply_gradients applies regularization loss automatically? if not, the following code shows an implementation, is that a good way to apply regularization? Am I doing the right way?</p>\n\n<pre><code>def GetModel():\n    inputs = Input(shape=(784,), name='digits')\n    x = Dense(64, activation='relu', kernel_regularizer=l2(1e-4))(inputs)\n    x = Dense(64, activation='relu', kernel_regularizer=l2(1e-4))(x)\n    outputs = Dense(10, name='predictions')(x)\n    model = Model(inputs=inputs, outputs=outputs)\n    return model\n\nmymodel = GetModel()\n\n@tf.function\ndef train_step(x, y_true, optimizer):   \n    with tf.GradientTape() as tape:\n        y_pred = mymodel(x, training=True)\n        loss_training = my_custom_loss_function(y_true, y_pred)\n        loss_regularization = tf.math.add_n(mymodel.losses)\n        loss_total = loss_training + loss_regularization\n\n    gradients = tape.gradient(loss_total, mymodel.trainable_variables)\n    optimizer.apply_gradients(zip(gradients, mymodel.trainable_variables))\n    return loss_total\n</code></pre>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 142}]
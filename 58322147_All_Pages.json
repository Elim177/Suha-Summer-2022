[{"items": [{"tags": ["python", "tensorflow", "keras", "heatmap", "tensorflow2.0"], "owner": {"account_id": 242560, "reputation": 9473, "user_id": 514149, "user_type": "registered", "accept_rate": 80, "profile_image": "https://i.stack.imgur.com/eATtl.png?s=256&g=1", "display_name": "Matthias", "link": "https://stackoverflow.com/users/514149/matthias"}, "is_answered": true, "view_count": 13537, "accepted_answer_id": 58323113, "answer_count": 2, "score": 6, "last_activity_date": 1612944516, "creation_date": 1570707840, "last_edit_date": 1570716665, "question_id": 58322147, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/58322147/how-to-generate-cnn-heatmaps-using-built-in-keras-in-tf2-0-tf-keras", "title": "How to generate CNN heatmaps using built-in Keras in TF2.0 (tf.keras)", "body": "<p>I used to generate heatmaps for my Convolutional Neural Networks, based on the stand-alone Keras library on top of TensorFlow 1. That worked fine, however, after my switch to TF2.0 and built-in <code>tf.keras</code> implementation (with <a href=\"https://www.tensorflow.org/guide/eager\" rel=\"noreferrer\">eager execution</a>) I cannot use my old heatmap generation code any longer.</p>\n\n<p>So I re-wrote parts of my code for TF2.0 and ended up with the following:</p>\n\n<pre><code>from tensorflow.keras.applications.vgg16 import preprocess_input\nfrom tensorflow.keras.preprocessing.image import load_img\nfrom tensorflow.keras.models import load_model\n\nfrom tensorflow.keras import preprocessing\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras import models\n\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport numpy as np\n\nimage_size = 150\nimage_path = \"/tmp/images/test-image.jpg\"\nmodel_path = \"/tmp/models/prototype/basic_vgg16.h5\"\n\n# Load pre-trained Keras model and the image to classify\nmodel = load_model(model_path)  # VGG16 CNN with custom classifier head\nimage = load_img(image_path, target_size=(image_size, image_size))\nimg_tensor = preprocessing.image.img_to_array(image)\nimg_tensor = np.expand_dims(img_tensor, axis=0)\nimg_tensor = preprocess_input(img_tensor)\n\ninput_layer = model.get_layer(\"model_input\")\nconv_layer = model.get_layer(\"block5_conv3\")\nheatmap_model = models.Model([model.inputs], [conv_layer.output, model.output])\n\n# Get gradient of the winner class w.r.t. the output of the (last) conv. layer\nwith tf.GradientTape() as gtape:\n    conv_output, predictions = heatmap_model(img_tensor)\n    loss = predictions[:, np.argmax(predictions[0])]\n    grads = gtape.gradient(loss, conv_output)\n    pooled_grads = K.mean(grads, axis=(0, 1, 2))\n\n# Get values of pooled grads and model conv. layer output as Numpy arrays\niterate = K.function([model.inputs], [pooled_grads, conv_layer.output[0]])\npooled_grads_value, conv_layer_output_value = iterate([img_tensor])\n\n# Multiply each channel in the feature-map array by \"how important it is\"\nfor i in range(pooled_grads_value.shape[0]):\n    conv_layer_output_value[:, :, i] *= pooled_grads_value[i]\n\n# Channel-wise mean of resulting feature-map is the heatmap of class activation\nheatmap = np.mean(conv_layer_output_value, axis=-1)\nheatmap = np.maximum(heatmap, 0)\nmax_heat = np.max(heatmap)\nif max_heat == 0:\n    max_heat = 1e-10\nheatmap /= max_heat\n\n# Render heatmap via pyplot\nplt.matshow(heatmap)\nplt.show()\n</code></pre>\n\n<p>But now the following line:</p>\n\n<pre><code>iterate = K.function([model.inputs], [pooled_grads, conv_layer.output[0]])\n</code></pre>\n\n<p>leads to this error message:</p>\n\n<pre><code>AttributeError: Tensor.op is meaningless when eager execution is enabled.\n</code></pre>\n\n<p>I always used Keras and did not work with TF directly, so I am bit lost here.<br>\nAny ideas what could be the problem here?</p>\n\n<hr>\n\n<p>PS: If you want to c&amp;p this code, you can create the VGG16-based model like so:</p>\n\n<pre><code># Create Keras model from pre-trained VGG16 and custom classifier\ninput_layer = layers.Input(shape=(image_size, image_size, 3), name=\"model_input\")\nvgg16_model = VGG16(weights=\"imagenet\", include_top=False, input_tensor=input_layer)\nmodel_head = vgg16_model.output\nmodel_head = layers.Flatten(name=\"model_head_flatten\")(model_head)\nmodel_head = layers.Dense(256, activation=\"relu\")(model_head)\nmodel_head = layers.Dense(3, activation=\"softmax\")(model_head)\nmodel = models.Model(inputs=input_layer, outputs=model_head)\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=optimizers.Adam(), metrics=[\"accuracy\"])\n</code></pre>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 32}]
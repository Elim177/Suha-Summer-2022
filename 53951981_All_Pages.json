[{"items": [{"tags": ["python", "tensorflow"], "owner": {"account_id": 3948330, "reputation": 5043, "user_id": 3259896, "user_type": "registered", "accept_rate": 60, "profile_image": "https://www.gravatar.com/avatar/641c30a7b383022f22b53c8cedb04e3f?s=256&d=identicon&r=PG&f=1", "display_name": "SantoshGupta7", "link": "https://stackoverflow.com/users/3259896/santoshgupta7"}, "is_answered": true, "view_count": 2230, "accepted_answer_id": 53974023, "answer_count": 1, "score": 0, "last_activity_date": 1546124825, "creation_date": 1545953313, "last_edit_date": 1546047082, "question_id": 53951981, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/53951981/tensorflow-how-to-remove-padding-specific-values-from-tensor", "title": "Tensorflow, how to remove padding (specific values) from tensor", "body": "<p>I am using the dataset API to batch data from a tfrecords file. The data has varying length rows. Since in order to use the <code>batch()</code> function all the rows need to be equal size, I need to use <code>padded_batch()</code> instead. This paddes all the rows within a batch to match the size of the biggest row in the batch.</p>\n\n<p>After the batching, is there a way to remove these padded values? </p>\n\n<p>Here is a minimal example where I use '-1' as the padded values</p>\n\n<pre><code>import math\nimport numpy as np\nimport tensorflow as tf\n\nimport math\nimport numpy as np\nimport tensorflow as tf\n\n#Set up data\ncells = np.array([[0,1,2,3], [2,3,4], [3,6,5,4,3], [3,9]])\nmells = np.array([[0], [2], [3], [9]])\nprint(cells)\n\n#Write data to tfrecords\nwriter = tf.python_io.TFRecordWriter('test.tfrecords')\nfor index in range(mells.shape[0]):\n    example = tf.train.Example(features=tf.train.Features(feature={\n        'num_value':tf.train.Feature(int64_list=tf.train.Int64List(value=mells[index])),\n        'list_value':tf.train.Feature(int64_list=tf.train.Int64List(value=cells[index]))\n    }))\n    writer.write(example.SerializeToString())\nwriter.close()\n\n#Open tfrecords using dataset api and batch data\nfilenames = [\"test.tfrecords\"]\ndataset = tf.data.TFRecordDataset(filenames)\ndef _parse_function(example_proto):\n    keys_to_features = {'num_value':tf.VarLenFeature(tf.int64),\n                        'list_value':tf.VarLenFeature(tf.int64)}\n    parsed_features = tf.parse_single_example(example_proto, keys_to_features)\n    return tf.sparse.to_dense(parsed_features['num_value']), \\\n           tf.sparse.to_dense(parsed_features['list_value'])\n# Parse the record into tensors.\ndataset = dataset.map(_parse_function)\n# Shuffle the dataset\ndataset = dataset.shuffle(buffer_size=1)\n# Repeat the input indefinitly\ndataset = dataset.repeat()  \n# Generate batches\ndataset = dataset.padded_batch(3, padded_shapes=([None],[None]), padding_values=(tf.constant(-1, dtype=tf.int64)\n                                                 ,tf.constant(-1, dtype=tf.int64)))\niterator = dataset.make_one_shot_iterator()\ni, data = iterator.get_next()\n\nwith tf.Session() as sess:\n    print(sess.run([i, data]))\n    print(sess.run([i, data]))\n</code></pre>\n\n<p>What I have tried so far is to use a boolean mask, described here <a href=\"https://stackoverflow.com/questions/42194051/filter-out-non-zero-values-in-a-tensor\">Filter out non-zero values in a tensor</a></p>\n\n<p>However, my attempt just flattens all the tensors in the batch. Here is the code I used</p>\n\n<pre><code>filenames = [\"test.tfrecords\"]\ndataset = tf.data.TFRecordDataset(filenames)\ndef _parse_function(example_proto):\n    keys_to_features = {'num_value':tf.VarLenFeature(tf.int64),\n                        'list_value':tf.VarLenFeature(tf.int64)}\n    parsed_features = tf.parse_single_example(example_proto, keys_to_features)\n    return tf.sparse.to_dense(parsed_features['num_value']), \\\n           tf.sparse.to_dense(parsed_features['list_value'])\n# Parse the record into tensors.\ndataset = dataset.map(_parse_function)\n# Shuffle the dataset\ndataset = dataset.shuffle(buffer_size=1)\n# Repeat the input indefinitly\ndataset = dataset.repeat()  \n# Generate batches\ndataset = dataset.padded_batch(3, padded_shapes=([None],[None]), padding_values=(tf.constant(-1, dtype=tf.int64)\n                                                 ,tf.constant(-1, dtype=tf.int64)))\n# Create a one-shot iterator\niterator = dataset.make_one_shot_iterator()\ni, data = iterator.get_next()\n\nneg1 = tf.constant(-1, dtype=tf.int64)\nwhere1 = tf.not_equal(data, neg1)\n\nresult=tf.boolean_mask( data , where1)\n\nwith tf.Session() as sess:\n    print(sess.run([data, result ]))\n</code></pre>\n\n<p>And this is the result</p>\n\n<pre><code>[array([[ 0,  1,  2,  3, -1],\n       [ 2,  3,  4, -1, -1],\n       [ 3,  6,  5,  4,  3]]), array([0, 1, 2, 3, 2, 3, 4, 3, 6, 5, 4, 3])]\n</code></pre>\n\n<p>I need sometime that preserved the shape of the tensors. So the result would be something like</p>\n\n<pre><code>array([[ 0,  1,  2,  3],\n           [ 2,  3,  4],\n           [ 3,  6,  5,  4,  3]])\n</code></pre>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 63}]
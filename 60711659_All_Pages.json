[{"items": [{"tags": ["python", "tensorflow", "machine-learning"], "owner": {"user_type": "does_not_exist", "display_name": "user13072350"}, "is_answered": false, "view_count": 141, "answer_count": 1, "score": 2, "last_activity_date": 1589037365, "creation_date": 1584384673, "question_id": 60711659, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/60711659/transforming-a-tf-data-dataset", "title": "Transforming a tf.data.dataset", "body": "<p>Let's say i have as source data a dataset of 32*32*3 images of type:</p>\n\n<p><code>&lt;DatasetV1Adapter shapes: {coarse_label: (), image: (32, 32, 3), label: ()}, types: {coarse_label: tf.int64, image: tf.uint8, label: tf.int64}&gt;</code></p>\n\n<p>After serializing the data i get:</p>\n\n<pre><code>&lt;MapDataset shapes: {depth: (), height: (), image_raw: (), label: (), width: ()}, types: {depth: tf.int64, height: tf.int64, image_raw: tf.string, label: tf.int64, width: tf.int64}&gt;\n</code></pre>\n\n<p>I can access each element using this piece of code:</p>\n\n<pre><code>for i in parsed_image_dataset.take(1):\n  j=i['image_raw']\narray_shape = e1['image'].numpy().shape\nprint(np.frombuffer(j.numpy(), dtype = 'uint8').reshape(array_shape))\n</code></pre>\n\n<p>where <code>e1</code> has be generated using <code>get_next</code> in the original dataset.So as expected the print prints an identical image to the one pre-serialization.However instead of doing this element by element could i somehow transform my serialized dataset immediatly into the original <code>uint8</code> one?</p>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 294}]
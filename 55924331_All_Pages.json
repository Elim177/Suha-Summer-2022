[{"items": [{"tags": ["python", "tensorflow", "keras", "backpropagation", "tensorflow2.0"], "owner": {"account_id": 4608321, "reputation": 654, "user_id": 4352606, "user_type": "registered", "accept_rate": 92, "profile_image": "https://graph.facebook.com/100002363644960/picture?type=large", "display_name": "Tai Christian", "link": "https://stackoverflow.com/users/4352606/tai-christian"}, "is_answered": true, "view_count": 2617, "accepted_answer_id": 56039605, "answer_count": 2, "score": 7, "last_activity_date": 1596097268, "creation_date": 1556638428, "last_edit_date": 1557835711, "question_id": 55924331, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/55924331/how-to-apply-guided-backprop-in-tensorflow-2-0", "title": "How to apply Guided BackProp in Tensorflow 2.0?", "body": "<p>I am starting with <code>Tensorflow 2.0</code> and trying to implement Guided BackProp to display Saliency Map. I started by computing the loss between <code>y_pred</code> and <code>y_true</code> of an image, then find gradients of all layers due to this loss. </p>\n\n<pre><code>with tf.GradientTape() as tape:\n    logits = model(tf.cast(image_batch_val, dtype=tf.float32))\n    print('`logits` has type {0}'.format(type(logits)))\n    xentropy = tf.nn.softmax_cross_entropy_with_logits(labels=tf.cast(tf.one_hot(1-label_batch_val, depth=2), dtype=tf.int32), logits=logits)\n    reduced = tf.reduce_mean(xentropy)\n    grads = tape.gradient(reduced, model.trainable_variables)\n</code></pre>\n\n<p>However, I don't know what to do with gradients in order to obtain the Guided Propagation.</p>\n\n<p>This is my model. I created it using Keras layers:</p>\n\n<pre><code>image_input = Input((input_size, input_size, 3))\n\nconv_0 = Conv2D(32, (3, 3), padding='SAME')(image_input)\nconv_0_bn = BatchNormalization()(conv_0)\nconv_0_act = Activation('relu')(conv_0_bn)\nconv_0_pool = MaxPool2D((2, 2))(conv_0_act)\n\nconv_1 = Conv2D(64, (3, 3), padding='SAME')(conv_0_pool)\nconv_1_bn = BatchNormalization()(conv_1)\nconv_1_act = Activation('relu')(conv_1_bn)\nconv_1_pool = MaxPool2D((2, 2))(conv_1_act)\n\nconv_2 = Conv2D(64, (3, 3), padding='SAME')(conv_1_pool)\nconv_2_bn = BatchNormalization()(conv_2)\nconv_2_act = Activation('relu')(conv_2_bn)\nconv_2_pool = MaxPool2D((2, 2))(conv_2_act)\n\nconv_3 = Conv2D(128, (3, 3), padding='SAME')(conv_2_pool)\nconv_3_bn = BatchNormalization()(conv_3)\nconv_3_act = Activation('relu')(conv_3_bn)\n\nconv_4 = Conv2D(128, (3, 3), padding='SAME')(conv_3_act)\nconv_4_bn = BatchNormalization()(conv_4)\nconv_4_act = Activation('relu')(conv_4_bn)\nconv_4_pool = MaxPool2D((2, 2))(conv_4_act)\n\nconv_5 = Conv2D(128, (3, 3), padding='SAME')(conv_4_pool)\nconv_5_bn = BatchNormalization()(conv_5)\nconv_5_act = Activation('relu')(conv_5_bn)\n\nconv_6 = Conv2D(128, (3, 3), padding='SAME')(conv_5_act)\nconv_6_bn = BatchNormalization()(conv_6)\nconv_6_act = Activation('relu')(conv_6_bn)\n\nflat = Flatten()(conv_6_act)\n\nfc_0 = Dense(64, activation='relu')(flat)\nfc_0_bn = BatchNormalization()(fc_0)\n\nfc_1 = Dense(32, activation='relu')(fc_0_bn)\nfc_1_drop = Dropout(0.5)(fc_1)\n\noutput = Dense(2, activation='softmax')(fc_1_drop)\n\nmodel = models.Model(inputs=image_input, outputs=output)\n</code></pre>\n\n<p>I am glad to provide more code if needed.</p>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 51}]
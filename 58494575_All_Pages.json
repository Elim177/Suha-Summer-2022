[{"items": [{"tags": ["numpy", "keras", "tensorflow2.0"], "owner": {"account_id": 108161, "reputation": 5951, "user_id": 287238, "user_type": "registered", "accept_rate": 75, "profile_image": "https://i.stack.imgur.com/oQJH2.jpg?s=256&g=1", "display_name": "mathtick", "link": "https://stackoverflow.com/users/287238/mathtick"}, "is_answered": false, "view_count": 715, "answer_count": 0, "score": 0, "last_activity_date": 1571936411, "creation_date": 1571694589, "last_edit_date": 1571936411, "question_id": 58494575, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/58494575/inference-speed-in-tensorflow-2-0-cpu-for-simple-models-vanilla-tensorflow-nu", "title": "Inference speed in tensorflow 2.0 (CPU) for simple models? Vanilla tensorflow/numpy is still 50x faster?", "body": "<p>Am finding that tensorflow keras (2.0) is still quite slow compared to numpy. Is tfdeploy still in use? What are the options for getting close to numpy speed in inference? </p>\n\n<p>UPDATE:</p>\n\n<p>Here is a cleaned up example showing three methods on a different machine. The tf.function wrapped tensorflow call is now 8x vanilla numpy which is possibly reasonable but still feels like there is some overhead to chase.</p>\n\n<pre><code>import tensorflow as tf\nimport numpy as np\n\nx = tf.convert_to_tensor(np.random.randn(1, 12).astype(np.float32)) # YES! one row only\nxnumpy = x.numpy()\nmodel = tf.keras.models.Sequential([\n    tf.keras.layers.Dense(16, use_bias=False) for i in range(10)\n    ])\n\n@tf.function\ndef f(x):\n    return model(x)\n\n\ndef chain_layers_tf(x, kernels):\n    y = x\n    for kernel in kernels:\n        y = tf.matmul(y, kernel)\n    return y\n\n# call once\nf(x)\nchain_layers_tf_wrapped = tf.function(chain_layers_tf)\n\nkernels_tf = [x.kernel for x in model.layers]\nkernels_np = [x.kernel.numpy() for x in model.layers]\n\nchain_layers_tf_wrapped(x, kernels_np)\nchain_layers_tf_wrapped(x, kernels_tf)\n\ndef chain_layers_np(x, kernels):\n    y = x\n    for kernel in kernels:\n        y = y.dot(kernel)\n    return y\n\nmodel(x)\n\n\"\"\"\n%timeit t.model(t.x)\n%timeit t.f(t.x)\n%timeit t.chain_layers_tf(t.x, t.kernels_tf)\n%timeit t.chain_layers_tf_wrapped(t.x, t.kernels_tf)\n%timeit t.chain_layers_np(t.xnumpy, t.kernels_np)\n\"\"\"\n\n# In [107]: %timeit t.model(t.x)\n#      ...: %timeit t.f(t.x)\n#      ...: %timeit t.chain_layers_tf(t.x, t.kernels_tf)\n#      ...: %timeit t.chain_layers_tf_wrapped(t.x, t.kernels_tf)\n#      ...: %timeit t.chain_layers_np(t.xnumpy, t.kernels_np)\n# 1.51 ms \u00b1 1.73 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 1000 loops each)\n# 131 \u00b5s \u00b1 856 ns per loop (mean \u00b1 std. dev. of 7 runs, 10000 loops each)\n# 491 \u00b5s \u00b1 1.17 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 1000 loops each)\n# 417 \u00b5s \u00b1 1.53 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 1000 loops each)\n# 5.21 \u00b5s \u00b1 7.56 ns per loop (mean \u00b1 std. dev. of 7 runs, 100000 loops each)\n</code></pre>\n\n<p>Previous notes:</p>\n\n<p><a href=\"https://i.stack.imgur.com/nzNiy.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/nzNiy.png\" alt=\"enter image description here\"></a></p>\n\n<p>UPDATE: </p>\n\n<pre><code>Not just numpy as above, but tensorflow is faster than tensorflow.keras\n\nIn [22]: x = np.random.randn(100, 12).astype(np.float32)\n\nIn [23]: a = np.random.randn(12, 16).astype(np.float32)\n\nIn [24]: %timeit tf.matmul(x, a)\n39.3 \u00b5s \u00b1 98.5 ns per loop (mean \u00b1 std. dev. of 7 runs, 10000 loops each)\n\n\nUPDATE: \n\nmore layers not much different\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/c7vB1.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/c7vB1.png\" alt=\"enter image description here\"></a></p>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 80}]
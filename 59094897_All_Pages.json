[{"items": [{"tags": ["tensorflow", "nested", "gradient", "backpropagation", "map-function"], "owner": {"account_id": 13457117, "reputation": 671, "user_id": 9710391, "user_type": "registered", "profile_image": "https://lh3.googleusercontent.com/-XdUIqdMkCWA/AAAAAAAAAAI/AAAAAAAAAAA/4252rscbv5M/photo.jpg?sz=256", "display_name": "gab", "link": "https://stackoverflow.com/users/9710391/gab"}, "is_answered": true, "view_count": 843, "accepted_answer_id": 59230178, "answer_count": 2, "score": 4, "last_activity_date": 1576144766, "creation_date": 1574967498, "last_edit_date": 1575738230, "question_id": 59094897, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/59094897/backpropagating-gradients-through-nested-tf-map-fn", "title": "Backpropagating gradients through nested tf.map_fn", "body": "<p>I would like to map a TensorFlow function on each vector corresponding to the depth channel of every pixel in a matrix with dimension <strong>[batch_size, H, W, n_channels]</strong>. </p>\n\n<p>In other words, for every image of size <em>H x W</em> that I have in the batch:</p>\n\n<ol>\n<li>I extract some features maps <em>F_k</em> (whose number is n_channels) with the same size <em>H x W</em> (hence, the features maps all together are a tensor of shape <em>[H, W, n_channels]</em>; </li>\n<li>then, I wish to apply a custom function to the vector <em>v_ij</em> that is associated with the <em>i-th</em> row and <em>j-th</em> column of each feature map <em>F_k</em>, but explores the depth channel in its entirety (e.g. <em>v</em> has dimension <em>[1 x 1 x n_channels]</em>). Ideally, all of this would happen in parallel. </li>\n</ol>\n\n<p>A picture to explain the process can be found below. The only difference with the picture is that both input and output \"receptive fields\" have size 1x1 (apply the function to each pixel independently). </p>\n\n<p><a href=\"https://i.stack.imgur.com/9oc9V.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/9oc9V.png\" alt=\"enter image description here\"></a></p>\n\n<p>This would be similar to applying a 1x1 convolution to the matrix; however, I need to apply a more general function over the depth channel, rather than a simple sum operation.</p>\n\n<p>I think <code>tf.map_fn()</code> could be an option and I tried the following solution, where I recursively use <code>tf.map_fn()</code> to access the features associated with each pixel. However, this kind of seems sub-optimal, and most importantly <strong>it raises an error when trying to backpropagate the gradients</strong>.</p>\n\n<p>Do you have any idea of the reason why this happens and how I should structure my code to avoid the error?</p>\n\n<p>This is my current implementation of the function:</p>\n\n<pre><code>import tensorflow as tf\nfrom tensorflow import layers\n\n\ndef apply_function_on_pixel_features(incoming):\n    # at first the input is [None, W, H, n_channels]\n    if len(incoming.get_shape()) &gt; 1:\n        return tf.map_fn(lambda x: apply_function_on_pixel_features(x), incoming)\n    else:\n        # here the input is [n_channels]\n        # apply some function that applies a transfomration and returns a vetor of the same size\n        output = my_custom_fun(incoming) # my_custom_fun() doesn't change the shape\n        return output\n</code></pre>\n\n<p>and the body of my code:</p>\n\n<pre><code>H = 128\nW = 132\nn_channels = 8\n\nx1 = tf.placeholder(tf.float32, [None, H, W, 1])\nx2 = layers.conv2d(x1, filters=n_channels, kernel_size=3, padding='same')\n\n# now apply a function to the features vector associated to each pixel\nx3 = apply_function_on_pixel_features(x2)  \nx4 = tf.nn.softmax(x3)\n\nloss = cross_entropy(x4, labels)\noptimizer = tf.train.AdamOptimizer(lr)\ntrain_op = optimizer.minimize(loss)  # &lt;--- ERROR HERE!\n</code></pre>\n\n<p>Particularly, the error is the following:</p>\n\n<pre><code>File \"/home/venvs/tensorflowGPU/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 2481, in AddOp\n    self._AddOpInternal(op)\n\nFile \"/home/venvs/tensorflowGPU/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 2509, in _AddOpInternal\n    self._MaybeAddControlDependency(op)\nFile \"/home/venvs/tensorflowGPU/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 2547, in _MaybeAddControlDependency\n    op._add_control_input(self.GetControlPivot().op)\n\nAttributeError: 'NoneType' object has no attribute 'op'\n</code></pre>\n\n<p>The whole error stack and the code can be found <a href=\"http://dropbox.com/sh/n73pmo5rr380mhi/AAC7vC_qkEieXkslcSuXaiy3a?dl=0\" rel=\"nofollow noreferrer\">here</a>.\nThanks for the help,</p>\n\n<p>G.</p>\n\n<hr>\n\n<p><strong>Update:</strong></p>\n\n<p><strong>Following @thushv89 suggestion, I added a possible solution to the problem. I still don't know why my previous code didn't work. Any insight on this would still be very appreciated.</strong></p>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 23}]
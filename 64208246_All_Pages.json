[{"items": [{"tags": ["python-3.x", "machine-learning", "deep-learning", "tf.keras", "generative-adversarial-network"], "owner": {"user_type": "does_not_exist", "display_name": "user14349917"}, "is_answered": false, "view_count": 90, "answer_count": 0, "score": 2, "last_activity_date": 1601900002, "creation_date": 1601899320, "last_edit_date": 1601900002, "question_id": 64208246, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/64208246/why-is-my-gan-not-producing-more-good-images-after-a-certain-point", "title": "Why is my GAN not producing more good images after a certain point?", "body": "<h2>Question</h2>\n<p>I was training a gan to generate human faces. Within approximately 500 epochs, it learned to generate images like this:</p>\n<p><a href=\"https://i.stack.imgur.com/HQXRX.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/HQXRX.png\" alt=\"enter image description here\" /></a></p>\n<p>Well, now this image is not too bad. We can see a face in the center of the image.</p>\n<p>Then I trained it for more 1000 epochs and it learned nothing. It was still generating the same type of images as shown above. Why was that? Why wasn't my gan not learning to produce even better images?</p>\n<h2>Code for the Models</h2>\n<p>Here is the code of the discriminator:</p>\n<pre><code>    def define_discriminator(in_shape=(64, 64, 3)):\n        Model = Sequential([\n                Conv2D(32, (3, 3), padding='same', input_shape=in_shape),\n                BatchNormalization(),\n                LeakyReLU(alpha=0.2),\n                MaxPooling2D(pool_size=(2,2)),\n                Dropout(0.2),\n\n                Conv2D(64, (3,3), padding='same'),\n                BatchNormalization(),\n                LeakyReLU(alpha=0.2),\n                MaxPooling2D(pool_size=(2,2)),\n                Dropout(0.3),\n\n                Conv2D(128, (3,3), padding='same'),\n                BatchNormalization(),\n                LeakyReLU(alpha=0.2),\n                MaxPooling2D(pool_size=(2,2)),\n                Dropout(0.3),\n\n                Conv2D(256, (3,3), padding='same'),\n                BatchNormalization(),\n                LeakyReLU(alpha=0.2),\n                MaxPooling2D(pool_size=(2,2)),\n                Dropout(0.4),\n\n                Flatten(),\n\n                Dense(1, activation='sigmoid')\n])\n        opt = Adam(lr=0.00002)\n        Model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n\n        return Model\n</code></pre>\n<p>Here is the code of the generator and the GAN:</p>\n<pre><code>def define_generator(in_shape=100):\n    Model = Sequential([\n                Dense(256*8*8, input_dim=in_shape),\n                BatchNormalization(),\n                LeakyReLU(alpha=0.2),\n                Reshape((8, 8, 256)),\n\n                Conv2DTranspose(256, (3,3), strides=(2,2), padding='same'),\n                BatchNormalization(),\n                LeakyReLU(alpha=0.2),\n\n                Conv2DTranspose(64, (3,3), strides=(2,2), padding='same'),\n                BatchNormalization(),\n                LeakyReLU(alpha=0.2),\n\n                Conv2DTranspose(3, (4, 4), strides=(2,2), padding='same', activation='sigmoid')\n    ])\n    return Model\n\ndef define_gan(d_model, g_model):\n    d_model.trainable = False\n    model = Sequential([\n                g_model,\n                d_model\n    ])\n    opt = Adam(lr=0.0002, beta_1=0.5)\n    model.compile(loss='binary_crossentropy', optimizer=opt)\n    return model\n</code></pre>\n<h2>Entire Reproducible Code</h2>\n<pre><code>from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, BatchNormalization\nfrom tensorflow.keras.layers import Dropout, Flatten, Dense, Conv2DTranspose\nfrom tensorflow.keras.layers import MaxPooling2D, Activation, Reshape, LeakyReLU\nfrom tensorflow.keras.datasets import mnist\nfrom tensorflow.keras.optimizers import Adam\nfrom numpy import ones\nfrom numpy import zeros\nfrom numpy.random import rand\nfrom numpy.random import randint\nfrom numpy.random import randn\nfrom numpy import vstack\nfrom numpy import array\nimport os\nfrom tensorflow.keras.preprocessing.image import load_img\nfrom tensorflow.keras.preprocessing.image import img_to_array\nfrom matplotlib import pyplot\n\n\ndef load_data(filepath):\n    image_array = []\n    n = 0\n    for fold in os.listdir(filepath):\n      if fold != 'wiki.mat':\n        if n &gt; 1:\n            break\n        for img in os.listdir(os.path.join(filepath, fold)):\n            image = load_img(filepath + fold +  '/'+ img, target_size=(64, 64))\n            img_array = img_to_array(image)\n            img_array = img_array.astype('float32')\n            img_array = img_array / 255.0\n            image_array.append(img_array)\n        n += 1\n    return array(image_array)\ndef generate_latent_points(n_samples, latent_dim=100):\n    latent_points = randn(n_samples * latent_dim)\n    latent_points = latent_points.reshape(n_samples, latent_dim)\n    return latent_points\n\ndef generate_real_samples(n_samples, dataset):\n    ix = randint(0, dataset.shape[0], n_samples)\n    x = dataset[ix]\n    y = ones((n_samples, 1))\n    return x, y\n\ndef generate_fake_samples(g_model, n_samples):\n    latent_points = generate_latent_points(n_samples)\n    x = g_model.predict(latent_points)\n    y = zeros((n_samples, 1))\n    return x, y\n\ndef save_plot(examples, epoch, n=10):\n    # plot images\n    for i in range(n * n):\n        # define subplot\n        pyplot.subplot(n, n, 1 + i)\n        # turn off axis\n        pyplot.axis('off')\n        # plot raw pixel data\n    pyplot.imshow(examples[i, :, :, 0])\n    # save plot to file\n    filename = 'generated_plot_e%03d.png' % (epoch+1)\n    pyplot.savefig(filename)\n    pyplot.close()\n\ndef summarize_performance(d_model, g_model, gan_model, dataset, epoch, n_samples=100):\n    real_x, real_y = generate_real_samples(n_samples, dataset)\n    _, d_real_acc = d_model.evaluate(real_x, real_y)\n    fake_x, fake_y = generate_fake_samples(g_model, n_samples)\n    _, d_fake_acc = d_model.evaluate(fake_x, fake_y)\n\n    latent_points, y = generate_latent_points(n_samples), ones((n_samples, 1))\n    gan_loss = gan_model.evaluate(latent_points, y)\n\n    print('Epoch %d, acc_real=%.3d, acc_fake=%.3f, gan_loss=%.3f' % (epoch, d_real_acc, d_fake_acc, gan_loss))\n\nsave_plot(fake_x, epoch)\nfilename = 'Genarator_Model % d' % (epoch + 1)\ng_model.save(filename)\n\ndef train(d_model, g_model, gan_model, dataset, epochs=200):\n    batch_size = 64\n    half_batch = int(batch_size / 2)\n    batch_per_epoch = int(dataset.shape[0] / batch_size)\n    for epoch in range(epochs):\n        for i in range(batch_per_epoch):\n            real_x, real_y = generate_real_samples(half_batch, dataset)\n            _, d_real_acc = d_model.train_on_batch(real_x, real_y)\n            fake_x, fake_y = generate_fake_samples(g_model, half_batch)\n            _, d_fake_acc = d_model.train_on_batch(fake_x, fake_y)\n\n            latent_points, y = generate_latent_points(batch_size), ones((batch_size, 1))\n            gan_loss = gan_model.train_on_batch(latent_points, y)\n\n            print('Epoch %d, acc_real=%.3d, acc_fake=%.3f, gan_loss=%.3f' % (epoch, d_real_acc, d_fake_acc, gan_loss))\n        if (epoch % 2) == 0:\n            summarize_performance(d_model, g_model, gan_model, dataset, epoch)\n\ndataset = load_data(filepath) # filepath is not defined since every person will have seperate filepath\n\ndiscriminator_model = define_discriminator()\ngenerator_model = define_generator()\ngan_model = define_gan(discriminator_model, generator_model)\n\ntrain(discriminator_model, generator_model, gan_model, dataset)\n</code></pre>\n<h2>Dataset</h2>\n<p>If you want <a href=\"https://drive.google.com/drive/folders/1tKx6egPVafsGgbCk7yKtaIcz_-8NMFTM?usp=sharing\" rel=\"nofollow noreferrer\">here</a> is the dataset.</p>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 270}]
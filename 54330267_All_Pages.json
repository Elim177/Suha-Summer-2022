[{"items": [{"tags": ["tensorflow", "keras", "lstm"], "owner": {"account_id": 1720655, "reputation": 820, "user_id": 1757224, "user_type": "registered", "accept_rate": 85, "profile_image": "https://i.stack.imgur.com/yUXOQ.jpg?s=256&g=1", "display_name": "ARAT", "link": "https://stackoverflow.com/users/1757224/arat"}, "is_answered": false, "view_count": 723, "answer_count": 1, "score": 1, "last_activity_date": 1610530426, "creation_date": 1548256306, "last_edit_date": 1609495260, "question_id": 54330267, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/54330267/dimension-of-the-bias-vector-in-tf-keras-layers-cudnnlstm", "title": "Dimension of the bias vector in tf.keras.layers.CuDNNLSTM", "body": "<p>I was experimenting on <code>tf.keras.layers.CuDNNLSTM</code> and realized the dimension of the bias size is <code>[8 * num_units,]</code>. (<a href=\"https://github.com/tensorflow/tensorflow/blob/a6d8ffae097d0132989ae4688d224121ec6d8f35/tensorflow/python/keras/layers/cudnn_recurrent.py#L449\" rel=\"nofollow noreferrer\">Source code</a>)</p>\n\n<pre><code>import tensorflow as tf\n\n#Data Parameters\nnum_timesteps = 24\nnum_features = 33\n\n#Network Parameters\nnum_units = 2048\n\ninputs = tf.placeholder(tf.float32, shape=[None, num_timesteps, num_features])\nLSTM1 = tf.keras.layers.CuDNNLSTM(units = num_units, kernel_initializer='glorot_uniform', recurrent_initializer='orthogonal', bias_initializer='zeros', unit_forget_bias=True, return_sequences=True, return_state=False)(inputs)\n#&lt;tf.Tensor 'cu_dnnlstm_1/transpose_1:0' shape=(?, 24, 2048) dtype=float32&gt;\n\ntf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES)\n#[&lt;tf.Variable 'cu_dnnlstm/kernel:0' shape=(33, 8192) dtype=float32&gt;,\n# &lt;tf.Variable 'cu_dnnlstm/recurrent_kernel:0' shape=(2048, 8192) dtype=float32&gt;,\n# &lt;tf.Variable 'cu_dnnlstm/bias:0' shape=(16384,) dtype=float32&gt;]\n</code></pre>\n\n<p>However, if you look at the formulation of LSTM Block, there is only 4 weights for each of the gate and block input. </p>\n\n<p><a href=\"https://i.stack.imgur.com/Mq5SV.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/Mq5SV.png\" alt=\"enter image description here\"></a></p>\n\n<p>The only assumption I have they also implemented bias vectors separately for both input and recurrent weights, however, I could not find a reference to it.</p>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 121}]
[{"items": [{"tags": ["python", "tensorflow", "tensorflow-datasets"], "owner": {"account_id": 10716056, "reputation": 2138, "user_id": 7886651, "user_type": "registered", "accept_rate": 76, "profile_image": "https://i.stack.imgur.com/zfb59.jpg?s=256&g=1", "display_name": "I. A", "link": "https://stackoverflow.com/users/7886651/i-a"}, "is_answered": false, "view_count": 486, "answer_count": 0, "score": 2, "last_activity_date": 1550707334, "creation_date": 1550707334, "question_id": 54797162, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/54797162/how-to-apply-transformation-on-pairs-of-elements-in-dataset-api-in-tensorflow", "title": "How to apply transformation on pairs of elements in dataset api in tensorflow?", "body": "<p>I am trying to feed a model samples containing images and labels. One label for each image. Furthermore, instead of feeding the images directly, I want to feed the difference of every pair of images. Note that these images came from a video, so this is why I am performing the difference. Also, I considered the second label and ignored the first one. </p>\n\n<p>For this reason, I have done the following which was partially successful:</p>\n\n<pre><code>def _parse_function(example_proto):\n\n    # The annotation contains the following features: timestamp; arousal; valence; liking\n    features = {\n        'image_raw': tf.FixedLenFeature([], tf.string),\n        'label': tf.FixedLenFeature([1], tf.float32)\n    }\n\n    parsed_features = tf.parse_single_example(example_proto, features)\n    # This is how we create one example, that is, extract one example from the database.\n    image = tf.decode_raw(parsed_features['image_raw'], tf.uint8)\n    image = tf.reshape(image, [112, 112, 3])\n    label = parsed_features['label']\n\n    return label, image\n\ndef my_flat_map(labels, images):\n    label_1 = tf.slice(labels, begin=[0, 0], size=[1, 1])\n    label_2 = tf.slice(labels, begin=[1, 0], size=[1, 1])\n\n    image_1 = tf.slice(images, begin=[0, 0, 0, 0], size=[1, -1, -1, -1])\n    image_2 = tf.slice(images, begin=[1, 0, 0, 0], size=[1, -1, -1, -1])\n\n    image = image_2 - image_1\n    image = tf.squeeze(image, axis=0)\n\n    to_return = tf.data.Dataset.from_tensors((label_2, image_2))\n    return to_return\n\ntrain_dataset = tf.data.TFRecordDataset(filename_train).map(_parse_function)\\\n            .batch(batch_size=2, drop_remainder=True)\\\n            .flat_map(my_flat_map)\\\n            .batch(train_batch_size)\n</code></pre>\n\n<p>Therefore, with this way, I will be consuming every 2 images from the pipeline. In other words, I will be considering images <code>[image1, image2]</code>; <code>[image3, image4]</code> and so on... On the other hand, I want to get: <code>[image1, image2]</code>; <code>[image2, image3]</code>; then apply the transformation on them to return one image and one label. I am aware that I have to use the <code>window</code> function from <a href=\"https://www.tensorflow.org/api_docs/python/tf/data/Dataset#window\" rel=\"nofollow noreferrer\">tf.data.Dataset.window</a> api; So I replaced <code>batch(batch_size=2, drop_remainder=True)</code> with <code>window(size=2, shift=1, drop_remainder=True)</code>, and I got the following error:</p>\n\n<pre><code>TypeError: Failed to convert object of type &lt;class 'tensorflow.python.data.ops.dataset_ops._VariantDataset'&gt; to Tensor. \n</code></pre>\n\n<p>Is there any way to solve this problem?</p>\n\n<p>Any help is much appreciated.</p>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 61}]
[{"items": [{"tags": ["python", "tensorflow"], "owner": {"account_id": 10716056, "reputation": 2138, "user_id": 7886651, "user_type": "registered", "accept_rate": 76, "profile_image": "https://i.stack.imgur.com/zfb59.jpg?s=256&g=1", "display_name": "I. A", "link": "https://stackoverflow.com/users/7886651/i-a"}, "is_answered": false, "view_count": 55, "answer_count": 0, "score": 1, "last_activity_date": 1539018762, "creation_date": 1539017833, "last_edit_date": 1539018762, "question_id": 52706923, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/52706923/error-running-tensorflow-model-while-using-tf-data-api-and-customized-optimizer", "title": "Error Running Tensorflow Model while Using tf.data api and customized optimizer", "body": "<p>In the following code, I wanted to train a model in tensorflow. the model is a ResNet model, a deep one, hence the batch should be small for data/all activations to fit in memory. For this reason, I have implemented a custom optimizer that accumulates the gradients over the different fed mini-batchs, and finally apply the gradient descent once. In addition, I have used <code>tf.data</code> api to fetch data from <code>tfrecords</code> which I created. Please note that my input data are video frames; and the detected variable used indicated whether a face is detected in a certain frame or not. Hence, detected is used only for <code>MSE</code> (Just for clarification).</p>\n\n<pre><code>import tensorflow as tf\nimport numpy as np\nimport csv\nimport os\n\nnum_epoch = 100\nlatent_dim = 100\ncell_size = 100\n\n# for each input frame, I have 3 outputs.\nnum_classes = 3\n\ncommon = \"C:/Users/user/Documents/SEWA_db/tfrecords_db/\"\n\nfilenames_train = []\nfilenames_dev = []\n\nfor i in range(1, 35):\n    filenames_train.append(common + \"Train_DE_{num:02d}.tfrecords\".format(num=i))\n\nfor i in range(1, 15):\n    filenames_dev.append(common + \"Devel_DE_{num:02d}.tfrecords\".format(num=i))\n\nphase_train = tf.placeholder_with_default(True, shape=(), name='phase')\n\ntrain_batch_size = 5\ntest_batch_size = 5\n\ntf.set_random_seed(123)\nmseed = 123\n\n# this method is used within the model()...\ndef create_variables(name, shape, initializer=tf.contrib.layers.xavier_initializer(), weight_decay=0.0001):\n    '''\n    :param name: A string. The name of the new variable\n    :param shape: A list of dimensions\n    :param initializer: User Xavier as default.\n    :param is_fc_layer: Want to create fc layer variable? May use different weight_decay for fc\n    layers.\n    :return: The created variable\n    '''\n\n    ## TODO: to allow different weight decay to fully connected layer and conv layer\n    regularizer = tf.contrib.layers.l2_regularizer(scale=weight_decay)\n\n    new_variables = tf.get_variable(name, shape=shape, initializer=initializer,\n                                    regularizer=regularizer)\n    return new_variables\n\ndef model(inputs, n):\n    ....\n    # predictions shape: (batch_size, 3)\n    return predictions\n\n# loss function:\nsummaries_while_testing = []\nsummaries_while_training = []\n\ndef loss(predictions, labels, detected, name_scope, train_test):\n    # MSE\n    with tf.name_scope(name_scope):\n\n        MSE = tf.square(tf.subtract(predictions, labels))\n        MSE = tf.boolean_mask(MSE, detected)\n        MSE = tf.reduce_mean(MSE)\n\n        if train_test == 'Train':\n            reg_losses = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)\n            MSE += tf.reduce_sum(reg_losses)\n            loss_s = tf.summary.scalar('MSE', MSE)\n            summaries_while_training.append(loss_s)\n        else:\n            loss_s = tf.summary.scalar('MSE', MSE)\n            summaries_while_testing.append(loss_s)\n\n    return MSE\n\n# optimizer:\ndef optimize(mse):\n     with tf.name_scope('Optimizer'):\n        update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n\n        with tf.control_dependencies(update_ops):\n            optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n\n            trainable_variables = tf.trainable_variables()\n\n            accum_vars = [tf.Variable(tf.zeros_like(single_tr_variable.value()), trainable=False)\n                          for single_tr_variable in trainable_variables]\n\n            # This is used as a rest mode between different training iterations...\n            zero_ops = [tv.assign(tf.zeros_like(tv)) for tv in accum_vars]\n\n            grads_vars = optimizer.compute_gradients(mse, trainable_variables)\n\n            accum_ops = [accum_vars[i].assign_add(gv[0]) for i, gv in enumerate(grads_vars) if gv[0] is not None]\n            train_step = optimizer.apply_gradients([(accum_vars[i], gv[1]) for i, gv in enumerate(grads_vars)])\n\n            return train_step, accum_ops, zero_ops\n\n# retrieve data section\ndef _parse_function(example_proto):\n\n    # The annotation contains the following features: timestamp; arousal; valence; liking\n    features = {\n        'height': tf.FixedLenFeature([], tf.int64),\n        'width': tf.FixedLenFeature([], tf.int64),\n        'image_raw': tf.FixedLenFeature([], tf.string),\n        'frame_number': tf.FixedLenFeature([1], tf.int64),\n        'detected': tf.FixedLenFeature([1], tf.int64),\n        'arousal': tf.FixedLenFeature([1], tf.float32),\n        'valence': tf.FixedLenFeature([1], tf.float32),\n        'liking': tf.FixedLenFeature([1], tf.float32)\n    }\n\n    parsed_features = tf.parse_single_example(example_proto, features)\n\n    # This is how we create one example, that is, extract one example from the database.\n    image = tf.decode_raw(parsed_features['image_raw'], tf.uint8)\n    # The height and the weights are used to\n    height = tf.cast(parsed_features['height'], tf.int32)\n    width = tf.cast(parsed_features['width'], tf.int32)\n\n    # The image is reshaped since when stored as a binary format, it is flattened. Therefore, we need the\n    # height and the weight to restore the original image back.\n    # Tensor(\"Reshape:0\", shape=(112, 112, 3), dtype=uint8)\n    image = tf.reshape(image, [112, 112, 3])\n\n    detected = parsed_features['detected']\n    arousal = parsed_features['arousal']\n    valence = parsed_features['valence']\n    liking = parsed_features['liking']\n\n    return detected, arousal, valence, liking, image\n\n###############################      TRAINING      ###################################\n\ndatasets_train_iterators = []\n\nfor file_name in filenames_train:\n    dataset_train = tf.data.TFRecordDataset(file_name).map(_parse_function).batch(train_batch_size)\n    datasets_train_iterators.append(dataset_train)\n\ndataset_train_all = tf.data.Dataset.zip(tuple(datasets_train_iterators))\niterator_train_all = dataset_train_all.make_initializable_iterator()\n\ndef retrieve_inputs_train():\n\n    next_batch = iterator_train_all.get_next()\n\n    detected = []\n    arousal = []\n    valence = []\n    liking = []\n    images = []\n\n    for n in next_batch:\n        detected.append(n[0])\n        arousal.append(n[1])\n        valence.append(n[2])\n        liking.append(n[3])\n        images.append(n[4])\n\n    detected = tf.concat(detected, axis=0)\n    arousal = tf.concat(arousal, axis=0)\n    valence = tf.concat(valence, axis=0)\n    liking = tf.concat(liking, axis=0)\n    images = tf.concat(images, axis=0)\n\n    return detected, arousal, valence, liking, images\n\n###############################      TESTING      ###################################\ndatasets_dev_iterators = []\n\nfor file_name in filenames_dev:\n    dataset_dev = tf.data.TFRecordDataset(file_name).map(_parse_function).batch(test_batch_size)\n    datasets_dev_iterators.append(dataset_dev)\n\ndataset_dev_all = tf.data.Dataset.zip(tuple(datasets_dev_iterators))\niterator_dev_all = dataset_dev_all.make_initializable_iterator()\n\ndef retrieve_inputs_dev():\n\n    next_batch = iterator_dev_all.get_next()\n\n    detected = []\n    arousal = []\n    valence = []\n    liking = []\n    images = []\n\n    for n in next_batch:\n        detected.append(n[0])\n        arousal.append(n[1])\n        valence.append(n[2])\n        liking.append(n[3])\n        images.append(n[4])\n\n    detected = tf.concat(detected, axis=0)\n    arousal = tf.concat(arousal, axis=0)\n    valence = tf.concat(valence, axis=0)\n    liking = tf.concat(liking, axis=0)\n    images = tf.concat(images, axis=0)\n\n    return detected, arousal, valence, liking, images\n\n# preparing model before training\ndetected, arousal, valence, liking, images = tf.cond(phase_train,\n                                                     lambda: retrieve_inputs_train(),\n                                                     lambda: retrieve_inputs_dev())\n\nimages_casted = tf.cast(images, tf.float32)\nwith tf.name_scope('image_normal'):\n    images_casted_normalized = tf.map_fn(lambda img: tf.image.per_image_standardization(img), images_casted)\n\n# shape of predictions: (680, 3) -&gt; 3 since we are outputing arousal, valence and liking\n# the n parameter is for Resnet configuration... Not important for now\npredictions = model(images_casted_normalized, n=[3, 4, 6, 3])\n\npredicted_arousal = tf.slice(predictions, begin=[0, 0], size=[-1, 1], name='predicted_arousal')\npredicted_valence = tf.slice(predictions, begin=[0, 1], size=[-1, 1], name='predicted_valence')\npredicted_liking = tf.slice(predictions, begin=[0, 2], size=[-1, 1], name='predicted_liking')\n\nMSE_a = tf.cond(phase_train, \n                lambda: loss(predicted_arousal, arousal, detected, 'MSE_arousal_Train', 'Train'),\n                lambda: loss(predicted_arousal, arousal, detected, 'MSE_arousal_Devel', 'Devel'))\n\nMSE_v = tf.cond(phase_train, \n                lambda: loss(predicted_valence, valence, detected, 'MSE_valence_Train', 'Train'),\n                lambda: loss(predicted_valence, valence, detected, 'MSE_valence_Devel', 'Devel'))\n\nMSE_l = tf.cond(phase_train,\n                lambda: loss(predicted_liking, liking, detected, 'MSE_liking_Train', 'Train'),\n                lambda: loss(predicted_liking, liking, detected, 'MSE_liking_Devel', 'Devel'))\n\nMSE = MSE_a + MSE_v + MSE_l\n\ntrain_step, accum_ops, zero_ops = optimize(MSE)\n\ninit_op = tf.global_variables_initializer()\n\nmodel_path = \"C:/Users/user/Documents/f24/model\"\nevents_path = \"C:/Users/user/Documents/f24/event_files/34_layers\"\nwith tf.Session() as sess:\n\n    sess.run(init_op)\n\n    train_writer = tf.summary.FileWriter(events_path, sess.graph)\n\n    merged_train = tf.summary.merge(summaries_while_training)\n    merged_val = tf.summary.merge(summaries_while_testing)\n\n    sess.run(iterator_train_all.initializer)\n    sess.run(iterator_dev_all.initializer)\n</code></pre>\n\n<p>Finally, I am getting the following error:</p>\n\n<pre><code>FailedPreconditionError: Attempting to use uninitialized value conv3_1/conv2_in_block/conv\n     [[Node: conv3_1/conv2_in_block/conv/read = Identity[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](conv3_1/conv2_in_block/conv)]]\n\nDuring handling of the above exception, another exception occurred:\n\nFailedPreconditionError                   Traceback (most recent call last)\n&lt;ipython-input-11-dbe6d12c67ce&gt; in &lt;module&gt;()\n      7 \n      8     for v in accum_vars:\n----&gt; 9         sess.run(v.initializer)\n     10 \n     11     sess.run(init_op)\n</code></pre>\n\n<p>...</p>\n\n<pre><code>File \"&lt;ipython-input-10-8d7d7b4aa814&gt;\", line 10, in &lt;module&gt;\n    predictions = model(images_casted_normalized, n=[3, 4, 6, 3])\n  File \"&lt;ipython-input-5-fae307f9536f&gt;\", line 25, in model\n    conv3 = residual_block(layers[-1], 256, is_training=phase_train)\n  File \"&lt;ipython-input-4-d8a2d1403f18&gt;\", line 97, in residual_block\n    conv2 = bn_relu_conv_layer(conv1, [3, 3, output_channel, output_channel], 1, is_training=is_training)\n  File \"&lt;ipython-input-4-d8a2d1403f18&gt;\", line 61, in bn_relu_conv_layer\n    filter = create_variables(name='conv', shape=filter_shape)\n  File \"&lt;ipython-input-4-d8a2d1403f18&gt;\", line 15, in create_variables\n    regularizer=regularizer)\n  File \"C:\\Users\\user\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 1317, in get_variable\n    constraint=constraint)\n</code></pre>\n\n<p>Now when I remove these 2 lines in the <code>optimize()</code>, my code works fine, but I know that this is wrong.</p>\n\n<pre><code>update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n\n    with tf.control_dependencies(update_ops):\n</code></pre>\n\n<p>Or, if I use the following code for the optimizer, my code runs fine.</p>\n\n<pre><code>def optimize(mse):\n     with tf.name_scope('Optimizer'):\n        update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n\n        with tf.control_dependencies(update_ops):\n            optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n            train_step = optimizer.minimize(mse)\n            return train_step\n</code></pre>\n\n<p>To me, this is weird and strange. I would love to know the reason for the error I am getting.</p>\n\n<p>Any help is much appreciated!!</p>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 74}]
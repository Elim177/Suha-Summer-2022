[{"items": [{"tags": ["python", "tensorflow", "tensorflow-probability"], "owner": {"account_id": 2811841, "reputation": 882, "user_id": 2417922, "user_type": "registered", "accept_rate": 0, "profile_image": "https://www.gravatar.com/avatar/5cee40c36bc502473b0976b339a8b8da?s=256&d=identicon&r=PG", "display_name": "Mark Lavin", "link": "https://stackoverflow.com/users/2417922/mark-lavin"}, "is_answered": false, "view_count": 122, "answer_count": 2, "score": 1, "last_activity_date": 1628197536, "creation_date": 1627326484, "last_edit_date": 1627415964, "question_id": 68535253, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/68535253/why-is-tensorflow-tensor-indexing-failing-in-normalizing-flow-prob-method", "title": "Why is Tensorflow tensor indexing failing in Normalizing Flow &quot;prob&quot; method", "body": "<p>I am building a Normalizing Flow (concatenation of Distribution and chain of Bijectors) in Tensorflow.  Here is the code for the chain of Bijectors:</p>\n<pre><code>class Flow( tfb.Bijector ):\n\n    def __init__( self, theta, a, **kwargs ):\n        tfb.Bijector.__init__( self, forward_min_event_ndims = 0, **kwargs )\n        bijectors = [ tfb.Tanh() ]\n        self.chain = tfb.Chain( bijectors = bijectors )\n\n    def _forward( self, z ):\n        return self.chain( z )\n\n    def _inverse( self, x ):\n        result = self.chain.inverse( x ) \n        return result\n\n    def _forward_log_det_jacobian( self, z ):\n        return self.chain._forward_log_det_jacobian( z, event_ndims = 2 )\n    \n</code></pre>\n<p>Here's how I'm trying to test it, specifically, testing the <code>prob</code> method\nof the base distribution plus Flow:</p>\n<pre><code>Z = tf.convert_to_tensor( [ [ [ 0.1, 0.2 ], [ 0.3, 0.4 ], [ 0.5, 0.6 ] ], \n                            [ [ 0.8, 0.7 ], [ 0.6, 0.5 ], [ 0.4, 0.3 ] ],\n                            [ [ 0.4, 0.7 ], [ 0.2, 0.1 ], [ 0.8, 0.0 ] ] ] )\nprint( &quot;Z&quot;, Z )\nnf = Flow( 1., 2. )  # ### theta, a \nbd = tfd.MultivariateNormalDiag( loc=[0.,0.], scale_diag=[1.,1.] )\ntd = tfd.TransformedDistribution( bd, nf )\ntd.log_prob( Z )\n</code></pre>\n<p>The last statement fails with the following stack trace:</p>\n<pre><code>---------------------------------------------------------------------------\nInvalidArgumentError                      Traceback (most recent call last)\n&lt;ipython-input-29-9f91e9e1871a&gt; in &lt;module&gt;()\n     24 bd = tfd.MultivariateNormalDiag( loc=[0.,0], scale_diag=[1.,1.] )\n     25 td = tfd.TransformedDistribution( bd, nf )\n---&gt; 26 td.prob( Z )\n\n12 frames\n/usr/local/lib/python3.7/dist-packages/tensorflow_probability/python/distributions/distribution.py in prob(self, value, name, **kwargs)\n   1322         values of type `self.dtype`.\n   1323     &quot;&quot;&quot;\n-&gt; 1324     return self._call_prob(value, name, **kwargs)\n   1325 \n   1326   def _call_unnormalized_log_prob(self, value, name, **kwargs):\n\n/usr/local/lib/python3.7/dist-packages/tensorflow_probability/python/distributions/distribution.py in _call_prob(self, value, name, **kwargs)\n   1304     with self._name_and_control_scope(name, value, kwargs):\n   1305       if hasattr(self, '_prob'):\n-&gt; 1306         return self._prob(value, **kwargs)\n   1307       if hasattr(self, '_log_prob'):\n   1308         return tf.exp(self._log_prob(value, **kwargs))\n\n/usr/local/lib/python3.7/dist-packages/tensorflow_probability/python/distributions/transformed_distribution.py in _prob(self, y, **kwargs)\n    371         )\n    372     ildj = self.bijector.inverse_log_det_jacobian(\n--&gt; 373         y, event_ndims=event_ndims, **bijector_kwargs)\n    374     if self.bijector._is_injective:  # pylint: disable=protected-access\n    375       base_prob = self.distribution.prob(x, **distribution_kwargs)\n\n/usr/local/lib/python3.7/dist-packages/tensorflow_probability/python/bijectors/bijector.py in inverse_log_det_jacobian(self, y, event_ndims, name, **kwargs)\n   1318       ValueError: if the value of `event_ndims` is not valid for this bijector.\n   1319     &quot;&quot;&quot;\n-&gt; 1320     return self._call_inverse_log_det_jacobian(y, event_ndims, name, **kwargs)\n   1321 \n   1322   def _call_forward_log_det_jacobian(self, x, event_ndims, name, **kwargs):\n\n/usr/local/lib/python3.7/dist-packages/tensorflow_probability/python/bijectors/bijector.py in _call_inverse_log_det_jacobian(self, y, event_ndims, name, **kwargs)\n   1274               'is implemented. One or the other is required.')\n   1275 \n-&gt; 1276         return self._reduce_jacobian_det_over_shape(ildj, reduce_shape)\n   1277 \n   1278   def inverse_log_det_jacobian(self,\n\n/usr/local/lib/python3.7/dist-packages/tensorflow_probability/python/bijectors/bijector.py in _reduce_jacobian_det_over_shape(self, unreduced, reduce_shape)\n   1531     ones = tf.ones(reduce_shape, unreduced.dtype)\n   1532     reduce_dims = ps.range(-ps.size(reduce_shape), 0)\n-&gt; 1533     return tf.reduce_sum(ones * unreduced, axis=reduce_dims)\n   1534 \n   1535   def _parameter_control_dependencies(self, is_init):\n\n/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py in binary_op_wrapper(x, y)\n   1232         #   r_binary_op_wrapper use different force_same_dtype values.\n   1233         x, y = maybe_promote_tensors(x, y, force_same_dtype=False)\n-&gt; 1234         return func(x, y, name=name)\n   1235       except (TypeError, ValueError) as e:\n   1236         # Even if dispatching the op failed, the RHS may be a tensor aware\n\n/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py in _mul_dispatch(x, y, name)\n   1573     return sparse_tensor.SparseTensor(y.indices, new_vals, y.dense_shape)\n   1574   else:\n-&gt; 1575     return multiply(x, y, name=name)\n   1576 \n   1577 \n\n/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py in wrapper(*args, **kwargs)\n    204     &quot;&quot;&quot;Call target, and fall back on dispatchers if there is a TypeError.&quot;&quot;&quot;\n    205     try:\n--&gt; 206       return target(*args, **kwargs)\n    207     except (TypeError, ValueError):\n    208       # Note: convert_to_eager_tensor currently raises a ValueError, not a\n\n/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py in multiply(x, y, name)\n    528   &quot;&quot;&quot;\n    529 \n--&gt; 530   return gen_math_ops.mul(x, y, name)\n    531 \n    532 \n\n/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py in mul(x, y, name)\n   6238       return _result\n   6239     except _core._NotOkStatusException as e:\n-&gt; 6240       _ops.raise_from_not_ok_status(e, name)\n   6241     except _core._FallbackException:\n   6242       pass\n\n/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py in raise_from_not_ok_status(e, name)\n   6895   message = e.message + (&quot; name: &quot; + name if name is not None else &quot;&quot;)\n   6896   # pylint: disable=protected-access\n-&gt; 6897   six.raise_from(core._status_to_exception(e.code, message), None)\n   6898   # pylint: enable=protected-access\n   6899 \n\n/usr/local/lib/python3.7/dist-packages/six.py in raise_from(value, from_value)\n\nInvalidArgumentError: required broadcastable shapes at loc(unknown) [Op:Mul]\n    \n</code></pre>\n<p>I'm not able to figure out from the stack trace where things are going wrong.</p>\n<p>Can you help?</p>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 198}]
[{"items": [{"tags": ["tensorflow", "tf.keras"], "owner": {"account_id": 9917031, "reputation": 629, "user_id": 7341479, "user_type": "registered", "accept_rate": 58, "profile_image": "https://www.gravatar.com/avatar/bc5177d504c7667725faafa54ddb3e23?s=256&d=identicon&r=PG&f=1", "display_name": "Royalblue", "link": "https://stackoverflow.com/users/7341479/royalblue"}, "is_answered": true, "view_count": 326, "accepted_answer_id": 67330082, "answer_count": 1, "score": 0, "last_activity_date": 1619768870, "creation_date": 1619766363, "question_id": 67329608, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/67329608/how-often-are-update-state-and-call-method-called-and-what-are-the-dimension", "title": "how often are update_state() and call() method called and what are the dimension of the parameters in tf.keras?", "body": "<p>I would like to know</p>\n<p>(1) how often the call() method of tf.keras.losses.Loss\nand the update_state() method of tf.keras.metrics.Metric gets called during a training:</p>\n<ul>\n<li>are they called per each instance (observation)?</li>\n<li>or called per each batch?</li>\n</ul>\n<p>(2) the dimension of y_true and y_pred passed to those methods:</p>\n<ul>\n<li>are their dimension (batch_size x output_dimension)</li>\n<li>or (1 x output_dimension)</li>\n</ul>\n<p>The following code snippet comes from\n<a href=\"https://www.tensorflow.org/guide/keras/train_and_evaluate\" rel=\"nofollow noreferrer\">https://www.tensorflow.org/guide/keras/train_and_evaluate</a></p>\n<p>For experiment I insert print(y_true.shape, y_pred.shape) in update_state() and I find that it is only printed once in the first epoch. From the print, it looks like y_true and y_pred have the dimension of\n(1 x output_dimension) in this particular example but is it always the case?</p>\n<p>So, additionally</p>\n<p>(3) I would like to know why it is printed only once and only in the first epoch.</p>\n<p>(4) I can't print the value of y_true or y_pred. How can I?</p>\n<pre><code>Epoch 1/3\n(None, 1) (None, 10)\n(None, 1) (None, 10)\n782/782 [==============================] - 3s 4ms/step - loss: 0.5666 - categorical_true_positives: 22080.8940\nEpoch 2/3\n782/782 [==============================] - 3s 4ms/step - loss: 0.1680 - categorical_true_positives: 23877.1162\nEpoch 3/3\n782/782 [==============================] - 3s 4ms/step - loss: 0.1190 - categorical_true_positives: 24198.2733\n&lt;tensorflow.python.keras.callbacks.History at 0x1fb132cde80&gt;\n</code></pre>\n<pre><code>import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\n\n(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n\n# Preprocess the data (these are NumPy arrays)\nx_train = x_train.reshape(60000, 784).astype(&quot;float32&quot;) / 255\nx_test = x_test.reshape(10000, 784).astype(&quot;float32&quot;) / 255\n\ny_train = y_train.astype(&quot;float32&quot;)\ny_test = y_test.astype(&quot;float32&quot;)\n\n# Reserve 10,000 samples for validation\nx_val = x_train[-10000:]\ny_val = y_train[-10000:]\nx_train = x_train[:-10000]\ny_train = y_train[:-10000]\n\ninputs = keras.Input(shape=(784,), name=&quot;digits&quot;)\nx = layers.Dense(64, activation=&quot;relu&quot;, name=&quot;dense_1&quot;)(inputs)\nx = layers.Dense(64, activation=&quot;relu&quot;, name=&quot;dense_2&quot;)(x)\noutputs = layers.Dense(10, activation=&quot;softmax&quot;, name=&quot;predictions&quot;)(x)\n\nmodel = keras.Model(inputs=inputs, outputs=outputs)\n\nclass CategoricalTruePositives(keras.metrics.Metric):\n    def __init__(self, name=&quot;categorical_true_positives&quot;, **kwargs):\n        super(CategoricalTruePositives, self).__init__(name=name, **kwargs)\n        self.true_positives = self.add_weight(name=&quot;ctp&quot;, initializer=&quot;zeros&quot;)\n\n    def update_state(self, y_true, y_pred, sample_weight=None):\n        print(y_true.shape, y_pred.shape) # For experiment\n        y_pred = tf.reshape(tf.argmax(y_pred, axis=1), shape=(-1, 1))\n        values = tf.cast(y_true, &quot;int32&quot;) == tf.cast(y_pred, &quot;int32&quot;)\n        values = tf.cast(values, &quot;float32&quot;)\n        if sample_weight is not None:\n            sample_weight = tf.cast(sample_weight, &quot;float32&quot;)\n            values = tf.multiply(values, sample_weight)\n        self.true_positives.assign_add(tf.reduce_sum(values))\n\n    def result(self):\n        return self.true_positives\n\n    def reset_states(self):\n        # The state of the metric will be reset at the start of each epoch.\n        self.true_positives.assign(0.0)\n        \nmodel.compile(\n    optimizer=keras.optimizers.RMSprop(learning_rate=1e-3),\n    loss=keras.losses.SparseCategoricalCrossentropy(),\n    metrics=[CategoricalTruePositives()],\n)\nmodel.fit(x_train, y_train, batch_size=64, epochs=3)   \n</code></pre>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 226}]
[{"items": [{"tags": ["python", "python-3.x", "tensorflow"], "owner": {"account_id": 4883126, "reputation": 799, "user_id": 3936294, "user_type": "registered", "accept_rate": 100, "profile_image": "https://i.stack.imgur.com/pQAM5.jpg?s=256&g=1", "display_name": "KyleL", "link": "https://stackoverflow.com/users/3936294/kylel"}, "is_answered": true, "view_count": 128, "accepted_answer_id": 60617419, "answer_count": 1, "score": 3, "last_activity_date": 1583858624, "creation_date": 1583838971, "last_edit_date": 1583858624, "question_id": 60616507, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/60616507/difference-between-tf-gradienttape-and-backprop-gradienttape", "title": "Difference between tf.GradientTape and backprop.GradientTape", "body": "<p>When looking at the <code>OptimizerV2</code> code in Tensorflow 1.15 I noticed that they use <code>backprop.GradientTape</code> to compute the gradient.</p>\n\n<p>I can't find any online reference to this class, only to <code>tf.GradientTape</code>.\nWhat is the difference between the two?</p>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 9}]
[{"items": [{"tags": ["python", "tensorflow", "google-colaboratory"], "owner": {"user_type": "does_not_exist", "display_name": "user10867289"}, "is_answered": true, "view_count": 316, "accepted_answer_id": 57437779, "answer_count": 1, "score": 1, "last_activity_date": 1565389628, "creation_date": 1565371717, "question_id": 57434742, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/57434742/unable-to-save-tensorflow-model-from-google-colab", "title": "unable to save tensorflow model from google colab", "body": "<p>I'm trying to save my tensorflow model from google colab but it's giving me an error i dont know why it's giving an error related to something that goes by 'Cannot serialize protocol buffer of type tensorflow.GraphDef as the serialized size (2897149641bytes) would be larger than the limit (2147483647 bytes)'\nim attaching the code i've used\nalso, below I've attached the error which is popping up</p>\n\n<pre><code>x = tf.placeholder(tf.float32, shape = [None, 4])\ny_true = tf.placeholder(tf.float32, shape = [None, 4])\n\nhidden_layer_1 = tf.layers.dense(x, 100, activation = tf.nn.relu)\nhidden_layer_2 = tf.layers.dense(hidden_layer_1, 100, activation = tf.nn.relu)\noutput = tf.layers.dense(hidden_layer_2, 4, activation = tf.nn.sigmoid)\n\ncost_func = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_true,logits=output))\noptimizer = tf.train.AdamOptimizer(learning_rate=0.001)\ntrain = optimizer.minimize(cost_func)\n\ninit = tf.global_variables_initializer()\nsaver = tf.train.Saver()\n\nsteps = 100\ncost_train = []\ncost_test = []\naccu_train = []\naccu_test = []\nwith tf.Session() as sess:\n\n    sess.run(init)\n\n    for i in range(steps):\n\n\n        _, c_train, pred_train = sess.run([train, cost_func, output],feed_dict={x:X_train,y_true:y_train})\n        _, c_test, pred_test = sess.run([train, cost_func, output],feed_dict={x:X_test,y_true:y_test})\n\n        matches_train = tf.equal(tf.argmax(pred_train,1),tf.argmax(y_train,1))\n        matches_test = tf.equal(tf.argmax(pred_test,1),tf.argmax(y_test,1))\n\n        acc_train = tf.reduce_mean(tf.cast(matches_train,tf.float32))\n        acc_test = tf.reduce_mean(tf.cast(matches_test,tf.float32))\n\n        a_train = sess.run(acc_train,feed_dict={x:X_train,y_true:y_train,})\n        a_test = sess.run(acc_test,feed_dict={x:X_test,y_true:y_test,})\n\n        cost_train.append(c_train)\n        cost_test.append(c_test)\n\n        accu_train.append(a_train)\n        accu_test.append(a_test)\n\n        print('Currently on step {}'.format(i))\n        print('TRAIN ERROR =', c_train,  '\\t', 'TEST ERROR =', c_test)\n        print('TRAIN ACCURACY =', a_train,  '\\t', 'TEST ACCURACY =', a_test)\n        print('---------------------------------------------------------------------------------------------------------------------------------------------------------')\n    save_path = saver.save(sess, \"/content/drive/My Drive/data/model/model.ckpt\")\n    final_pred = sess.run(output,feed_dict={x:test})\n</code></pre>\n\n<pre><code>---------------------------------------------------------------------------\nInvalidArgumentError                      Traceback (most recent call last)\n&lt;ipython-input-56-f10b5e5ffc9f&gt; in &lt;module&gt;()\n     29         accu_test.append(a_test)\n     30 \n---&gt; 31         save_path = saver.save(sess, \"model.ckpt\")\n     32 \n     33         print('Currently on step {}'.format(i))\n\n3 frames\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py in save(self, sess, save_path, global_step, latest_filename, meta_graph_suffix, write_meta_graph, write_state, strip_default_attrs, save_debug_info)\n   1198               meta_graph_filename,\n   1199               strip_default_attrs=strip_default_attrs,\n-&gt; 1200               save_debug_info=save_debug_info)\n   1201 \n   1202     if self._is_empty:\n\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py in export_meta_graph(self, filename, collection_list, as_text, export_scope, clear_devices, clear_extraneous_savers, strip_default_attrs, save_debug_info)\n   1241     return export_meta_graph(\n   1242         filename=filename,\n-&gt; 1243         graph_def=ops.get_default_graph().as_graph_def(add_shapes=True),\n   1244         saver_def=self.saver_def,\n   1245         collection_list=collection_list,\n\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py in as_graph_def(self, from_version, add_shapes)\n   3463     \"\"\"\n   3464     # pylint: enable=line-too-long\n-&gt; 3465     result, _ = self._as_graph_def(from_version, add_shapes)\n   3466     return result\n   3467 \n\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py in _as_graph_def(self, from_version, add_shapes)\n   3388     with self._lock:\n   3389       with c_api_util.tf_buffer() as buf:\n-&gt; 3390         c_api.TF_GraphToGraphDef(self._c_graph, buf)\n   3391         data = c_api.TF_GetBuffer(buf)\n   3392       graph = graph_pb2.GraphDef()\n\nInvalidArgumentError: Cannot serialize protocol buffer of type tensorflow.GraphDef as the serialized size (2897149641bytes) would be larger than the limit (2147483647 bytes)\n</code></pre>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 261}]
[{"items": [{"tags": ["tensorflow", "keras", "deep-learning", "neural-network", "reinforcement-learning"], "owner": {"account_id": 13897864, "reputation": 303, "user_id": 10034197, "user_type": "registered", "profile_image": "https://lh5.googleusercontent.com/--K6mMBgB2u0/AAAAAAAAAAI/AAAAAAAAAAA/AB6qoq2uowJ8Ra_JZM6bAK8QpgOvCfl_nw/mo/photo.jpg?sz=256", "display_name": "Zeinab Akhavan", "link": "https://stackoverflow.com/users/10034197/zeinab-akhavan"}, "is_answered": false, "view_count": 112, "answer_count": 0, "score": 0, "last_activity_date": 1629357923, "creation_date": 1629353507, "last_edit_date": 1629357923, "question_id": 68842842, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/68842842/how-to-design-a-neural-network-with-multiple-dependent-outputs", "title": "How to design a neural network with multiple dependent outputs?", "body": "<p>I have built an actor-critic network in tensorflow. I have a question about my actor network layers design. The actor network should generate 2 outputs. The second output is dependent on the first output, i.e. in order to generate the second output, I need to concatenate the input state and the first output and pass them through the network again and then generate the second output.</p>\n<p>The following is my design but I'm not sure if I should use the same hidden layer for both of outputs or create separate hidden layers for each output.</p>\n<pre><code>def get_actor():\n    # Initialize weights between -3e-3 and 3-e3\n    last_init = tf.random_uniform_initializer(minval=-0.003, maxval=0.003)\n\n    inputs = layers.Input(shape=(num_states_actor,))\n    f = layers.Dense(256, activation=&quot;relu&quot;)(inputs)\n    out1 = layers.Dense(256, activation=&quot;relu&quot;)(f)\n    outputs1 = layers.Dense(4, activation=&quot;softmax&quot;, kernel_initializer=last_init)(out1)\n    out2 = layers.Concatenate()([inputs, outputs1])\n    f = layers.Dense(256, activation=&quot;relu&quot;)(out2)\n    out3 = layers.Dense(256, activation=&quot;relu&quot;)(f)\n    outputs2 = 1e-4 + layers.Dense(1, activation=&quot;relu&quot;, kernel_initializer=last_init)(out3)\n    model = tf.keras.Model(inputs=inputs, outputs=([outputs1, outputs2]))\n    # print(model.summary())\n    return model\n</code></pre>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 86}]
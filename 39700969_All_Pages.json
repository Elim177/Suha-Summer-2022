[{"items": [{"tags": ["python", "deep-learning", "lstm", "tensorflow"], "migrated_from": {"other_site": {"aliases": ["https://statistics.stackexchange.com", "https://crossvalidated.com"], "styling": {"tag_background_color": "#edefed", "tag_foreground_color": "#5D5D5D", "link_color": "#0077CC"}, "related_sites": [{"relation": "meta", "api_site_parameter": "stats.meta", "site_url": "https://stats.meta.stackexchange.com", "name": "Cross Validated Meta"}, {"relation": "chat", "site_url": "https://chat.stackexchange.com?tab=site&host=stats.stackexchange.com", "name": "Chat Stack Exchange"}], "markdown_extensions": ["MathJax", "Prettify"], "launch_date": 1288900046, "open_beta_date": 1280170800, "closed_beta_date": 1279566000, "site_state": "normal", "high_resolution_icon_url": "https://cdn.sstatic.net/Sites/stats/Img/apple-touch-icon@2.png", "twitter_account": "StackStats", "favicon_url": "https://cdn.sstatic.net/Sites/stats/Img/favicon.ico", "icon_url": "https://cdn.sstatic.net/Sites/stats/Img/apple-touch-icon.png", "audience": "people interested in statistics, machine learning, data analysis, data mining, and data visualization", "site_url": "https://stats.stackexchange.com", "api_site_parameter": "stats", "logo_url": "https://cdn.sstatic.net/Sites/stats/Img/logo.png", "name": "Cross Validated", "site_type": "main_site"}, "on_date": 1474887301, "question_id": 236940}, "owner": {"user_type": "does_not_exist", "display_name": "user132405"}, "is_answered": false, "view_count": 504, "answer_count": 0, "score": 0, "last_activity_date": 1474887301, "creation_date": 1474884711, "question_id": 39700969, "link": "https://stackoverflow.com/questions/39700969/lstm-rnn-input-error", "title": "lstm RNN input error", "body": "<p>I am trying to design a simple lstm in tensorflow. I want to classify a sequence of data into classes from 1 to 10.</p>\n\n<p>I have <em>10 timestamps</em> and data X. I am only taking one sequence for now, so my batch size = 1.\nAt every epoch, a new sequence is generated. For example X is a numpy array like this-</p>\n\n<pre><code>X [[ 2.52413028  2.49449348  2.46520466  2.43625973  2.40765466  2.37938545\n     2.35144815  2.32383888  2.29655379  2.26958905]]\n</code></pre>\n\n<p>To make it suitable for lstm input, I first converted in to a tensor and then reshaped it (batch_size, sequence_lenght, input dimension) -</p>\n\n<pre><code>X= np.array([amplitude * np.exp(-t / tau)])\nprint 'X', X\n\n#Sorting out the input\ntrain_input = X\ntrain_input = tf.convert_to_tensor(train_input)\ntrain_input = tf.reshape(train_input,[1,10,1])\nprint 'ti', train_input\n</code></pre>\n\n<p>For output I am generating a one hot encoded label within a class range of 1 to 10. </p>\n\n<pre><code>#------------sorting out the output\ntrain_output= [int(math.ceil(tau/resolution))]\ntrain_output= one_hot(train_output, num_labels=10)\nprint 'label', train_output\n\ntrain_output = tf.convert_to_tensor(train_output)\n\n&gt;&gt;label [[ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]]\n</code></pre>\n\n<p>Then I created the placeholders for tensorflow graph, made the lstm cell and gave weights and bias-</p>\n\n<pre><code>data = tf.placeholder(tf.float32, shape= [batch_size,len(t),1])\ntarget = tf.placeholder(tf.float32, shape = [batch_size, num_classes])\n\ncell = tf.nn.rnn_cell.LSTMCell(num_hidden)\noutput, state = rnn.dynamic_rnn(cell, data, dtype=tf.float32)\n\nweight = tf.Variable(tf.random_normal([batch_size, num_classes, 1])),\nbias = tf.Variable(tf.random_normal([num_classes]))\n\n#training\nprediction = tf.nn.softmax(tf.matmul(output,weight) + bias)\ncross_entropy = -tf.reduce_sum(target * tf.log(prediction))\noptimizer = tf.train.AdamOptimizer()\nminimize = optimizer.minimize(cross_entropy)\n</code></pre>\n\n<p>I have written the code this far and got error at the prediction step. Is it to do with the input shapes? Here is the traceback---</p>\n\n<pre><code>Traceback (most recent call last):\n  File \"/home/raisa/PycharmProjects/RNN_test1/test3.py\", line 66, in &lt;module&gt;\nprediction = tf.nn.softmax(tf.matmul(output,weight) + bias)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_ops.py\", line 1024, in matmul\nb = ops.convert_to_tensor(b, name=\"b\")\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 566, in convert_to_tensor\nret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/constant_op.py\", line 179, in _constant_tensor_conversion_function\n    return constant(v, dtype=dtype, name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/constant_op.py\", line 162, in constant\ntensor_util.make_tensor_proto(value, dtype=dtype, shape=shape))\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/tensor_util.py\", line 390, in make_tensor_proto\ntensor_proto.string_val.extend([compat.as_bytes(x) for x in proto_values])\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/util/compat.py\", line 44, in as_bytes\nraise TypeError('Expected binary or unicode string, got %r' % bytes_or_text)\nenter code here\nTypeError: Expected binary or unicode string, got &lt;tensorflow.python.ops.variables.Variable object at 0x7f5c04251910&gt;\n</code></pre>\n\n<p>Process finished with exit code 1</p>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 299}]
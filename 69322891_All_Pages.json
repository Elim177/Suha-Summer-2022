[{"items": [{"tags": ["python", "tensorflow", "keras", "reshape", "numpy-ndarray"], "owner": {"account_id": 19583067, "reputation": 49, "user_id": 14331697, "user_type": "registered", "profile_image": "https://lh6.googleusercontent.com/-zjM4KZR62pg/AAAAAAAAAAI/AAAAAAAAAAA/AMZuuckn6D6Lnd45h7aX3waondxPn694aQ/photo.jpg?sz=256", "display_name": "Brian Droncheff", "link": "https://stackoverflow.com/users/14331697/brian-droncheff"}, "is_answered": false, "view_count": 117, "answer_count": 0, "score": 1, "last_activity_date": 1632540739, "creation_date": 1632540140, "last_edit_date": 1632540739, "question_id": 69322891, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/69322891/using-a-multiple-matrices-to-predict-a-matrix-in-python-with-keras", "title": "Using a multiple matrices to predict a matrix in Python with Keras", "body": "<p>I modified the code from <a href=\"https://medium.com/analytics-vidhya/adding-mixed-shaped-inputs-to-a-neural-network-5bafc58e9476\" rel=\"nofollow noreferrer\">here</a>. What I'm trying to do is combine the two matrices to predict the output matrix. The output matrix is built from the two input matrices. The problem seems to be associated to:</p>\n<pre><code>    self.Combined_dense_1 = tf.keras.layers.Dense(units=32, activation=&quot;relu&quot;)\n    self.Combined_dense_2 = tf.keras.layers.Dense(units=16, activation=&quot;softmax&quot;)\n</code></pre>\n<p>The linked medium tutorial only predicting a single number based on the combined mixed input. I however am trying to predict a whole matrix but don't know how to structure the combined layer (if this is even the problem).</p>\n<p>The error: &quot;ValueError: Shape mismatch: The shape of labels (received (40,)) should equal the shape of logits except for the last dimension (received (10, 16)).&quot;</p>\n<p>The code:</p>\n<pre><code>import warnings\nimport sys\nif not sys.warnoptions:\n    warnings.simplefilter(&quot;ignore&quot;)\nimport numpy as np\nimport os\nimport random\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom IPython.display import clear_output\n\nclass model(keras.Model):\n    def __init__(self):\n        super().__init__()\n\n        # The layers to process our image\n        self.Conv2D_1 = tf.keras.layers.Conv2D(filters=32,\n                                               kernel_size=(1, 1),\n                                               strides=(1, 1)\n                                               )\n\n        self.Conv2D_2 = tf.keras.layers.Conv2D(filters=32,\n                                               kernel_size=(3, 3),\n                                               strides=(1, 1)\n                                               )\n\n        # our combined layers\n        self.Combined_dense_1 = tf.keras.layers.Dense(units=32, activation=&quot;relu&quot;)\n        self.Combined_dense_2 = tf.keras.layers.Dense(units=16, activation=&quot;softmax&quot;)\n\n    def call(self, input_image_one, input_image_two):\n        # Image model\n        I = self.Conv2D_1(input_image_one)\n        I = self.Conv2D_2(I)\n        # Flatten I so we can merge our data.\n        I = tf.keras.layers.Flatten()(I)\n\n        N = self.Conv2D_1(input_image_two)\n        N = self.Conv2D_2(N)\n        N = tf.keras.layers.Flatten()(N)\n\n        # Combined model\n        x = tf.concat([N, I], 1)  # Concatenate through axis #1\n        x = self.Combined_dense_1(x)\n        x = self.Combined_dense_2(x)\n        return x\n\nnetwork = model()\n\noptimizer = tf.keras.optimizers.Adam()\nloss_function = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n\ndef train_step(model, optimizer, loss_function,\n               images_one_batch, images_two_batch,\n               labels):\n    with tf.GradientTape() as tape:\n\n        model_output = model(images_one_batch, images_two_batch)\n        print(model_output)\n        loss = loss_function(labels, model_output)  # our labels vs our predictions\n\n    grads = tape.gradient(loss, model.trainable_variables)\n    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n\n    return loss\n\ndef train(model, optimizer, loss_function, epochs,\n          images_one_batch, images_two_batch,\n          labels):\n    loss_array = []\n    for epoch in range(epochs):\n        loss = train_step(model, optimizer, loss_function, images_one_batch, images_two_batch, labels)\n        loss_array.append(loss)\n\n        if ((epoch + 1) % 20 == 0):\n            # Calculating accuracy\n            network_output = network(images_one_batch, images_two_batch)\n            preds = np.argmax(network_output, axis=1)\n            acc = 0\n            for i in range(len(images_one_batch)):\n                if (preds[i] == labels[i]):\n                    acc += 1\n\n            print(&quot; loss:&quot;, loss, &quot;  Accuracy: &quot;, acc / len(images_one_batch) * 100, &quot;%&quot;)\n\n            clear_output(wait=True)\n\n\n\nNumberofVars = 2;\nwidth= NumberofVars; height = NumberofVars\n\nNumberOfComputationSets = 10\n\nCM_MatrixArr1 = []\nCM_MatrixArr2 = []\n\nfor j in range(NumberOfComputationSets):\n    \n    Theta1 = list(np.reshape(np.random.randint(2, size=4), (1,4))[0])\n    Theta1 = list(np.float_(Theta1))\n    CM_MatrixArr1.append(Theta1)\n\n    Theta2 = list(np.reshape(np.random.randint(2, size=4), (1,4))[0])\n    Theta2 = list(np.float_(Theta2))\n    CM_MatrixArr2.append(Theta2)\n\ncombinedCM_MatrixArr = []\ncombinedCM_toIntArr = []\n\nfor x,y in zip(CM_MatrixArr1, CM_MatrixArr2):\n    combinedCM = []\n    combinedCM_toInt = 0\n\n    for a,b in zip(x,y):\n        LogVal = (a == b)\n        combinedCM.append(float(LogVal == True))\n\n    combinedCM_MatrixArr.append(combinedCM)\n\n\ncombinedCM_MatrixArr = np.array(combinedCM_MatrixArr)\ncombinedCM_MatrixArr = combinedCM_MatrixArr.reshape(NumberOfComputationSets,2,2)\n\n\nCM_MatrixArr1 = np.array(CM_MatrixArr1)\nCM_MatrixArr1 = CM_MatrixArr1.reshape(NumberOfComputationSets,2,2)\nCM_MatrixArr1 = CM_MatrixArr1.reshape(NumberOfComputationSets, 2,2,1)\n\nCM_MatrixArr2 = np.array(CM_MatrixArr2)\nCM_MatrixArr2 = CM_MatrixArr2.reshape(NumberOfComputationSets,2,2)\nCM_MatrixArr2 = CM_MatrixArr2.reshape(NumberOfComputationSets, 2,2,1)\n\n\ntrain(network,optimizer,loss_function,300,CM_MatrixArr1,CM_MatrixArr2,combinedCM_MatrixArr)\n</code></pre>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 40}]
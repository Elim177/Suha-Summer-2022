[{"items": [{"tags": ["tensorflow", "keras", "deep-learning", "nlp"], "owner": {"account_id": 20465057, "reputation": 21, "user_id": 15016764, "user_type": "registered", "profile_image": "https://i.stack.imgur.com/Up7SH.jpg?s=256&g=1", "display_name": "devanshu singh", "link": "https://stackoverflow.com/users/15016764/devanshu-singh"}, "is_answered": false, "view_count": 245, "answer_count": 1, "score": 0, "last_activity_date": 1632220074, "creation_date": 1632139128, "last_edit_date": 1632220074, "question_id": 69254063, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/69254063/gpu-goes-out-of-memory-during-training-large-dataset", "title": "GPU goes out of memory during training large dataset", "body": "<p>I am using a Transformer network for machine translation, during training of model the GPU runs out of memory during large dataset, it works fine with small data.</p>\n<p>This is the self attention part, The error comes during the computation of matrices.</p>\n<pre><code>import tensorflow as tf\n\nclass SelfAttention(tf.keras.layers.Layer):\n    def __init__(self, embed_size, head):\n        super(SelfAttention, self).__init__()\n        self.head = head\n        self.embed_size = embed_size\n        self.head_dim = embed_size // head\n\n        assert (self.head_dim * head == embed_size), 'size of head_dim is not matching'\n\n        self.query = tf.keras.layers.Dense(self.head_dim, activation='linear', use_bias=False)\n        self.value = tf.keras.layers.Dense(self.head_dim, activation='linear', use_bias=False)\n        self.key = tf.keras.layers.Dense(self.head_dim, activation='linear', use_bias=False)\n        self.fc_layer = tf.keras.layers.Dense(self.embed_size, activation='linear')\n\n    def call(self, value, key, query, mask):\n        # Number of training examples\n        N = query.shape[0]\n        query_len, value_len, key_len = query.shape[1], value.shape[1], key.shape[1]\n\n        # Reshape according to the number of examples and words\n        query = tf.reshape(query, (N, query_len, self.head, self.head_dim))\n        value = tf.reshape(value, (N, value_len, self.head, self.head_dim))\n        key = tf.reshape(key, (N, key_len, self.head, self.head_dim))\n\n        query = self.query(query)\n        value = self.value(value)\n        key = self.key(key)\n\n        # energy shape: (N, head, query_len, key_len) try to imagine the shape in mind\n        energy = tf.einsum(&quot;nqhd, nkhd-&gt;nhqk&quot;, query, key)\n\n        if mask is not None:\n            energy = energy * mask\n            energy = tf.where(tf.equal(energy, 0), -1e20, energy)\n\n        attention = tf.keras.activations.softmax(energy, axis=3)\n\n        # attention shape: (N, head, query_len, key_len)\n        # value shape:(N, value_len, head, head_dim)\n        # output: (N, query_len, head, head_dim)\n        output = tf.reshape(tf.einsum(&quot;nhql, nlhd-&gt;nqhd&quot;, attention, value), (N, query_len, self.head*self.head_dim))\n\n        output = tf.keras.activations.linear(output)\n\n        return output\n</code></pre>\n<p>The error is</p>\n<pre><code>2021-09-20 11:51:49.615495: I tensorflow/core/common_runtime/bfc_allocator.cc:1036] 1 Chunks of size 35477760 totalling 33.83MiB\n2021-09-20 11:51:49.615502: I tensorflow/core/common_runtime/bfc_allocator.cc:1036] 1 Chunks of size 40866304 totalling 38.97MiB\n2021-09-20 11:51:49.615509: I tensorflow/core/common_runtime/bfc_allocator.cc:1036] 1 Chunks of size 47409664 totalling 45.21MiB\n2021-09-20 11:51:49.615516: I tensorflow/core/common_runtime/bfc_allocator.cc:1036] 1 Chunks of size 47547136 totalling 45.34MiB\n\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/ops.py in raise_from_not_ok_status(e, name)\n   6860   message = e.message + (&quot; name: &quot; + name if name is not None else &quot;&quot;)\n   6861   # pylint: disable=protected-access\n-&gt; 6862   six.raise_from(core._status_to_exception(e.code, message), None)\n   6863   # pylint: enable=protected-access\n   6864 \n\n/opt/conda/lib/python3.7/site-packages/six.py in raise_from(value, from_value)\n\nResourceExhaustedError: OOM when allocating tensor with shape[32,334,25335] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:BiasAdd]\n</code></pre>\n<p>What should I do?</p>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 76}]
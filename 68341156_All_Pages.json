[{"items": [{"tags": ["tensorflow-federated"], "owner": {"account_id": 22185030, "reputation": 137, "user_id": 16428078, "user_type": "registered", "profile_image": "https://www.gravatar.com/avatar/17e9bf8464ed809eaf2c797eaaa93086?s=256&d=identicon&r=PG&f=1", "display_name": "ozgur", "link": "https://stackoverflow.com/users/16428078/ozgur"}, "is_answered": true, "view_count": 345, "accepted_answer_id": 68350737, "answer_count": 1, "score": 2, "last_activity_date": 1626228295, "creation_date": 1626054877, "last_edit_date": 1626228295, "question_id": 68341156, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/68341156/tensorflow-federated-tff-0-19-performs-significantly-worse-than-tff-0-17-when", "title": "Tensorflow federated (TFF) 0.19 performs significantly worse than TFF 0.17 when running &quot;Building Your Own Federated Learning Algorithm&quot; tutorial", "body": "<p>At the very end the &quot;<em>Building Your Own Federated Learning Algorithm</em>&quot; tutorial it is stated ,after training our model for 15 rounds, we shall expect a <code>sparse_categorical_accuracy</code> around 0.25, but running the tutorial in colab as is gives a result between 0.09 and 0.11 based on my runs. Yet simply changing the tf and tff versions to 2.3.x and 0.17, respectively, gives a result around 0.25, just like we expected!</p>\n<p>To replicate run the said tutorial as is, it should use tf 2.5 and tff 0.19. After that run the same tutorial by simply changing</p>\n<pre><code>!pip install --quiet --upgrade tensorflow-federated\n</code></pre>\n<p>to</p>\n<pre><code>!pip install --quiet tensorflow==2.3.0\n!pip install --quiet --upgrade tensorflow-federated==0.17.0\n</code></pre>\n<p>Also tf 2.4 and tff 0.18 combination works just fine and gives a score around 0.25. So it is only tf 2.5 and tff 0.19 combination that doesnt give the expected result.</p>\n<p>Just to be clear I am not saying first setup doesnt train the model; running it for 200 rounds shows a steady improvement in score reaching something like 0.7-0.8. I would appreciate a clarification on why thats the case, or if I made something wrong please point it out.</p>\n<p><strong>Edit:</strong> To make sure same clients were being used across different tff versions I have used the following codes</p>\n<p>for training data</p>\n<pre><code>sorted_client_ids = sorted(emnist_train.client_ids)\nsorted_client_ids2 = sorted_client_ids[0:10]\n\nfederated_train_data = [preprocess(emnist_train.create_tf_dataset_for_client(x))\n                       for x in sorted_client_ids2]\n</code></pre>\n<p>for test data</p>\n<pre><code>sorted_client_ids = sorted(emnist_test.client_ids)\nsorted_client_ids2 = sorted_client_ids[0:100]\n\ndef data(client, source=emnist_test):\n    return preprocess(source.create_tf_dataset_for_client(client))\n\ncentral_emnist_test = (tf.data.Dataset.from_tensor_slices(\n    [data(client) for client in sorted_client_ids2])).flat_map(lambda x: x)\n</code></pre>\n<p>I trained each for 50 rounds. The results I got with these settings are</p>\n<p>for tff 0.17: loss: 1.8676 - sparse_categorical_accuracy: 0.5115</p>\n<p>for tff 0.18: loss: 1.8503 - sparse_categorical_accuracy: 0.5160</p>\n<p>for tff 0.19: loss: 2.2007 - sparse_categorical_accuracy: 0.1014</p>\n<p>So my problem here is all three versions of tff had used same training data, same test data, the models had the same initialization and same rounds of training but the results for tff 0.19 and tff 0.18/0.17 was vastly different, whereas tff 0.18 and 0.17 had produced quite similar results.</p>\n<p>Again just to clarify tff 0.19 had improved its accuracy as well, but to a significantly lesser degree.</p>\n<p><strong>EDIT 2:</strong> Following the advice of Zachary Charles I have used federated sgd. For tff 0.18 and 0.17 edit the first line.</p>\n<pre><code>!pip install --quiet --upgrade tensorflow-federated\n!pip install --quiet --upgrade nest-asyncio\n\nimport nest_asyncio\nnest_asyncio.apply()\n\nimport collections\nimport attr\nimport functools\nimport numpy as np\nimport tensorflow as tf\nimport tensorflow_federated as tff\n\nnp.random.seed(0)\n\nprint(tf.__version__)\nprint(tff.__version__)\n\nemnist_train, emnist_test = tff.simulation.datasets.emnist.load_data()\n\nNUM_CLIENTS = 10\nBATCH_SIZE = 20\n\ndef preprocess(dataset):\n    def batch_format_fn(element):\n        return(tf.reshape(element['pixels'],[-1,784]),\n              tf.reshape(element['label'],[-1,1]))\n    return dataset.batch(BATCH_SIZE).map(batch_format_fn)\n\nsorted_client_ids = sorted(emnist_train.client_ids)\nsorted_client_ids2 = sorted_client_ids[0:10]\n\nfederated_train_data = [preprocess(emnist_train.create_tf_dataset_for_client(x))\n                       for x in sorted_client_ids2]\n\ndef create_keras_model():\n    return tf.keras.models.Sequential([\n        tf.keras.layers.InputLayer(input_shape=(784,)),\n        tf.keras.layers.Dense(10, kernel_initializer='zeros'),\n        tf.keras.layers.Softmax(),\n    ])\n\ndef model_fn():\n    keras_model = create_keras_model()\n    return tff.learning.from_keras_model(\n        keras_model,\n        input_spec=federated_train_data[0].element_spec,\n        loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n        metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n    \nsorted_client_ids = sorted(emnist_test.client_ids)\nsorted_client_ids2 = sorted_client_ids[0:10]\n\ndef data(client, source=emnist_test):\n    return preprocess(source.create_tf_dataset_for_client(client))\n\ncentral_emnist_test = (tf.data.Dataset.from_tensor_slices(\n    [data(client) for client in sorted_client_ids2])).flat_map(lambda x: x)\n\ndef evaluate(server_state):\n    keras_model = create_keras_model()\n    keras_model.compile(\n      loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n      metrics=[tf.keras.metrics.SparseCategoricalAccuracy()]  \n    )\n    keras_model.set_weights(server_state)\n    keras_model.evaluate(central_emnist_test)\n\n\niterative_process = tff.learning.build_federated_sgd_process(\n    model_fn,\n    server_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.01))\n\nstate = iterative_process.initialize()\nevaluate(state.model.trainable)\n\nfor round in range(50):\n    print(round)\n    state,_ = iterative_process.next(state, federated_train_data)\n\nevaluate(state.model.trainable)\n</code></pre>\n<p>The results I got are</p>\n<p>Before training</p>\n<ul>\n<li>tff 0.19: loss: 2.3026 - sparse_categorical_accuracy: 0.1207</li>\n<li>tff 0.18: loss: 2.3026 - sparse_categorical_accuracy: 0.1010</li>\n<li>tff 0.17: loss: 2.3026 - sparse_categorical_accuracy: 0.1207</li>\n</ul>\n<p>After training</p>\n<ul>\n<li>tff 0.19: loss: 2.2122 - sparse_categorical_accuracy: 0.1983</li>\n<li>tff 0.18: loss: 2.2158 - sparse_categorical_accuracy: 0.1700</li>\n<li>tff 0.17: loss: 2.2122 - sparse_categorical_accuracy: 0.1983</li>\n</ul>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 107}]
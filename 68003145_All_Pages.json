[{"items": [{"tags": ["tensorflow", "relational-database", "tensorflow2.0"], "owner": {"account_id": 4548208, "reputation": 3430, "user_id": 8089695, "user_type": "registered", "accept_rate": 100, "profile_image": "https://www.gravatar.com/avatar/92107cb1b109e2b8281e9cb76b5e3f16?s=256&d=identicon&r=PG&f=1", "display_name": "MiloMinderbinder", "link": "https://stackoverflow.com/users/8089695/milominderbinder"}, "is_answered": false, "view_count": 139, "answer_count": 0, "score": 5, "last_activity_date": 1624684954, "creation_date": 1623848335, "last_edit_date": 1624684954, "question_id": 68003145, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/68003145/how-to-create-tensorflow-data-ingestion-pipeline-for-multiple-related-csvs", "title": "How to create Tensorflow data ingestion pipeline for multiple related CSVs?", "body": "<p>Let us say we have some Relational data.\nMaking a simple example for a retail store chain:</p>\n<ul>\n<li>Dataset 1 --&gt; Store_id, Daily_sales</li>\n<li>Dataset 2 --&gt; Customer_id, store_id, Time in, Time out</li>\n</ul>\n<p>Let us say the task is to predict <code>Daily_sales</code>.</p>\n<p>I know how how to create data batches for one single CSV. I can use <code>tf.data.experimental.make_csv_dataset</code> and iterate over the dataset iterable that it returns to read the batches lazily.</p>\n<p>However, I want to read in the batches from <code>Dataset 1</code> and <code>Dataset 2</code> described above where the common id is <code>store_id</code> such that the batch reads the rows with same <code>store_id</code>s from both the datasets. I want to do this because I will run two networks (RNN on <code>Dataset 2</code> and a single Fully connected layer on <code>Dataset 1</code>) on both datasets and then merge them in the final fully connected layer.</p>\n<p>Can you please guide me on how to approach this problem in scenarios where:</p>\n<ul>\n<li>The datasets can fit into the memory</li>\n<li>The datasets can not fit into the memory</li>\n</ul>\n<p>Here is a concrete example of the consistent batch creation I am looking  for:</p>\n<pre><code>import pandas as pd\nDataset_1 = pd.DataFrame({'id':['a','b','c','d'],'col1':[1,2,3,4]})\nprint(Dataset_1)\n  id  col1\n0  a     1\n1  b     2\n2  c     3\n3  d     4\nDataset_2 = pd.DataFrame({'id':['a','a','b','c','c','c','d'],'col1':[10,11,12,13,14,15,16]})\nprint(Dataset_2)\n    id  col1\n0   a   10\n1   a   11\n2   b   12\n3   c   13\n4   c   14\n5   c   15\n6   d   16\n#Let us say i want to create 2 batches. The following dataframes are how i want my batches to look like\nbatch_1 = (pd.DataFrame({'id':['a','b'],'col1':[1,2]}),pd.DataFrame({'id':['a','a','b'],'col1':[10,11,12]}))\nprint(batch_1[0])\n    id  col1\n0   a   1\n1   b   2\nprint(batch_1[1])\n  id  col1\n0  a    10\n1  a    11\n2  b    12\nbatch_2 = (pd.DataFrame({'id':['c','d'],'col1':[3,4]}),pd.DataFrame({'id':['c','c','c','d'],'col1':[13,14,15,16]}))\nprint(batch_2[0])\nid  col1\n0  c     3\n1  d     4\n\nprint(batch_2[1])\n id  col1\n0  c    13\n1  c    14\n2  c    15\n3  d    16\n</code></pre>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 166}]
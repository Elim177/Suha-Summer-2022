[{"items": [{"tags": ["python", "tensorflow", "keras", "multiprocessing", "tensorflow2.0"], "owner": {"account_id": 3728998, "reputation": 246, "user_id": 3701747, "user_type": "registered", "profile_image": "https://www.gravatar.com/avatar/0b2e3e0cb01e1de3ae5e8028b38db798?s=256&d=identicon&r=PG&f=1", "display_name": "kosa", "link": "https://stackoverflow.com/users/3701747/kosa"}, "is_answered": false, "view_count": 513, "answer_count": 1, "score": 0, "last_activity_date": 1612631461, "creation_date": 1612547504, "question_id": 66068180, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/66068180/tensflow-keras-typeerror-cant-pickle-thread-rlock-objects-when-using-multipr", "title": "Tensflow Keras: TypeError: can&#39;t pickle _thread.RLock objects when using multiprocessing", "body": "<p>I have raised this issue in GitHub: <a href=\"https://github.com/tensorflow/tensorflow/issues/46917\" rel=\"nofollow noreferrer\">https://github.com/tensorflow/tensorflow/issues/46917</a></p>\n<p>I am trying to use multiprocessing threads to speedup the some of my code. In which I have to send a Keras model to each thread and use it to predict on some inputs and do some following computations. However, I end up with the following error</p>\n<pre><code>Tensflow Keras: TypeError: can't pickle _thread.RLock objects\n</code></pre>\n<p>I tried,</p>\n<ol>\n<li>using <code>partial</code> to fix the model argument and use the resulting partial-function.</li>\n<li>cloning the model and using a clone for each thread</li>\n<li>saving and reloading a model for each thread</li>\n<li>tried using <code>pathos.multiprocessing</code>\nbut none of them worked.</li>\n</ol>\n<p>The following is the MWE</p>\n<pre><code>import tensorflow as tf\nfrom tensorflow import keras\nimport numpy as np\n\n\nfrom multiprocessing import Pool\n# from multiprocessing.dummy import Pool as ThreadPool\n# from pathos.multiprocessing import ProcessingPool as Pool\nfrom functools import partial\n\n\ndef simple_model():\n    model = keras.models.Sequential([\n        keras.layers.Dense(units = 10, input_shape = [1]),\n        keras.layers.Dense(units = 1, activation = 'sigmoid')\n    ])\n    model.compile(optimizer = 'sgd', loss = 'mean_squared_error')\n    return model\n\ndef clone_model(model):\n    model_clone = tf.keras.models.clone_model(model)\n    model_clone.set_weights(model.get_weights())\n    model_clone.build((None, 1))\n    model_clone.compile(optimizer = 'sgd', loss = 'mean_squared_error')\n    return model_clone\n\ndef work(model, seq):\n    return model.predict(seq)\n\ndef load_model(model_savepath):\n    return tf.keras.models.load_model(model_savepath)\n\ndef worker(model, n = 4):\n    seqences = np.arange(0,100).reshape(n, -1)\n    pool = Pool()\n    model_savepath = './simple_model.h5'\n    model.save(model_savepath)\n    model_list = [load_model(model_savepath) for _ in range(n)]\n    # model_list = [clone_model(model) for _ in range(n)]\n    results = pool.map(work, zip(model_list,seqences))\n    # partial_work = partial(work, model=model)\n    # results = pool.map(partial_work, seqences)\n    pool.close()\n    pool.join()\n    \n    return np.reshape(results, (-1, ))\n\n\n\nif __name__ == '__main__':\n\n    model = simple_model()\n    out = worker(model, n=4)\n    print(out)\n</code></pre>\n<p>This results in the following error trace:</p>\n<pre><code>File &quot;c:/Users/***/Documents/GitHub/COVID-NSF/test4.py&quot;, line 42, in &lt;module&gt;\n  out = worker(model, n=4)\nFile &quot;c:/Users/****/Documents/GitHub/COVID-NSF/test4.py&quot;, line 30, in worker\n  results = pool.map(work, zip(model_list,seqences))\nFile &quot;C:\\Users\\****\\anaconda3\\envs\\tf-gpu\\lib\\multiprocessing\\pool.py&quot;, line 268, in map\n  return self._map_async(func, iterable, mapstar, chunksize).get()\nFile &quot;C:\\Users\\****\\anaconda3\\envs\\tf-gpu\\lib\\multiprocessing\\pool.py&quot;, line 657, in get\n  raise self._value\nFile &quot;C:\\Users\\***\\anaconda3\\envs\\tf-gpu\\lib\\multiprocessing\\pool.py&quot;, line 431, in _handle_tasks\n  put(task)\nFile &quot;C:\\Users\\***\\anaconda3\\envs\\tf-gpu\\lib\\multiprocessing\\connection.py&quot;, line 206, in send\n  self._send_bytes(_ForkingPickler.dumps(obj))\nFile &quot;C:\\Users\\***\\anaconda3\\envs\\tf-gpu\\lib\\multiprocessing\\reduction.py&quot;, line 51, in dumps\n  cls(buf, protocol).dump(obj)\nTypeError: can't pickle _thread.RLock objects\n</code></pre>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 41}]
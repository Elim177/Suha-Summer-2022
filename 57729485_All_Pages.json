[{"items": [{"tags": ["neural-network", "branch"], "owner": {"account_id": 15085414, "reputation": 147, "user_id": 11057642, "user_type": "registered", "profile_image": "https://www.gravatar.com/avatar/bcc1147639cc503c5323ed4503df7c2c?s=256&d=identicon&r=PG", "display_name": "Keren", "link": "https://stackoverflow.com/users/11057642/keren"}, "is_answered": false, "view_count": 446, "answer_count": 1, "score": 0, "last_activity_date": 1567180874, "creation_date": 1567178711, "question_id": 57729485, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/57729485/model-with-two-branches-converging-to-one-zero-gradients-and-constant-output", "title": "Model with two branches converging to one - zero gradients and constant output", "body": "<p>I am building a neural network that takes two different inputs; pictures and a set of numerical features.</p>\n\n<p>The pictures are supposed to go through some CNN architecture and then flatten out, while the features are supposed to go through some dense layers and then I want to concatenate them into a single vector and continue with a few more dense layers.</p>\n\n<p>Before I share the code, I want to say that my combined_network manages to take my two inputs and bring them through the two branches and output a single value. The problem is that the gradients for the combined network zero out completely and the output is ones even right after compiling the network. However, when I check the gradients for each of the two branches separately (without inserting them into the combined model), the gradients are not zero.</p>\n\n<p>Apparently there is some problem with how I created the combined network and I would love some input.</p>\n\n<p>CNN</p>\n\n<pre class=\"lang-py prettyprint-override\"><code>\n#INPUT IS [224,224]\nmodel = tf.keras.Sequential()\n#add model layers\nmodel.add(tf.keras.layers.Conv2D(128, kernel_size=4,padding='same',activation='relu',input_shape=[inputs_shape_0,inputs_shape_1,1]))\nmodel.add(tf.keras.layers.Dropout(0.5))\nmodel.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2),padding='same'))\nmodel.add(tf.keras.layers.Conv2D(64,kernel_size=4,padding='same',activation='relu'))\nmodel.add(tf.keras.layers.Dropout(0.5))\nmodel.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2),padding='same'))\nmodel.add(tf.keras.layers.Conv2D(32,kernel_size=4,padding='same',activation='relu'))\nmodel.add(tf.keras.layers.Dropout(0.5))\nmodel.add(tf.keras.layers.Conv2D(16, kernel_size=2,padding='same',activation='relu'))\nmodel.add(tf.keras.layers.Dropout(0.5))\nmodel.add(layers.Flatten())\n\nmodel.summary()\n\n</code></pre>\n\n<p>Dense network</p>\n\n<pre class=\"lang-py prettyprint-override\"><code>feat_model = tf.keras.Sequential()\nfeat_model.add(tf.keras.layers.Dense(16,activation=tf.nn.relu,input_shape=(inputs_shape_0,)))\nfeat_model.add(tf.keras.layers.Dropout(0.5))\nfeat_model.add(tf.keras.layers.Dense(8,activation=tf.nn.relu))\nfeat_model.add(tf.keras.layers.Dropout(0.5))\nfeat_model.add(tf.keras.layers.Dense(4,activation=tf.nn.relu))\nfeat_model.add(tf.keras.layers.Dropout(0.5))\nmodel.summary()\n</code></pre>\n\n<p>Combined network</p>\n\n<pre class=\"lang-py prettyprint-override\"><code>def create_combined(model_1, model_2):\n\n  # combine the output of the two branches\n\n  combined = tf.keras.layers.concatenate([model_1.output, model_2.output])\n\n  # apply a FC layer and then a regression prediction on the  \n  # combined outputs\n  z_0 = tf.keras.layers.Dense(24, activation=\"relu\")(combined)\n  z_1 = tf.keras.layers.Dense(12, activation = \"relu\")(z_0)\n  z_2 = tf.keras.layers.Dense(1, activation=\"softmax\")(z_1)\n\n  # our model will accept the inputs of the two branches and\n  # then output a single value\n  combined_model = tf.keras.Model(inputs=[model_1.input, model_2.input], outputs=z_2)\n\n  combined_model.compile(loss='binary_crossentropy', optimizer='adam')\n\n  return combined_model\n</code></pre>\n\n<p>I also changed my two input networks to the functional API and it still is the same. Would really appreciate any help.</p>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 37}]
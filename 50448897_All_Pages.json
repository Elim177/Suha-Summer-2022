[{"items": [{"tags": ["python", "numpy", "tensorflow"], "owner": {"account_id": 4910266, "reputation": 507, "user_id": 4397162, "user_type": "registered", "profile_image": "https://www.gravatar.com/avatar/44a2f7aea6a0ee61359f985e5171c58e?s=256&d=identicon&r=PG&f=1", "display_name": "johnsmith", "link": "https://stackoverflow.com/users/4397162/johnsmith"}, "is_answered": true, "view_count": 277, "accepted_answer_id": 50476322, "answer_count": 1, "score": 0, "last_activity_date": 1527022485, "creation_date": 1526905596, "last_edit_date": 1526957704, "question_id": 50448897, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/50448897/tensorflow-and-word-embeddings-typeerror-unhashable-type-numpy-ndarray", "title": "TensorFlow and word embeddings - TypeError: unhashable type: &#39;numpy.ndarray&#39;", "body": "<p>I wish to modify the code at <a href=\"http://www.brightideasinanalytics.com/rnn-pretrained-word-vectors/\" rel=\"nofollow noreferrer\">http://www.brightideasinanalytics.com/rnn-pretrained-word-vectors/</a>, which is about predicting the next word, to have code that predicts answers to questions.</p>\n\n<p>Here is an excerpt of the code I'm having trouble with:</p>\n\n<pre><code>import tensorflow.contrib as ct\n\ndef NHIDDEN():\n    return 1\n\ng = tf.Graph()\ntf.reset_default_graph()\n\nwith g.as_default():\n    # lines 97-104 of original code\n    # RNN output node weights and biases\n    weights = { 'out': tf.Variable(tf.random_normal([NHIDDEN(), embedding_dim])) }\n    biases = { 'out': tf.Variable(tf.random_normal([embedding_dim])) }\n\n    with tf.name_scope(\"embedding\"):\n        W = tf.Variable(tf.constant(0.0, shape=[vocab_size, embedding_dim]),\n                    trainable=False, name=\"W\")\n        embedding_placeholder = tf.placeholder(tf.float32, [vocab_size, embedding_dim])\n        embedding_init = W.assign(embedding_placeholder)\n        preimage = tf.nn.embedding_lookup(W, x2)\n\n    # lines 107-119 of original\n    # reshape input data\n    x_unstack = tf.unstack(preimage)\n\n    # create RNN cells\n    rnn_cell = ct.rnn.MultiRNNCell([ct.rnn.BasicLSTMCell(NHIDDEN()), ct.rnn.BasicLSTMCell(NHIDDEN())])\n    outputs, states = ct.rnn.static_rnn(rnn_cell, x_unstack, dtype=tf.float32)\n\n    # capture only the last output\n    pred = tf.matmul(outputs[-1], weights['out']) + biases['out'] \n\n    # Create loss function and optimizer\n    cost = tf.reduce_mean(tf.nn.l2_loss(pred-y))\n    optimizer = tf.train.AdamOptimizer(learning_rate=0.001).minimize(cost)\n\n    # lines 130, 134 and 135 of original\n    step = 0\n    acc_total = 0\n    loss_total = 0\n\n    with tf.Session(graph = g) as sess:\n        # lines 138, 160, 162, 175, 178 and 182 of original\n        while step &lt; 1: # training_iters:\n            _,loss, pred_ = sess.run([optimizer, cost, pred], feed_dict =\n                                 {x: tf.nn.embedding_lookup(W, x2), y: tf.nn.embedding_lookup(W, y)})\n            loss_total += loss\n            print(\"loss = \" + \"{:.6f}\".format(loss_total))\n            step += 1\n        print (\"Finished Optimization\")\n</code></pre>\n\n<p>The error I get is:</p>\n\n<pre><code>---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\n&lt;ipython-input-7-7a72d8d4f100&gt; in &lt;module&gt;()\n     42         while step &lt; 1: # training_iters:\n     43             _,loss, pred_ = sess.run([optimizer, cost, pred], feed_dict =\n---&gt; 44                                      {x: tf.nn.embedding_lookup(W, x2), y: tf.nn.embedding_lookup(W, y)})\n     45             loss_total += loss\n     46             print(\"loss = \" + \"{:.6f}\".format(loss_total))\n\nTypeError: unhashable type: 'numpy.ndarray'\n</code></pre>\n\n<p>How do I fix the code? Is it because of <code>unstack</code>ing?</p>\n\n<p>Additional context: <code>x2</code> and <code>y</code> are assigned the return value of <code>np.array(list(vocab_processor.transform([s])))</code> where <code>s</code> is a string (by passing different strings). <code>embedding_dim</code>, <code>vocab_size</code> and <code>W</code> are computed using the code at <a href=\"https://ireneli.eu/2017/01/17/tensorflow-07-word-embeddings-2-loading-pre-trained-vectors/\" rel=\"nofollow noreferrer\">https://ireneli.eu/2017/01/17/tensorflow-07-word-embeddings-2-loading-pre-trained-vectors/</a>.</p>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 38}]
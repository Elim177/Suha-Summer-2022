[{"items": [{"tags": ["python", "tensorflow", "keras", "deep-learning", "tensorflow2.0"], "owner": {"account_id": 16230354, "reputation": 2719, "user_id": 11725056, "user_type": "registered", "profile_image": "https://www.gravatar.com/avatar/3fb8aa3bd56b90f894e9805de55ff840?s=256&d=identicon&r=PG&f=1", "display_name": "Deshwal", "link": "https://stackoverflow.com/users/11725056/deshwal"}, "is_answered": true, "view_count": 3086, "accepted_answer_id": 69093914, "answer_count": 3, "score": 5, "last_activity_date": 1631248689, "creation_date": 1599732279, "question_id": 63827339, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/63827339/how-to-build-a-custom-data-generator-for-keras-tf-keras-where-x-images-are-being", "title": "How to build a Custom Data Generator for Keras/tf.Keras where X images are being augmented and corresponding Y labels are also images", "body": "<p>I am working on Image Binarization using UNet and have a dataset of 150 images and their binarized versions too. My idea is to augment the images randomly to make them look like they are differentso I have made a function which inserts any of the 4-5 types of Noises, skewness, shearing and so on to an image. I could have easily used</p>\n<p><code>ImageDataGenerator(preprocess_function=my_aug_function)</code> to augment the images but the problem is that my <strong>y target</strong> is also an image. Also, I could have used something like:</p>\n<pre><code>train_dataset = (\n    train_dataset.map(\n        encode_single_sample, num_parallel_calls=tf.data.experimental.AUTOTUNE\n    )\n    .batch(batch_size)\n    .prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n)\n</code></pre>\n<p>But it has 2 problems:</p>\n<ol>\n<li>With larger dataset, it'll blow up the memory as data needs to be already in the memory</li>\n<li>This is the crucial part that I need to augment the images on the go to make it look like I have a huge dataset.</li>\n</ol>\n<p>Another Solution could be saving augmented images to a directory and making them 30-40K and then loading them. It would be silly thing to do.</p>\n<p>Now the idea part is that I can use <code>Sequence</code> as the parent class but How can I keep on augmenting and generating new images on the fly with respective Y binarized images?</p>\n<p>I have an idea as the below code. Can somebody help me with the augmentation and generation of y images. I have my <code>X_DIR, Y_DIR</code> where image names for binarised and original are same but stored in different directories.</p>\n<pre><code>class DataGenerator(tensorflow.keras.utils.Sequence):\n    def __init__(self, files_path, labels_path, batch_size=32, shuffle=True, random_state=42):\n        'Initialization'\n        self.files = files_path\n        self.labels = labels_path\n        self.batch_size = batch_size\n        self.shuffle = shuffle\n        self.random_state = random_state\n        self.on_epoch_end()\n\n\n    def on_epoch_end(self):\n        'Updates indexes after each epoch'\n        # Shuffle the data here\n\n\n    def __len__(self):\n        return int(np.floor(len(self.files) / self.batch_size))\n\n    def __getitem__(self, index):\n        # What do I do here? \n\n\n    def __data_generation(self, files):\n        # I think this is responsible for Augmentation but no idea how should I implement it and how does it works.\n\n</code></pre>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 60}]
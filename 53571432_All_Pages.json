[{"items": [{"tags": ["tensorflow", "tensorflow-datasets"], "owner": {"user_type": "does_not_exist", "display_name": "user9670587"}, "is_answered": false, "view_count": 1961, "answer_count": 1, "score": 4, "last_activity_date": 1545009234, "creation_date": 1543672214, "question_id": 53571432, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/53571432/replacing-queue-based-input-pipelines-with-tf-data", "title": "Replacing Queue-based input pipelines with tf.data", "body": "<p>I am reading Ganegedara\u2018s NLP with Tensorflow. The introduction to input pipieline has the following example</p>\n\n<pre><code>import tensorflow as tf\nimport numpy as np\nimport os\n\n# Defining the graph and session\ngraph = tf.Graph() # Creates a graph\nsession = tf.InteractiveSession(graph=graph) # Creates a session\n\n# The filename queue\nfilenames = ['test%d.txt'%i for i in range(1,4)]\nfilename_queue = tf.train.string_input_producer(filenames, capacity=3, shuffle=True,name='string_input_producer')\n\n# check if all files are there\nfor f in filenames:\n    if not tf.gfile.Exists(f):\n        raise ValueError('Failed to find file: ' + f)\n    else:\n        print('File %s found.'%f)\n\n# Reader which takes a filename queue and \n# read() which outputs data one by one\nreader = tf.TextLineReader()\n\n# ready the data of the file and output as key,value pairs \n# We're discarding the key\nkey, value = reader.read(filename_queue, name='text_read_op')\n\n# if any problems encountered with reading file \n# this is the value returned\nrecord_defaults = [[-1.0], [-1.0], [-1.0], [-1.0], [-1.0], [-1.0], [-1.0], [-1.0], [-1.0], [-1.0]]\n\n# decoding the read value to columns\ncol1, col2, col3, col4, col5, col6, col7, col8, col9, col10 = tf.decode_csv(value, record_defaults=record_defaults)\nfeatures = tf.stack([col1, col2, col3, col4, col5, col6, col7, col8, col9, col10])\n\n# output x is randomly assigned a batch of data of batch_size \n# where the data is read from the txt files\nx = tf.train.shuffle_batch([features], batch_size=3,\n                           capacity=5, name='data_batch', \n                           min_after_dequeue=1,num_threads=1)\n\n# QueueRunner retrieve data from queues and we need to explicitly start them\n# Coordinator coordinates multiple QueueRunners\ncoord = tf.train.Coordinator()\nthreads = tf.train.start_queue_runners(coord=coord, sess=session)\n\n# Executing operations and evaluating nodes in the graph\ntf.global_variables_initializer().run() # Initialize the variables\n\n# Calculate h with x and print the results for 5 steps\nfor step in range(5):\n    x_eval = session.run(x) \n    print('========== Step %d =========='%step)\n    print('Evaluated data (x)')\n    print(x_eval)\n    print('')\n\n# We also need to explicitly stop the coordinator \n# otherwise the process will hang indefinitely\ncoord.request_stop()\ncoord.join(threads)\nsession.close()\n</code></pre>\n\n<p>Which has the following output:</p>\n\n<pre><code>========== Step 0 ==========\nEvaluated data (x)\n[[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]]\n\n========== Step 1 ==========\nEvaluated data (x)\n[[1.  0.9 0.8 0.7 0.6 0.5 0.4 0.3 0.2 0.1]\n [1.  0.9 0.8 0.7 0.6 0.5 0.4 0.3 0.2 0.1]\n [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]]\n\n========== Step 2 ==========\nEvaluated data (x)\n[[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n [1.  0.9 0.8 0.7 0.6 0.5 0.4 0.3 0.2 0.1]\n [1.  0.9 0.8 0.7 0.6 0.5 0.4 0.3 0.2 0.1]]\n\n========== Step 3 ==========\nEvaluated data (x)\n[[0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1. ]\n [0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1. ]\n [0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1. ]]\n\n========== Step 4 ==========\nEvaluated data (x)\n[[0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1. ]\n [1.  0.9 0.8 0.7 0.6 0.5 0.4 0.3 0.2 0.1]\n [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]]\n</code></pre>\n\n<p>It also generates a lot of warning about Queue-based input pipelines being deprecated and suggests using the tf.data module instead.</p>\n\n<p>This is my attempt to using tf.data module</p>\n\n<pre><code>import tensorflow as tf\nimport numpy as np\nimport os\n\ngraph = tf.Graph()\nsession = tf.InteractiveSession(graph=graph)\nfilenames = ['test%d.txt'%i for i in range(1,4)]\nrecord_defaults = [[-1.0]] * 10\nfeatures = tf.data.experimental.CsvDataset(filenames, record_defaults).batch(batch_size=3).shuffle(buffer_size=5)\nx = features.make_one_shot_iterator().get_next()\nx = tf.convert_to_tensor(x)\n# Executing operations and evaluating nodes in the graph\ntf.global_variables_initializer().run() # Initialize the variables\n# Calculate h with x and print the results for 5 steps\nfor step in range(5):\n    x_eval = session.run(x)\n    print('========== Step %d =========='%step)\n    print('Evaluated data (x)')\n    print(x_eval)\n    print('')\nsession.close()\n</code></pre>\n\n<p>Which produces this output instead:</p>\n\n<pre><code>========== Step 0 ==========\nEvaluated data (x)\n[[0.1 0.1 0.1]\n [0.2 0.2 0.2]\n [0.3 0.3 0.3]\n [0.4 0.4 0.4]\n [0.5 0.5 0.5]\n [0.6 0.6 0.6]\n [0.7 0.7 0.7]\n [0.8 0.8 0.8]\n [0.9 0.9 0.9]\n [1.  1.  1. ]]\n\n========== Step 1 ==========\nEvaluated data (x)\n[[0.1 0.1 0.1]\n [0.1 0.1 0.1]\n [0.1 0.1 0.1]\n [0.1 0.1 0.1]\n [0.1 0.1 0.1]\n [0.1 0.1 0.1]\n [0.1 0.1 0.1]\n [0.1 0.1 0.1]\n [0.1 0.1 0.1]\n [0.1 0.1 0.1]]\n\n========== Step 2 ==========\nEvaluated data (x)\n[[1.  1.  1. ]\n [0.9 0.9 0.9]\n [0.8 0.8 0.8]\n [0.7 0.7 0.7]\n [0.6 0.6 0.6]\n [0.5 0.5 0.5]\n [0.4 0.4 0.4]\n [0.3 0.3 0.3]\n [0.2 0.2 0.2]\n [0.1 0.1 0.1]]\n\n========== Step 3 ==========\nEvaluated data (x)\n[[0.1 0.1 0.1]\n [0.2 0.2 0.1]\n [0.3 0.3 0.1]\n [0.4 0.4 0.1]\n [0.5 0.5 0.1]\n [0.6 0.6 0.1]\n [0.7 0.7 0.1]\n [0.8 0.8 0.1]\n [0.9 0.9 0.1]\n [1.  1.  0.1]]\n\n========== Step 4 ==========\nEvaluated data (x)\n[[0.1 1.  1. ]\n [0.1 0.9 0.9]\n [0.1 0.8 0.8]\n [0.1 0.7 0.7]\n [0.1 0.6 0.6]\n [0.1 0.5 0.5]\n [0.1 0.4 0.4]\n [0.1 0.3 0.3]\n [0.1 0.2 0.2]\n [0.1 0.1 0.1]]\n</code></pre>\n\n<p>It looks like the original code samples 3 rows everytime, and my attempt with tf.data samples 3 columns. Why is this and how can I fix my code and make it equivalent to the original?</p>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 65}]
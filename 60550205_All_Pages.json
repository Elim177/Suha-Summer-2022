[{"items": [{"tags": ["python", "deep-learning", "conv-neural-network"], "owner": {"account_id": 26373, "reputation": 43816, "user_id": 68571, "user_type": "registered", "accept_rate": 79, "profile_image": "https://i.stack.imgur.com/Yw9Lg.png?s=256&g=1", "display_name": "VansFannel", "link": "https://stackoverflow.com/users/68571/vansfannel"}, "is_answered": true, "view_count": 79, "accepted_answer_id": 60550375, "answer_count": 1, "score": 0, "last_activity_date": 1584382969, "creation_date": 1583426476, "last_edit_date": 1584382969, "question_id": 60550205, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/60550205/relationship-between-input-size-and-number-of-filters-on-each-conv2d-layer-in-a", "title": "Relationship between input size and number of filters on each Conv2D layer in a U-NET", "body": "<p>I have this U-NET implementation:</p>\n\n<pre><code>import numpy as np \nimport os\nimport skimage.io as io\nimport skimage.transform as trans\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.python.keras.models import *\nfrom tensorflow.python.keras.layers import *\nfrom tensorflow.python.keras.optimizers import *\nfrom tensorflow.python.keras.callbacks import ModelCheckpoint, LearningRateScheduler\nfrom tensorflow.python.keras import backend as keras\n\ndef unet(pretrained_weights = None,input_size = (240, 240, 1)):\n    inputs = Input(input_size)\n    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n    drop4 = Dropout(0.5)(conv4)\n    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n\n    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n    drop5 = Dropout(0.5)(conv5)\n\n    up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n    merge6 = concatenate([drop4,up6], axis = 3)\n    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n\n    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n    merge7 = concatenate([conv3,up7], axis = 3)\n    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n\n    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n    merge8 = concatenate([conv2,up8], axis = 3)\n    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n\n    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n    merge9 = concatenate([conv1,up9], axis = 3)\n    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n    conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n    conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)\n\n    model = Model(inputs = inputs, outputs = conv10)\n\n    model.compile(tf.keras.optimizers.Adam(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['accuracy'])\n\n    #model.summary()\n\n    if(pretrained_weights):\n        model.load_weights(pretrained_weights)\n\n    return model\n</code></pre>\n\n<p>When I change its <code>input_size</code> parameter to <code>(200, 200, 1)</code> it fails with this error:</p>\n\n<pre><code>A `Concatenate` layer requires inputs with matching shapes except for the concat axis. Got inputs shapes: [(None, 25, 25, 512), (None, 24, 24, 512)]\n</code></pre>\n\n<p>At this line:</p>\n\n<pre><code>merge6 = concatenate([drop4,up6], axis = 3)\n</code></pre>\n\n<p>I think the problem is related to the size of the filters in <a href=\"https://keras.io/layers/convolutional/#conv2d\" rel=\"nofollow noreferrer\">Conv2D</a> layers.</p>\n\n<p>Is there any relationship between <code>input_size</code> and filters size in all <code>Conv2D</code> layers?</p>\n\n<p>If there is any relationship, I could fix my problem.</p>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 3}]
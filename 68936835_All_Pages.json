[{"items": [{"tags": ["tensorflow", "keras", "nlp", "tokenize", "bert-language-model"], "owner": {"account_id": 9968983, "reputation": 2859, "user_id": 7375754, "user_type": "registered", "accept_rate": 77, "profile_image": "https://www.gravatar.com/avatar/830f6d236ab0502a68fd9b9daf7f729f?s=256&d=identicon&r=PG&f=1", "display_name": "Jane Sully", "link": "https://stackoverflow.com/users/7375754/jane-sully"}, "is_answered": false, "view_count": 658, "answer_count": 1, "score": 0, "last_activity_date": 1629984054, "creation_date": 1629973621, "question_id": 68936835, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/68936835/how-to-specify-input-sequence-length-for-bert-tokenizer-in-tensorflow", "title": "How to specify input sequence length for BERT tokenizer in Tensorflow?", "body": "<p>I am following this <a href=\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4\" rel=\"nofollow noreferrer\">example</a> to use BERT for sentiment classification.</p>\n<pre><code>text_input = tf.keras.layers.Input(shape=(), dtype=tf.string)\npreprocessor = hub.KerasLayer(\n    &quot;https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3&quot;) # 128 by default\nencoder_inputs = preprocessor(text_input)\nencoder = hub.KerasLayer(\n    &quot;https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4&quot;,\n    trainable=True)\noutputs = encoder(encoder_inputs)\npooled_output = outputs[&quot;pooled_output&quot;]      # [batch_size, 768].\nsequence_output = outputs[&quot;sequence_output&quot;]  # [batch_size, seq_length, 768].\nembedding_model = tf.keras.Model(text_input, pooled_output)sentences = tf.constant([&quot;(your text here)&quot;])print(embedding_model(sentences))\n</code></pre>\n<p>The sequence length by default seems to 128 from looking at the output shape from encoder_inputs. However, I\u2019m not sure how to change this? Ideally I\u2019d like to use to a larger sequence length.</p>\n<p>There\u2019s an example of modifying sequence length from the preprocessor page, but I\u2019m not sure how to incorporate this into the functional model definition I have above? I would greatly appreciate any help with this.</p>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 0}]
[{"items": [{"tags": ["tensorflow", "tensorflow-slim"], "owner": {"account_id": 97477, "reputation": 4181, "user_id": 264410, "user_type": "registered", "accept_rate": 60, "profile_image": "https://www.gravatar.com/avatar/98a0fcc9a9390a0863a901945c45212c?s=256&d=identicon&r=PG", "display_name": "michael", "link": "https://stackoverflow.com/users/264410/michael"}, "is_answered": true, "view_count": 6111, "answer_count": 2, "score": 1, "last_activity_date": 1604014367, "creation_date": 1515730346, "question_id": 48219442, "content_license": "CC BY-SA 3.0", "link": "https://stackoverflow.com/questions/48219442/use-tf-to-float-or-tf-image-convert-image-dtype-in-image-pipeline-for-cn", "title": "use `tf.to_float()` or `tf.image.convert_image_dtype()` in image pipeline for CNN?", "body": "<p>I am modifying the <code>tf.slim</code> example using this file as a template <a href=\"https://github.com/tensorflow/models/blob/master/research/slim/preprocessing/vgg_preprocessing.py\" rel=\"nofollow noreferrer\">vgg_preprocessing.py</a> . </p>\n\n<p>When I read the data from the TFRecord file using a clip from the <code>tf.slim</code> notebook (<a href=\"https://github.com/tensorflow/models/blob/master/research/slim/slim_walkthrough.ipynb\" rel=\"nofollow noreferrer\">slim_walkthrough.ipynb</a>) I get an image with distorted colors. It happens when the pre-processing script uses <code>tf.to_float()</code> changes the image tensor from <code>tf.uint8</code> to <code>tf.float32</code>. </p>\n\n<p><code>image = tf.to_float(image)</code>\n<a href=\"https://i.stack.imgur.com/wB7Jj.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/wB7Jj.png\" alt=\"enter image description here\"></a></p>\n\n<p><code>image = tf.image.convert_image_dtype(image, dtype=tf.float32)</code>\n<a href=\"https://i.stack.imgur.com/gFdkb.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/gFdkb.png\" alt=\"enter image description here\"></a></p>\n\n<p>Do the differences matter after you run it through a CNN? If so, which one is more appropriate for the <code>Vgg16</code> image processing pipeline? Does it matter if I switch to a different pre-trained model like <code>Inception</code>?</p>\n\n<p>Here is the full method:</p>\n\n<pre><code># tf.to_float() and tf.image.convert_image_dtype() give different results\ndef preprocess_for_train(image,\n                     output_height,\n                     output_width):\n  # randomly crop to 224x244\n  image = _random_crop([image], output_height, output_width)[0]\n  image.set_shape([output_height, output_width, 3])\n\n  image = tf.to_float(image)\n  # image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n\n  image = tf.image.random_flip_left_right(image)\n  return image\n</code></pre>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 61}]
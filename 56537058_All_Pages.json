[{"items": [{"tags": ["python", "tensorflow"], "owner": {"account_id": 1913456, "reputation": 331, "user_id": 1726633, "user_type": "registered", "accept_rate": 60, "profile_image": "https://www.gravatar.com/avatar/cd298e702bbaa223ddf3607ba68bc64d?s=256&d=identicon&r=PG", "display_name": "user1726633", "link": "https://stackoverflow.com/users/1726633/user1726633"}, "is_answered": true, "view_count": 39, "accepted_answer_id": 56537561, "answer_count": 1, "score": -1, "last_activity_date": 1560233752, "creation_date": 1560231052, "last_edit_date": 1560232874, "question_id": 56537058, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/56537058/efficient-path-update-for-large-tensors", "title": "Efficient path update for large tensors", "body": "<p>I'm trying to find the most tensorflow efficient way to perform a path dependent update on a large tensor (>200 rows and columns).</p>\n\n<p>The solution needs to be differentiable (and potentially xla compatible)</p>\n\n<p>I'm currently using tf.unstack, examining each tensor in a for loop and using tf.where to filter out the condition I want. This is quite slow and results in many tensor operations</p>\n\n<pre class=\"lang-py prettyprint-override\"><code>\nBt = tf.ones([256])\nBt_n = tf.random_normal([200,256]) # would actually be calculated elsewhere\nMr = tf.random_normal([200,256])\nMp = tf.random_normal([200,256])\n\ntotal = [Bt]\n\nfor mr, mp, n_Bt in zip(tf.unstack(Mr), \n                      tf.unstack(Mp),                                                      \n                      tf.unstack(Bt_n)):\n    Bt = tf.where(tf.logical_or(Bt &lt;= mr, Bt &gt;= mp), n_Bt, Bt)\n    total.append(Bt)\n\nfinal = tf.concat(total, axis=0)\n</code></pre>\n\n<p>Just looking for the most efficient (fewest ops needed) way to accomplish this.</p>\n\n<p>Thanks.</p>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 51}]
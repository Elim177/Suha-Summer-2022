[{"items": [{"tags": ["tensorflow"], "owner": {"account_id": 8811628, "reputation": 61, "user_id": 6584508, "user_type": "registered", "profile_image": "https://lh6.googleusercontent.com/-poDBSuParZw/AAAAAAAAAAI/AAAAAAAAAEg/UZrv7OSNgFk/photo.jpg?sz=256", "display_name": "Hanbin Zheng", "link": "https://stackoverflow.com/users/6584508/hanbin-zheng"}, "is_answered": true, "view_count": 2507, "answer_count": 1, "score": 5, "last_activity_date": 1536862343, "creation_date": 1468414796, "last_edit_date": 1468461888, "question_id": 38352494, "content_license": "CC BY-SA 3.0", "link": "https://stackoverflow.com/questions/38352494/how-tensorflow-deals-with-large-variables-which-can-not-be-stored-in-one-box", "title": "How tensorflow deals with large Variables which can not be stored in one box", "body": "<p>I want to train a DNN model by training data with more than one billion feature dimensions. So the shape of the first layer weight matrix will be (1,000,000,000, 512). this weight matrix is too large to be stored in one box.</p>\n\n<p>By now, is there any solution to deal with such large variables, for example partition the large weight matrix to multiple boxes.</p>\n\n<h2>Update:</h2>\n\n<p>Thanks Olivier and Keveman. let me add more detail about my problem.\nThe example is very sparse and all features are binary value: 0 or 1. The parameter weight looks like  tf.Variable(tf.truncated_normal([1 000 000 000, 512],stddev=0.1))</p>\n\n<p>The solutions kaveman gave seem reasonable, and I will update results after trying.</p>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 46}]
[{"items": [{"tags": ["python", "tensorflow", "recurrent-neural-network", "tensorflow-estimator"], "owner": {"account_id": 4351403, "reputation": 669, "user_id": 3673043, "user_type": "registered", "accept_rate": 50, "profile_image": "https://www.gravatar.com/avatar/5b9edc66864a60b8f10d2e173e1e80fc?s=256&d=identicon&r=PG", "display_name": "suyash", "link": "https://stackoverflow.com/users/3673043/suyash"}, "is_answered": false, "view_count": 186, "answer_count": 0, "score": 1, "last_activity_date": 1534088016, "creation_date": 1534088016, "question_id": 51810283, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/51810283/using-a-placeholder-to-initialize-the-initial-state-for-a-rnn-cell-in-a-tensorfl", "title": "Using a placeholder to initialize the initial state for a RNN Cell in a TensorFlow Estimator model_fn", "body": "<p>I'm having a problem making the cell <code>initial_state</code> configurable so I can use different batch sizes for training and prediction. Essentially at training, I am going to feed fixed size mini batches, while at prediction, I'll predict one input at a time, and feed that back into the model to get the next output. </p>\n\n<p>However, I am unable to create a graph with the first dimension for the cell <code>initial_state</code> configurable. Here is a simple <code>model_fn</code> to model character input</p>\n\n<pre><code>def model_fn(features, labels, mode, params):\n    inputs = tf.one_hot(features, params[\"VOCAB_SIZE\"], 1.0, 0.0)\n\n    cell = tf.nn.rnn_cell.MultiRNNCell([\n        tf.nn.rnn_cell.GRUCell(params[\"INTERNAL_SIZE\"]) for _ in range(params[\"NUM_LAYERS\"])\n    ], state_is_tuple=False)\n\n    pkeep = params[\"DROPOUT_PKEEP\"] if mode == tf.estimator.ModeKeys.TRAIN else 1.0\n    cell = tf.nn.rnn_cell.DropoutWrapper(cell, input_keep_prob=pkeep)\n\n    initial_state = tf.get_variable(\n        \"initial_state\", \n        dtype=tf.float32, \n        initializer=cell.zero_state(params[\"BATCH_SIZE\"], dtype=tf.float32),\n    )\n\n    if mode == tf.estimator.ModeKeys.EVAL:\n        initial_state = cell.zero_state(1, dtype=tf.float32)\n\n    outputs, final_state = tf.nn.dynamic_rnn(cell, inputs, initial_state=initial_state)\n\n    if mode != tf.estimator.ModeKeys.EVAL:\n        tf.assign(initial_state, final_state)\n\n    logits = ...\n\n    if mode == tf.estimator.ModeKeys.PREDICT:\n        logits = tf.reshape(logits, [-1, 1, 98])\n    else:\n        logits = tf.reshape(logits, [-1, features.shape[1], 98])\n\n    probabilities = tf.nn.softmax(logits)\n    predictions = tf.argmax(probabilities, 2)\n\n    if mode == tf.estimator.ModeKeys.PREDICT:\n        predictions = { \"predictions\": predictions, \"probabilities\": probabilities }\n        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n\n    loss = ...\n\n    if mode == tf.estimator.ModeKeys.EVAL:\n        accuracy = tf.metrics.accuracy(labels=labels, predictions=predictions)\n        return tf.estimator.EstimatorSpec(mode, loss=loss, eval_metric_ops={\n            \"accuracy\": accuracy,\n        })\n\n    optimizer = tf.train.AdamOptimizer(learning_rate=params[\"LEARNING_RATE\"])\n    train_op = optimizer.minimize(loss, global_step=tf.train.get_global_step())\n\n    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n</code></pre>\n\n<p>The problem is that the requires me to pass <code>BATCH_SIZE</code> in params that is used to define the <code>initial_state</code>, which at train time is a value like 200. However at test time, for a single batch, it gives an error saying that <code>[1, 384] dimensional tensor cannot be assigned to a [200, 384] dimensional variable</code>. How do I make the dimension of the <code>initial_state</code> configurable based on the training mode?</p>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 75}]
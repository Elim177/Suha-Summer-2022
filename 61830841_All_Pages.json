[{"items": [{"tags": ["tensorflow", "keras", "deep-learning", "conv-neural-network", "vgg-net"], "owner": {"account_id": 18596683, "reputation": 61, "user_id": 13552520, "user_type": "registered", "profile_image": "https://lh6.googleusercontent.com/-OcJ-bRvHDzo/AAAAAAAAAAI/AAAAAAAAAAA/AMZuucm2EdUaq2oG10s8m06AaimFkklfDQ/photo.jpg?sz=256", "display_name": "Rodrigo Pina", "link": "https://stackoverflow.com/users/13552520/rodrigo-pina"}, "is_answered": true, "view_count": 6321, "accepted_answer_id": 62297190, "answer_count": 1, "score": 1, "last_activity_date": 1591770626, "creation_date": 1589593187, "last_edit_date": 1590525490, "question_id": 61830841, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/61830841/why-am-i-getting-valueerror-no-gradients-provided-for-any-variable-variable", "title": "Why am I getting &quot;ValueError: No gradients provided for any variable: [&#39;Variable:0&#39;].&quot; error?", "body": "<p>I'm extremely new to tensorflow, and I'm trying to build a style transfer model, I understand the concept of how the model is but am having difficulty at actually implementing it, since I don't fully understand what is going on in tensorflow, yet. When I try to run the optimization for the generated image I get the \"No gradients provided\" error, which I don't understand since my code has:</p>\n\n<pre><code>    loss = total_loss(content_feats, style_feats, output_feats)\n\n    grad = tape.gradient(loss, output_processado)\n    optimizer.apply_gradients(zip([grad],[output_processado]))\n</code></pre>\n\n<blockquote>\n  <hr>\n  \n  <p>ValueError                                Traceback (most recent call\n  last)</p>\n  \n  <p> in ()\n        8 \n        9     grad = tape.gradient(loss, output_processado)\n  ---> 10     optimizer.apply_gradients(zip([grad],[output_processado]))\n       11 \n       12     clip = tf.clip_by_value(output_processado, min_value, max_value)</p>\n  \n  <p>1 frames</p>\n  \n  <p>/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py in _filter_grads(grads_and_vars)    1217   if not filtered:    1218<br>\n  raise ValueError(\"No gradients provided for any variable: %s.\" %\n  -> 1219                      ([v.name for _, v in grads_and_vars],))    1220   if vars_with_empty_grads:    1221     logging.warning(</p>\n  \n  <p>ValueError: No gradients provided for any variable: ['Variable:0'].</p>\n</blockquote>\n\n<pre><code>import tensorflow as tf\ndevice_name = tf.test.gpu_device_name()\nif device_name != '/device:GPU:0':\n  raise SystemError('GPU device not found')\nprint('Found GPU at: {}'.format(device_name))\n\n\nimport numpy as np\nfrom PIL import Image\nimport requests\nfrom io import BytesIO\nfrom keras.applications.vgg19 import VGG19\nfrom keras.applications.vgg19 import preprocess_input\nfrom keras.preprocessing.image import load_img\nfrom keras.preprocessing.image import img_to_array\nfrom keras.models import Model\nimport keras.backend as K\nfrom matplotlib import pyplot as plt\nfrom numpy import expand_dims\nfrom tensorflow import GradientTape\n\nITERATIONS = 10\nCHANNELS = 3\nIMAGE_SIZE = 500\nIMAGE_WIDTH = IMAGE_SIZE\nIMAGE_HEIGHT = IMAGE_SIZE\nCONTENT_WEIGHT = 0.02\nSTYLE_WEIGHT = 4.5\n\nMEAN = np.array([103.939, 116.779, 123.68])\n\nCONTENT_LAYERS = ['block4_conv2']\nSTYLE_LAYERS = ['block1_conv1', 'block2_conv1', 'block3_conv1', 'block4_conv1', 'block5_conv1']\n\ninput_image_path = \"input.png\"\nstyle_image_path = \"style.png\"\noutput_image_path = \"output.png\"\ncombined_image_path = \"combined.png\"\n\nsan_francisco_image_path = \"https://www.economist.com/sites/default/files/images/print-edition/20180602_USP001_0.jpg\"\n\ntytus_image_path = \"http://meetingbenches.com/wp-content/flagallery/tytus-brzozowski-polish-architect-and-watercolorist-a-fairy-tale-in-warsaw/tytus_brzozowski_13.jpg\"\n\n\ninput_image = Image.open(BytesIO(requests.get(san_francisco_image_path).content))\ninput_image = input_image.resize((IMAGE_WIDTH, IMAGE_HEIGHT))\ninput_image.save(input_image_path)\n#input_image\n\n# Style visualization \nstyle_image = Image.open(BytesIO(requests.get(tytus_image_path).content))\nstyle_image = style_image.resize((IMAGE_WIDTH, IMAGE_HEIGHT))\nstyle_image.save(style_image_path)\n#style_image\n\ndef obter_modelo():\n\n  modelo = VGG19(include_top = False, weights = 'imagenet', input_tensor = None)\n\n  c_layer = CONTENT_LAYERS\n  s_layers = STYLE_LAYERS\n\n  output_layers = [modelo.get_layer(layer).output for layer in (c_layer + s_layers)]\n\n  return Model(modelo.inputs, output_layers)\n\ndef processar_imagem(img):\n\n  imagem = img.resize((IMAGE_HEIGHT, IMAGE_WIDTH))\n  imagem = img_to_array(imagem)\n  imagem = preprocess_input(imagem)\n  imagem = expand_dims(imagem, axis=0)\n\n  return imagem\n\ndef desprocessar_imagem(img):\n  imagem = img\n  mean = MEAN\n  imagem[..., 0] += mean[0]\n  imagem[..., 1] += mean[1]\n  imagem[..., 2] += mean[2]\n  imagem = imagem[..., ::-1]\n\n  return imagem.astype(int)\n\ndef content_loss(c_mat, out_mat):\n  return 0.5 * K.sum(K.square(out_mat - c_mat))\n\n\ndef matriz_gram(mat):\n  return K.dot(mat,K.transpose(mat))\n\n\ndef style_loss(s_mat, out_mat):\n\n  style_feat = K.batch_flatten(K.permute_dimensions(s_mat,(2,0,1)))\n  output_feat = K.batch_flatten(K.permute_dimensions(out_mat,(2,0,1)))\n\n  style_gram = matriz_gram(style_feat)\n  output_gram = matriz_gram(output_feat)\n\n  return K.sum(K.square(style_gram - output_gram)) / (4.0 * (CHANNELS ** 2) * (IMAGE_SIZE ** 2))\n\n\ndef total_loss(c_layer, s_layers, out_layers):\n\n  content_layer = c_layer[0]\n  out_content = out_layers[0]\n\n  style_layers = s_layers[1:]\n  out_style = out_layers[1:]\n\n  c_loss = content_loss(content_layer[0], out_content[0])\n\n  s_loss = None\n\n  for i in range(len(style_layers)):\n    if s_loss is None:\n      s_loss = style_loss(style_layers[i][0], out_style[i][0])\n\n    else:\n      s_loss += style_loss(style_layers[i][0], out_style[i][0])\n\n  return CONTENT_WEIGHT * c_loss + (STYLE_WEIGHT * s_loss)/len(style_layers)\n\nmodelo = obter_modelo()\n\n#content image\ncontent_processado = processar_imagem(input_image)\ncontent_feats = modelo(K.variable(content_processado))\n\n#style image\nstyle_processado = processar_imagem(style_image)\nstyle_feats = modelo(K.variable(style_processado))\n\n#output image\noutput_processado = preprocess_input(np.random.uniform(0,250,(IMAGE_HEIGHT, IMAGE_WIDTH,CHANNELS)))\noutput_processado = expand_dims(output_processado, axis=0)\noutput_processado = K.variable(output_processado)\n\noptimizer = tf.optimizers.Adam(5,beta_1=.99,epsilon=1e-3)\nepochs=200\n\nmelhor_loss = K.variable(2000000.0)\nmelhor_imagem = None\n\nmin_value = MEAN\nmax_value = 255 + MEAN\nloss = K.variable(0.0)\n\nfor e in range(epochs):\n  with tf.GradientTape() as tape:\n    tape.watch(output_processado)\n    output_feats = modelo(output_processado)\n\n    loss = total_loss(content_feats, style_feats, output_feats)\n\n    grad = tape.gradient(loss, output_processado)\n    optimizer.apply_gradients(zip([grad],[output_processado]))\n\n    clip = tf.clip_by_value(output_processado, min_value, max_value)\n    output_processado.assign(clip)\n    print(\"Epoch: \" + str(e) )\n</code></pre>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 182}]
[{"items": [{"tags": ["python", "numpy", "tensorflow", "keras"], "owner": {"account_id": 26373, "reputation": 43816, "user_id": 68571, "user_type": "registered", "accept_rate": 79, "profile_image": "https://i.stack.imgur.com/Yw9Lg.png?s=256&g=1", "display_name": "VansFannel", "link": "https://stackoverflow.com/users/68571/vansfannel"}, "is_answered": false, "view_count": 87, "answer_count": 0, "score": 0, "last_activity_date": 1591629947, "creation_date": 1591629947, "question_id": 62265539, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/62265539/create-my-own-loss-without-interrupting-the-gradient-chain-registered-by-the-gra", "title": "Create my own loss without interrupting the gradient chain registered by the gradient tape", "body": "<p>I'm learning Tensorflow 2.10, with Python 3.7.7.</p>\n\n<p>I'm trying to use the tutorial \"<a href=\"https://www.tensorflow.org/tutorials/customization/custom_training_walkthrough\" rel=\"nofollow noreferrer\">Tensorflow - Custom training: walkthrough</a>\" to use my own loss function.</p>\n\n<p>This is my first version of loss function, and it works:</p>\n\n<pre><code>    def loss(model, x, y):\n      output = model(x)\n      return tf.norm(y - output)\n</code></pre>\n\n<p>I have changed to try another one, and it doesn't work:</p>\n\n<pre><code>def my_loss(model, x, y):\n  output = model(x)\n\n  # Only valid values for output var are 0.0 and 1.0.\n  output_np = np.array(output)\n  output_np[output_np &gt;= 0.5] = 1.0\n  output_np[output_np &lt; 0.5] = 0.0\n\n  # Counts how many 1.0 are on y var.\n  unique, counts = np.unique(y, return_counts=True)\n  dict_wmh = dict(zip(unique, counts))  \n  wmh_count = 0\n  if 1.0 in dict_wmh:\n    wmh_count = dict_wmh[1.0]\n\n  # Add y and output to get another array.\n  c = y + output_np\n  unique, counts = np.unique(c, return_counts=True)\n  dict_net = dict(zip(unique, counts))\n\n  # Counts how many 2.0 are on this new array.\n  net_count = 0\n  if 2.0 in dict_net:\n    net_count = dict_net[2.0]\n\n  # Return the different between the number of ones in the label and the network output.\n  return wmh_count - net_count\n  #return tf.convert_to_tensor(wmh_count - net_count, dtype=tf.float32)\n</code></pre>\n\n<p>I get the error:</p>\n\n<blockquote>\n  <p>Cannot convert value 0 to a TensorFlow DType.</p>\n</blockquote>\n\n<p>If I change the return with this one:</p>\n\n<pre><code>return tf.convert_to_tensor(wmh_count - net_count, dtype=tf.float32)\n</code></pre>\n\n<p>I get the error:</p>\n\n<blockquote>\n  <p>No gradients provided for any variable: ['conv1_1/kernel:0',\n  'conv1_1/bias:0', ...</p>\n</blockquote>\n\n<p>On this function:</p>\n\n<pre><code>def grad(model, inputs, targets):\n    with tf.GradientTape() as tape:\n        tape.watch(model.trainable_variables)\n        #loss_value = loss(model, inputs, targets)\n        loss_value = my_loss(model, inputs, targets)\n\n    return loss_value, tape.gradient(loss_value, model.trainable_variables)\n</code></pre>\n\n<p>Because I have asked this <a href=\"https://stackoverflow.com/questions/62191618/tf-gradienttape-doesnt-return-gradients\">SO question</a>, now I know that my new loss function \"<a href=\"https://stackoverflow.com/a/62191901/68571\">interrupts the gradient chain registered by the gradient tape</a>\".</p>\n\n<p>This new loss function (my_loss) does the following:</p>\n\n<ol>\n<li>Converts the output of the model into an array which values are 0.0 or 1.0.</li>\n<li>Create a new array adding this <code>output</code> to the <code>y</code> (which values are also 0.0 or 1.0).</li>\n<li>Counts how many 2.0 are this new array.</li>\n<li>Counts how many 1.0 are in the <code>y</code> array.</li>\n<li>Returns the different between point 3 and 4.</li>\n</ol>\n\n<p>How can I convert this into Tensors to not \"<a href=\"https://stackoverflow.com/a/62191901/68571\">interrupts the gradient chain registered by the gradient tape</a>\"?</p>\n\n<p>Maybe there is a native function to do what I am trying to do.</p>\n\n<p>By the way, I have convert it to numpy arrays because I can't do this, <code>output_np[output_np &gt;= 0.5] = 1.0</code>, with Tensors.</p>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 227}]
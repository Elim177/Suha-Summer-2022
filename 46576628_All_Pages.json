[{"items": [{"tags": ["python", "tensorflow", "distributed-computing"], "owner": {"account_id": 8798611, "reputation": 433, "user_id": 6575669, "user_type": "registered", "accept_rate": 0, "profile_image": "https://www.gravatar.com/avatar/7bd481bcde73bb91cce36780635b423d?s=256&d=identicon&r=PG&f=1", "display_name": "prateek agrawal", "link": "https://stackoverflow.com/users/6575669/prateek-agrawal"}, "is_answered": true, "view_count": 1161, "answer_count": 2, "score": 0, "last_activity_date": 1508223072, "creation_date": 1507167807, "question_id": 46576628, "content_license": "CC BY-SA 3.0", "link": "https://stackoverflow.com/questions/46576628/distributed-tensorflow-master-stuck-while-training-workers-do-not-start-traini", "title": "Distributed Tensorflow, Master stuck while training, workers do not start training, while using SyncReplicasOptimizer and MonitoredTrainingSession?", "body": "<p>I am trying to write a synchronous training code in distributed tensorflow using SyncReplicaOptimizer and MonitoredTraining Session.</p>\n\n<p>The problem I am facing is that the master hangs up the training in between after some steps and none of the workers start training. Has any one encountered this before?</p>\n\n<p>This is the code I have written. Data is read from tensor flow records. I have followed the exact way described in the tensorflow website.</p>\n\n<pre><code>def build(self):\n    self.modelObj = Model(self.imagesize, self.targetSize)\n    self.modelObj.model()\n    self.global_step = tf.contrib.framework.get_or_create_global_step()\n    self.opt = tf.train.AdamOptimizer(self.learningrate)\n    if self.syncTraining:\n        self.trainer = tf.train.SyncReplicasOptimizer(self.opt,replicas_to_aggregate=self.num_workers,total_num_replicas=self.num_workers)\n    else:\n        self.trainer = self.opt\n    self.trainstep = self.trainer.minimize(self.modelObj.loss, global_step=self.global_step)\n    self.saver = tf.train.Saver(max_to_keep=1)\n    self.summary_op = tf.summary.merge_all()\n    self.init_op = tf.global_variables_initializer()\n    if self.syncTraining:\n        self.sync_replicas_hook = self.trainer.make_session_run_hook(is_chief = (self.task_index==0))\n\n\ndef train(self):\n    if self.syncTraining:\n\n\n\n        with tf.train.MonitoredTrainingSession(master=self.server.target,\n                                               is_chief=(self.task_index==0),\n                                               checkpoint_dir=self.logdir,\n                                               hooks=[self.sync_replicas_hook]) as self.session:\n            step = 0\n            try:\n                while not self.session.should_stop():\n                    # training\n\n                    [trainx, trainy_] = self.session.run([self.trainx, self.trainy_])\n                    feed = {self.modelObj.x: trainx, self.modelObj.y_: trainy_,\n                            self.modelObj.batch: self.batch_size, self.modelObj.keep_prob: 0.7}\n                    _, trainloss = self.session.run([self.trainstep, self.modelObj.loss], feed_dict=feed)\n\n                    print(\"step: %d, training loss %f\" % (step, trainloss))\n\n                    step += 1\n\n            except tf.errors.OutOfRangeError:\n                print('training finished, number of epochs reached')\n</code></pre>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 94}]
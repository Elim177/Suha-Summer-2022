[{"items": [{"tags": ["python-3.x", "keras", "tensorflow2.0"], "owner": {"account_id": 10051699, "reputation": 420, "user_id": 7431308, "user_type": "registered", "profile_image": "https://lh4.googleusercontent.com/-b9z7Yg-zGIk/AAAAAAAAAAI/AAAAAAAAAQM/-6mGL_zh6B0/photo.jpg?sz=256", "display_name": "Adrien", "link": "https://stackoverflow.com/users/7431308/adrien"}, "is_answered": true, "view_count": 55, "accepted_answer_id": 65638912, "answer_count": 1, "score": 1, "last_activity_date": 1610186697, "creation_date": 1610141221, "last_edit_date": 1610172313, "question_id": 65636637, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/65636637/keras-gradient-wrt-something-else", "title": "Keras gradient wrt something else", "body": "<p>I am working to implement the method described in the article <a href=\"https://drive.google.com/file/d/1s-qs-ivo_fJD9BU_tM5RY8Hv-opK4Z-H/view\" rel=\"nofollow noreferrer\">https://drive.google.com/file/d/1s-qs-ivo_fJD9BU_tM5RY8Hv-opK4Z-H/view</a> . The final algorithm to use is here (it is on page 6):</p>\n<p><a href=\"https://i.stack.imgur.com/d60S8.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/d60S8.png\" alt=\"Algorithm1 \" /></a></p>\n<ul>\n<li>d are units vector</li>\n<li>xhi is a non-null number</li>\n<li>D is the loss function (sparse cross-entropy in my case)</li>\n</ul>\n<p>The idea is to do an adversarial training, by modifying the data in the direction where the network is the most sensible to small changes and training the network with the modified data but with the same label as the original data.</p>\n<p>I am trying to implement this method in Keras with the MNIST dataset and a mini-batch of 100 data, but I can't get my head around with the computation of the gradient wrt r (first line of the 3rd step of the algorithm). I can't figure out how to compute it with Keras. Here is my code :</p>\n<pre class=\"lang-py prettyprint-override\"><code>loss = losses.SparseCategoricalCrossentropy()\n\nfor epoch in range(5):\n    print(f&quot;Start of epoch {epoch}&quot;)\n    for step, (xBatchTrain,yBatchTrain) in enumerate(trainDataset):\n        #Generating the 100 unit vectors\n        randomVectors = np.random.random(xBatchTrain.shape)\n        U = randomVectors / np.linalg.norm(randomVectors,axis=1)[:, None]\n\n        #Generating the r vectors\n        Xi = 2\n        R = tf.convert_to_tensor(U * Xi[:, None],dtype='float32')\n\n        dataNoised = xBatchTrain + R\n\n        with tf.GradientTape(persistent=True) as imTape:\n            imTape.watch(R)\n            #Geting the losses\n            C = [loss(label,pred) for label, pred in zip(yBatchTrain,dumbModel(dataNoised,training=False))]\n\n        #Getting the gradient wrt r for each images\n        for l,r in zip(C,R):\n            print(imTape.gradient(l,r))\n</code></pre>\n<p>The &quot;<code>print</code>&quot; line returns None for every sample. I should return me a vector of 784 values, each for one pixel?</p>\n<p>(I apologize is part of the code is ugly, I am new to Keras, tf and deep learning)</p>\n<p>[EDIT]</p>\n<p>Here is a gist with the whole notebook: <a href=\"https://gist.github.com/DridriLaBastos/136a8e9d02b311e82fe22ec1c2850f78\" rel=\"nofollow noreferrer\">https://gist.github.com/DridriLaBastos/136a8e9d02b311e82fe22ec1c2850f78</a></p>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 234}]
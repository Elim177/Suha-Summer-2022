[{"items": [{"tags": ["tensorflow", "keras", "keras-layer"], "owner": {"account_id": 6948356, "reputation": 765, "user_id": 5331881, "user_type": "registered", "accept_rate": 52, "profile_image": "https://i.stack.imgur.com/1UV1a.jpg?s=256&g=1", "display_name": "Javier Ventajas Hern&#225;ndez", "link": "https://stackoverflow.com/users/5331881/javier-ventajas-hern%c3%a1ndez"}, "is_answered": false, "view_count": 241, "answer_count": 0, "score": 0, "last_activity_date": 1595232507, "creation_date": 1595232507, "question_id": 62991141, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/62991141/loading-tf-keras-model-subclass-calls-step-function-in-superclass", "title": "Loading tf.keras.Model subclass calls step_function in superclass", "body": "<p>I'm implementing a GAN using keras where I override the train_step function to customize my own training loop. When I create the model and fit it, everything works correctly. However, when I load a previously saved model and try to fit it, the train_step function called belongs to the keras.Model superclass, which causes the following error to be thrown:</p>\n<pre><code>    ValueError: No gradients provided for any variable: ['sequential/conv2d/kernel:0', 'sequential_1/conv2d_1/kernel:0', 'sequential_1/batch_normalization/gamma:0', 'sequential_1/batch_normalization/beta:0', 'sequential_2/conv2d_2/kernel:0', 'sequential_2/batch_normalization_1/gamma:0', 'sequential_2/batch_normalization_1/beta:0', 'sequential_3/conv2d_3/kernel:0', 'sequential_3/batch_normalization_2/gamma:0', 'sequential_3/batch_normalization_2/beta:0', 'sequential_4/conv2d_4/kernel:0', 'sequential_4/batch_normalization_3/gamma:0', 'sequential_4/batch_normalization_3/beta:0', 'sequential_5/conv2d_5/kernel:0', 'sequential_5/batch_normalization_4/gamma:0', 'sequential_5/batch_normalization_4/beta:0', 'sequential_6/conv2d_6/kernel:0', 'sequential_6/batch_normalization_5/gamma:0', 'sequential_6/batch_normalization_5/beta:0', 'sequential_7/conv2d_7/kernel:0', 'sequential_7/batch_normalization_6/gamma:0', 'sequential_7/batch_normalization_6/beta:0', 'sequential_8/conv2d_transpose/kernel:0', 'sequential_8/batch_normalization_7/gamma:0', 'sequential_8/batch_normalization_7/beta:0', 'sequential_9/conv2d_transpose_1/kernel:0', 'sequential_9/batch_normalization_8/gamma:0', 'sequential_9/batch_normalization_8/beta:0', 'sequential_10/conv2d_transpose_2/kernel:0', 'sequential_10/batch_normalization_9/gamma:0', 'sequential_10/batch_normalization_9/beta:0', 'sequential_11/conv2d_transpose_3/kernel:0', 'sequential_11/batch_normalization_10/gamma:0', 'sequential_11/batch_normalization_10/beta:0', 'sequential_12/conv2d_transpose_4/kernel:0', 'sequential_12/batch_normalization_11/gamma:0', 'sequential_12/batch_normalization_11/beta:0', 'sequential_13/conv2d_transpose_5/kernel:0', 'sequential_13/batch_normalization_12/gamma:0', 'sequential_13/batch_normalization_12/beta:0', 'sequential_14/conv2d_transpose_6/kernel:0', 'sequential_14/batch_normalization_13/gamma:0', 'sequential_14/batch_normalization_13/beta:0', 'conv2d_transpose_7/kernel:0', 'conv2d_transpose_7/bias:0', 'sequential_15/conv2d_8/kernel:0', 'sequential_16/conv2d_9/kernel:0', 'sequential_16/batch_normalization_14/gamma:0', 'sequential_16/batch_normalization_14/beta:0', 'sequential_17/conv2d_10/kernel:0', 'sequential_17/batch_normalization_15/gamma:0', 'sequential_17/batch_normalization_15/beta:0', 'conv2d_11/kernel:0', 'batch_normalization_16/gamma:0', 'batch_normalization_16/beta:0', 'conv2d_12/kernel:0', 'conv2d_12/bias:0'].\n</code></pre>\n<p>The training script looks like this:</p>\n<pre><code>if __name__ == '__main__':\n    ds_train = create_dataset('flic', test=False, batch_size=32)\n    ds_test = create_dataset('flic', test=True, batch_size=32)\n\n    model_path = './model/gan'\n\n    if os.path.exists(model_path):\n        print('Model found in disk, restoring...')\n        model = load_model(model_path)\n    else:\n        print('Model not found in disk, creating new one...')\n        os.makedirs(model_path)\n        generator = build_generator(img_width=256, img_height=256, output_channels=2)\n        discriminator = build_discriminator(img_width=256, img_height=256, output_channels=2)\n        model = PatchGAN(generator=generator, discriminator=discriminator)\n\n    model.compile()\n\n    model.fit(\n        ds_train,\n        epochs=1,\n        steps_per_epoch=1,\n        callbacks=[\n            TensorBoard(),\n            LambdaCallback(on_epoch_end=lambda epoch, logs: save_model(model, model_path)),\n            LambdaCallback(on_epoch_end=lambda epoch, logs: preview_output(model.generator, ds_test))\n        ]\n    )\n</code></pre>\n<p>And the GAN code looks like this:</p>\n<pre><code>    class PatchGAN(tf.keras.Model):\n\n    def __init__(self,\n                 generator,\n                 discriminator,\n                 lamb=100,\n                 loss_function=BinaryCrossentropy(from_logits=True),\n                 generator_optimizer=Adam(learning_rate=0.0003),\n                 discriminator_optimizer=Adam(learning_rate=0.0003),\n                 *args,\n                 **kwargs):\n\n        super().__init__(*args, **kwargs)\n        self.lamb = lamb\n        self.generator = generator\n        self.discriminator = discriminator\n        self.loss_function = loss_function\n        self.generator_optimizer = generator_optimizer\n        self.discriminator_optimizer = discriminator_optimizer\n        self._set_inputs(generator.inputs)\n\n    def call(self, inputs, training=None, mask=None):\n        return self.generator(inputs)\n\n    def train_step(self, data):\n        input_image, target = data\n\n        with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n            gen_output = self.generator(input_image, training=True)\n            disc_real_output = self.discriminator([input_image, target], training=True)\n            disc_generated_output = self.discriminator([input_image, gen_output], training=True)\n\n            gan_loss = self.loss_function(tf.ones_like(disc_generated_output), disc_generated_output)\n            l1_loss = tf.reduce_mean(tf.abs(target - gen_output))\n            total_gen_loss = gan_loss + (self.lamb * l1_loss)\n\n            real_loss = self.loss_function(tf.ones_like(disc_real_output), disc_real_output)\n            generated_loss = self.loss_function(tf.zeros_like(disc_generated_output), disc_generated_output)\n            total_disc_loss = real_loss + generated_loss\n\n        generator_gradients = gen_tape.gradient(total_gen_loss, self.generator.trainable_variables)\n        discriminator_gradients = disc_tape.gradient(total_disc_loss, self.discriminator.trainable_variables)\n\n        self.generator_optimizer.apply_gradients(\n            zip(generator_gradients, self.generator.trainable_variables))\n        self.discriminator_optimizer.apply_gradients(\n            zip(discriminator_gradients, self.discriminator.trainable_variables))\n\n        return {\n            &quot;d_loss&quot;: total_disc_loss,\n            &quot;g_loss&quot;: total_gen_loss,\n            &quot;gen_gan_loss&quot;: gan_loss,\n            &quot;gen_l1_loss&quot;: l1_loss\n        }\n\n\ndef _downsample(filters, size, apply_batchnorm=True):\n    initializer = tf.random_normal_initializer(0., 0.02)\n    result = tf.keras.Sequential()\n    result.add(\n        tf.keras.layers.Conv2D(filters, size, strides=2,\n                               padding='same', kernel_initializer=initializer,\n                               use_bias=False))\n    if apply_batchnorm:\n        result.add(tf.keras.layers.BatchNormalization())\n    result.add(tf.keras.layers.LeakyReLU())\n    return result\n\n\ndef _upsample(filters, size, apply_dropout=False):\n    initializer = tf.random_normal_initializer(0., 0.02)\n    result = tf.keras.Sequential()\n    result.add(\n        tf.keras.layers.Conv2DTranspose(filters, size, strides=2,\n                                        padding='same', kernel_initializer=initializer,\n                                        use_bias=False))\n    result.add(tf.keras.layers.BatchNormalization())\n    if apply_dropout:\n        result.add(tf.keras.layers.Dropout(0.5))\n    result.add(tf.keras.layers.ReLU())\n    return result\n\n\ndef build_generator(img_width, img_height, output_channels):\n    inputs = tf.keras.layers.Input(shape=[img_width, img_height, 1])\n\n    down_stack = [\n        _downsample(64, 4, apply_batchnorm=False),  # (bs, 128, 128, 64)\n        _downsample(128, 4),  # (bs, 64, 64, 128)\n        _downsample(256, 4),  # (bs, 32, 32, 256)\n        _downsample(512, 4),  # (bs, 16, 16, 512)\n        _downsample(512, 4),  # (bs, 8, 8, 512)\n        _downsample(512, 4),  # (bs, 4, 4, 512)\n        _downsample(512, 4),  # (bs, 2, 2, 512)\n        _downsample(512, 4),  # (bs, 1, 1, 512)\n    ]\n\n    up_stack = [\n        _upsample(512, 4, apply_dropout=True),  # (bs, 2, 2, 1024)\n        _upsample(512, 4, apply_dropout=True),  # (bs, 4, 4, 1024)\n        _upsample(512, 4, apply_dropout=True),  # (bs, 8, 8, 1024)\n        _upsample(512, 4),  # (bs, 16, 16, 1024)\n        _upsample(256, 4),  # (bs, 32, 32, 512)\n        _upsample(128, 4),  # (bs, 64, 64, 256)\n        _upsample(64, 4),  # (bs, 128, 128, 128)\n    ]\n\n    initializer = tf.random_normal_initializer(0., 0.02)\n    last = tf.keras.layers.Conv2DTranspose(output_channels, 4,\n                                           strides=2,\n                                           padding='same',\n                                           kernel_initializer=initializer,\n                                           activation='tanh')  # (bs, 256, 256, 3)\n    x = inputs\n    # Downsampling through the model\n    skips = []\n    for down in down_stack:\n        x = down(x)\n        skips.append(x)\n    skips = reversed(skips[:-1])\n    # Upsampling and establishing the skip connections\n    for up, skip in zip(up_stack, skips):\n        x = up(x)\n        x = tf.keras.layers.Concatenate()([x, skip])\n    x = last(x)\n    return tf.keras.Model(inputs=inputs, outputs=x)\n\n\ndef build_discriminator(img_width, img_height, output_channels):\n    initializer = tf.random_normal_initializer(0., 0.02)\n\n    inp = tf.keras.layers.Input(shape=[img_width, img_height, 1], name='input_image')\n    tar = tf.keras.layers.Input(shape=[img_width, img_height, output_channels], name='target_image')\n\n    x = tf.keras.layers.concatenate([inp, tar])  # (bs, 256, 256, channels*2)\n\n    down1 = _downsample(128, 4, False)(x)  # (bs, 128, 128, 64)\n    down2 = _downsample(256, 4)(down1)  # (bs, 64, 64, 128)\n    down3 = _downsample(256, 4)(down2)  # (bs, 32, 32, 256)\n\n    zero_pad1 = tf.keras.layers.ZeroPadding2D()(down3)  # (bs, 34, 34, 256)\n    conv = tf.keras.layers.Conv2D(512, 4, strides=1,\n                                  kernel_initializer=initializer,\n                                  use_bias=False)(zero_pad1)  # (bs, 31, 31, 512)\n    batchnorm1 = tf.keras.layers.BatchNormalization()(conv)\n    leaky_relu = tf.keras.layers.LeakyReLU()(batchnorm1)\n    zero_pad2 = tf.keras.layers.ZeroPadding2D()(leaky_relu)  # (bs, 33, 33, 512)\n    last = tf.keras.layers.Conv2D(1, 4, strides=1, kernel_initializer=initializer)(zero_pad2)  # (bs, 30, 30, 1)\n    return tf.keras.Model(inputs=[inp, tar], outputs=last)\n</code></pre>\n<p>Does anybody know why this happens?</p>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 209}]
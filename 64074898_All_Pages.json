[{"items": [{"tags": ["python", "tensorflow", "keras", "autoencoder"], "owner": {"account_id": 19598711, "reputation": 1, "user_id": 14344082, "user_type": "registered", "profile_image": "https://www.gravatar.com/avatar/cec2e5bcc8c8cbda5dcabb4b4e76bf15?s=256&d=identicon&r=PG&f=1", "display_name": "NiemalsAufgeben", "link": "https://stackoverflow.com/users/14344082/niemalsaufgeben"}, "is_answered": false, "view_count": 259, "answer_count": 0, "score": 0, "last_activity_date": 1601104298, "creation_date": 1601104298, "question_id": 64074898, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/64074898/variational-auto-encoder-produces-the-same-picture-as-the-input", "title": "Variational Auto Encoder produces the same picture as the input", "body": "<p>I'm trying to train a CVAE, convolutional variational auto encoder, to generate new pictures of human faces.</p>\n<p>I'm using the same loss function, training step function, generating function etc. as in the official <a href=\"https://www.tensorflow.org/tutorials/generative/cvae\" rel=\"nofollow noreferrer\">TensorFlow CVAE Tutorial</a>. I'll post them below.</p>\n<p>The only thing I've changed is the encoder and decoder network and the input and output shapes (because I want 128x128 RGB pictures, while the tutorial deals with 28x28 MNIST pictures).</p>\n<p>The problem I encounter is, that every picture generated (by <code>generate_and_save_images()</code>) is not a new one (variational), but just a picture that exists 1 by 1 in the dataset. (My training dataset has 518 pictures of faces)</p>\n<p>So the generating of new pictures doesn't work, we just have the same pictures 1 by 1 recreated.</p>\n<p>Why? And how to fix it?</p>\n<pre><code>  @tf.function\n  def sample(self, eps=None):\n    if eps is None:\n      eps = tf.random.normal(shape=(100, self.latent_dim))\n    return self.decode(eps, apply_sigmoid=True)\n\n  def encode(self, x):\n    mean, logvar = tf.split(self.encoder(x), num_or_size_splits=2, axis=1)\n    return mean, logvar\n\n  def reparameterize(self, mean, logvar):\n    eps = tf.random.normal(shape=mean.shape)\n    return eps * tf.exp(logvar * .5) + mean\n\n  def decode(self, z, apply_sigmoid=False):\n    logits = self.decoder(z)\n    if apply_sigmoid:\n      probs = tf.sigmoid(logits)\n      return probs\n    return logits\n\ndef log_normal_pdf(sample, mean, logvar, raxis=1):\n  log2pi = tf.math.log(2. * np.pi)\n  return tf.reduce_sum(\n      -.5 * ((sample - mean) ** 2. * tf.exp(-logvar) + logvar + log2pi),\n      axis=raxis)\n\ndef compute_loss(model, x):\n  mean, logvar = model.encode(x)\n  z = model.reparameterize(mean, logvar)\n  x_logit = model.decode(z)\n  cross_ent = tf.nn.sigmoid_cross_entropy_with_logits(logits=x_logit, labels=x)\n  logpx_z = -tf.reduce_sum(cross_ent, axis=[1, 2, 3])\n  logpz = log_normal_pdf(z, 0., 0.)\n  logqz_x = log_normal_pdf(z, mean, logvar)\n  return -tf.reduce_mean(logpx_z + logpz - logqz_x)\n\n@tf.function\ndef train_step(model, x, optimizer):\n  &quot;&quot;&quot;Executes one training step and returns the loss.\n\n  This function computes the loss and gradients, and uses the latter to\n  update the model's parameters.\n  &quot;&quot;&quot;\n  with tf.GradientTape() as tape:\n    loss = compute_loss(model, x)\n  gradients = tape.gradient(loss, model.trainable_variables)\n  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n\n# keeping the random vector constant for generation (prediction) so\n# it will be easier to see the improvement.\nrandom_vector_for_generation = tf.random.normal(\n    shape=[num_examples_to_generate, latent_dim])\n\ndef generate_and_save_images(model, epoch, test_sample):\n  mean, logvar = model.encode(test_sample)\n  z = model.reparameterize(mean, logvar)\n  predictions = model.sample(z)\n  _ = plt.figure(figsize=(20, 20))\n\n  for i in range(predictions.shape[0]):\n    plt.subplot(4, 4, i + 1)\n    plt.imshow(predictions[i, :, :, :])\n    plt.axis('off')\n\n  # tight_layout minimizes the overlap between 2 sub-plots\n  plt.savefig(r'D:\\...\\image_at_epoch_{:04d}.png'.format(epoch))\n  plt.show()\n</code></pre>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 181}]
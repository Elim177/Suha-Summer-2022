[{"items": [{"tags": ["python", "tensorflow2.0", "object-detection-api"], "owner": {"account_id": 12407130, "reputation": 176, "user_id": 9041483, "user_type": "registered", "profile_image": "https://www.gravatar.com/avatar/59df4513b52491907c604fd4a028b965?s=256&d=identicon&r=PG&f=1", "display_name": "Danil Kononyhin", "link": "https://stackoverflow.com/users/9041483/danil-kononyhin"}, "is_answered": false, "view_count": 623, "answer_count": 0, "score": 1, "last_activity_date": 1614272137, "creation_date": 1602234535, "question_id": 64277009, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/64277009/eager-few-shot-object-detection-colab-for-centernet", "title": "Eager Few Shot Object Detection Colab for CenterNet", "body": "<p>I am using Tensorflow Object Detection API. Recently it was updated to Tensorflow2.\nAnd with it authors put out a great Colab <a href=\"https://github.com/tensorflow/models/blob/master/research/object_detection/colab_tutorials/eager_few_shot_od_training_tf2_colab.ipynb\" rel=\"nofollow noreferrer\">https://github.com/tensorflow/models/blob/master/research/object_detection/colab_tutorials/eager_few_shot_od_training_tf2_colab.ipynb</a>. They fine-tune RetinaNet on new dataset, however I don't understand how can I use this to fine-tune CenterNet (and EfficientDet).</p>\n<p>They have the following code for initialising RetinaNet model:</p>\n<pre><code>tf.keras.backend.clear_session()\n\nprint('Building model and restoring weights for fine-tuning...', flush=True)\nnum_classes = 1\npipeline_config = 'models/research/object_detection/configs/tf2/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.config'\ncheckpoint_path = 'models/research/object_detection/test_data/checkpoint/ckpt-0'\n\n# Load pipeline config and build a detection model.\n#\n# Since we are working off of a COCO architecture which predicts 90\n# class slots by default, we override the `num_classes` field here to be just\n# one (for our new rubber ducky class).\nconfigs = config_util.get_configs_from_pipeline_file(pipeline_config)\nmodel_config = configs['model']\nmodel_config.ssd.num_classes = num_classes\nmodel_config.ssd.freeze_batchnorm = True\ndetection_model = model_builder.build(\n      model_config=model_config, is_training=True)\n\n# Set up object-based checkpoint restore --- RetinaNet has two prediction\n# `heads` --- one for classification, the other for box regression.  We will\n# restore the box regression head but initialize the classification head\n# from scratch (we show the omission below by commenting out the line that\n# we would add if we wanted to restore both heads)\nfake_box_predictor = tf.compat.v2.train.Checkpoint(\n    _base_tower_layers_for_heads=detection_model._box_predictor._base_tower_layers_for_heads,\n    # _prediction_heads=detection_model._box_predictor._prediction_heads,\n    #    (i.e., the classification head that we *will not* restore)\n    _box_prediction_head=detection_model._box_predictor._box_prediction_head,\n    )\nfake_model = tf.compat.v2.train.Checkpoint(\n          _feature_extractor=detection_model._feature_extractor,\n          _box_predictor=fake_box_predictor)\nckpt = tf.compat.v2.train.Checkpoint(model=fake_model)\nckpt.restore(checkpoint_path).expect_partial()\n\n# Run model through a dummy image so that variables are created\nimage, shapes = detection_model.preprocess(tf.zeros([1, 640, 640, 3]))\nprediction_dict = detection_model.predict(image, shapes)\n_ = detection_model.postprocess(prediction_dict, shapes)\nprint('Weights restored!')\n</code></pre>\n<p>I tried to do similar thing with CenterNet model (it is used for inferencing in this Colab tutorial <a href=\"https://github.com/tensorflow/models/blob/master/research/object_detection/colab_tutorials/inference_tf2_colab.ipynb\" rel=\"nofollow noreferrer\">https://github.com/tensorflow/models/blob/master/research/object_detection/colab_tutorials/inference_tf2_colab.ipynb</a>):</p>\n<pre><code>pipeline_config =  'models/research/object_detection/configs/tf2/centernet_hourglass104_512x512_coco17_tpu-8.config'\nmodel_dir = 'models/research/object_detection/test_data/checkpoint/'\nnum_classes = 1\n# Load pipeline config and build a detection model\nconfigs = config_util.get_configs_from_pipeline_file(pipeline_config)\nmodel_config = configs['model']\n\nmodel_config.center_net.num_classes = num_classes\ndetection_model = model_builder.build(\n      model_config=model_config, is_training=True)\n\n# Restore checkpoint\nckpt = tf.compat.v2.train.Checkpoint(\n      model=detection_model)\nckpt.restore(os.path.join(model_dir, 'ckpt-0')).expect_partial()\n</code></pre>\n<p>However, an exception is thrown because shapes are not compatible (because I changed number of classes). In the example with RetinaNet this trick was used (as I understand) to make tensors of right shapes:</p>\n<pre><code>fake_box_predictor = tf.compat.v2.train.Checkpoint(\n    _base_tower_layers_for_heads=detection_model._box_predictor._base_tower_layers_for_heads,\n    # _prediction_heads=detection_model._box_predictor._prediction_heads,\n    #    (i.e., the classification head that we *will not* restore)\n    _box_prediction_head=detection_model._box_predictor._box_prediction_head,\n    )\nfake_model = tf.compat.v2.train.Checkpoint(\n          _feature_extractor=detection_model._feature_extractor,\n          _box_predictor=fake_box_predictor)\n</code></pre>\n<p>But how can I discover what should I write inside checkpoint function? (for example, <code>_base_tower_layers_for_heads=detection_model._box_predictor._base_tower_layers_for_heads</code> or <code>_box_prediction_head=detection_model._box_predictor._box_prediction_head</code>)</p>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 51}]
[{"items": [{"tags": ["python", "tensorflow", "keras"], "owner": {"account_id": 17194773, "reputation": 1, "user_id": 12447802, "user_type": "registered", "profile_image": "https://lh3.googleusercontent.com/-CmX3KLf_shU/AAAAAAAAAAI/AAAAAAAAAAA/ACHi3rci-6CMX0QRJ7VSki03GlWIPUD8Og/photo.jpg?sz=256", "display_name": "Hari Khanal", "link": "https://stackoverflow.com/users/12447802/hari-khanal"}, "is_answered": true, "view_count": 382, "answer_count": 2, "score": 0, "last_activity_date": 1589885803, "creation_date": 1574882112, "last_edit_date": 1576409033, "question_id": 59077093, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/59077093/problem-with-training-cifar10-data-in-tensorflow-2", "title": "Problem with training cifar10 data in Tensorflow-2", "body": "<p>I got the following error in training cifar10 data in tensorflow-2. I used this <a href=\"https://www.tensorflow.org/tutorials/quickstart/advanced\" rel=\"nofollow noreferrer\">tutorial</a>.  </p>\n\n<blockquote>\n  <p>TypeError: Expected float32 passed to parameter 'y' of op 'Equal',\n  got 'collections' of type 'str' instead. Error: Expected float32, got\n  'collections' of type 'str' instead.</p>\n</blockquote>\n\n<p>My code looks like:</p>\n\n<pre><code>    class Mymodel(tf.keras.Model):\n\n        def __init__(self, class_size):\n            \"\"\"Initialize parameters and build model.\n            \"\"\"\n            super(Mymodel, self).__init__()\n\n            self.class_size =class_size\n            self.conv1 = tf.keras.layers.Conv2D(32, kernel_size =3, strides =2, activation='relu')\n            self.conv2 = tf.keras.layers.Conv2D(64, kernel_size =2, strides =2, activation='relu')\n            self.conv3 = tf.keras.layers.Conv2D(64, kernel_size =2, strides =1, activation='relu')\n            self.flat = tf.keras.layers.Flatten()\n            self.d1 = tf.keras.layers.Dense(512, activation='relu')\n            self.d2 = tf.keras.layers.Dense(128, activation='relu')\n            self.fd =tf.keras.layers.Dense(self.class_size, activation='softmax') \n\n        def call(self, inputs):\n            x = self.conv1(inputs)\n            x = self.conv2(x)\n            x = self.conv3(x)\n            x = self.flat(x)\n            x = self.d1(x)\n            x = self.d2(x)\n            return self.fd(x)\n\n    model = Mymodel(10)\n\n    train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n    train_images, test_images = train_images / 255.0, test_images / 255.0\n\n    train_ds = tf.data.Dataset.from_tensor_slices(\n        (train_images, train_labels)).shuffle(1000).batch(32)\n\n    test_ds = tf.data.Dataset.from_tensor_slices((test_images, test_labels)).batch(32)\n\n    # define the training and testing objects \n\n    loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n\n    optimizer = tf.keras.optimizers.Adam()\n\n    @tf.function\n    def train_step(images, labels):\n      with tf.GradientTape() as tape:\n        predictions = model(images)\n        loss = loss_object(labels, predictions)\n      gradients = tape.gradient(loss, model.trainable_variables)\n      optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n      loss(loss)\n      accuracy(labels, predictions)\n\n\ntf.function\ndef test_step(images, labels):\n  predictions = model(images)\n  t_loss = loss_object(labels, predictions)\n  loss(t_loss)\n  accuracy(labels, predictions)\n\n\ndef train():\n    EPOCHS = 5\n\n    for epoch in range(EPOCHS):\n      for images, labels in train_ds:\n        train_step(images, labels)\n\n      for test_images, test_labels in test_ds:\n        test_step(test_images, test_labels)\n\n      template = 'Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, Test Accuracy: {}'\n      print(template.format(epoch+1,\n                        train_loss.result(),\n                        train_accuracy.result()*100,\n                        test_loss.result(),\n                        test_accuracy.result()*100))\n\n      # Reset the metrics for the next epoch\n    train_loss.reset_states()\n    train_accuracy.reset_states()\n    test_loss.reset_states()\n    test_accuracy.reset_states()\ntrain()\n</code></pre>\n\n<p>It works when I replaced the compile and fit functions.  </p>\n\n<pre><code>model.compile(optimizer='adam',\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])\nmodel.fit(train_images, train_labels, batch_size= 200, epochs=6, validation_data=(test_images, test_labels))\n</code></pre>\n\n<p>Highly appropriated for any help.  </p>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 150}]
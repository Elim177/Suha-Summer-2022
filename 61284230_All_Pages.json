[{"items": [{"tags": ["tensorflow2.0"], "owner": {"account_id": 6837069, "reputation": 21, "user_id": 5258581, "user_type": "registered", "profile_image": "https://www.gravatar.com/avatar/fc6dcd0a89d3b4b78f1cadf3cfb6e5ef?s=256&d=identicon&r=PG&f=1", "display_name": "HeeJo You", "link": "https://stackoverflow.com/users/5258581/heejo-you"}, "is_answered": false, "view_count": 40, "answer_count": 1, "score": 0, "last_activity_date": 1587218372, "creation_date": 1587184178, "last_edit_date": 1587218372, "question_id": 61284230, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/61284230/why-all-weights-become-zeros-in-this-code", "title": "Why all weights become zeros in this code?", "body": "<p>I am trying to make a singer classification on TensorFlow 2. However, when I trained my model, I found all weights finally become to zero matrices. I am not sure why this problem occurs. Please let me know.</p>\n\n<p>The following code is the simplest version of my problem. I tested this code on TF2.1, TF2.2rc0, TF2.2rc3, but the results were same.</p>\n\n<pre><code>import tensorflow as tf\nimport numpy as np\n\naudios = tf.keras.layers.Input(\n    shape= [None,],\n    dtype= tf.float32\n    )\nsingers = tf.keras.layers.Input(\n    shape= [],\n    dtype= tf.int32\n    )\n\nnew_Tensor = tf.keras.layers.Lambda(lambda x: tf.expand_dims(x, axis= -1))(audios)    #[Batch, T, 1]\nnew_Tensor = tf.keras.layers.Dense(128)(new_Tensor) #[Batch, T, 128]\nnew_Tensor = tf.keras.layers.Lambda(lambda x: tf.reduce_mean(x, axis= 1))(new_Tensor)    #[Batch, 128]\nnew_Tensor = tf.keras.layers.Dense(12)(new_Tensor)  #[Batch, 12]\n\noptimizer = tf.keras.optimizers.Adam(\n    learning_rate= 0.002\n    )\n\nmodel = tf.keras.Model(\n    inputs= audios,\n    outputs= new_Tensor\n    )\nmodel.summary()\n\nwhile True:\n    with tf.GradientTape() as tape:\n        # audios = np.random.rand(3, 16000) * 2 - 1\n        singers = np.random.randint(0, 12, 3)\n        audios = np.zeros((3, 16000)) + np.expand_dims(singers, axis= -1)\n\n        logits = model(audios, training= True)        \n        loss = tf.reduce_sum(tf.keras.losses.sparse_categorical_crossentropy(\n            y_true= singers,\n            y_pred= logits\n            ))\n\n    gradients = tape.gradient(loss, model.trainable_variables)\n    optimizer.apply_gradients([\n        (gradient, variable)\n        for gradient, variable in zip(gradients, model.trainable_variables)\n        ])\n    print(loss)\n    for gradient, variable in zip(gradients, model.trainable_variables):\n        print('{}: {}'.format(variable.name, gradient))\n\n\n</code></pre>\n\n<p><br><br>\n<strong>EDIT :</strong></p>\n\n<p>I found a answer. 'tf.keras.losses' does not work without compile. When I changed them to 'tf.nn.sparse_softmax_cross_entropy_with_logits', it works now.</p>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 129}]
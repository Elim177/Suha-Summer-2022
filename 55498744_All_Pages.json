[{"items": [{"tags": ["tensorflow", "keras"], "owner": {"account_id": 108161, "reputation": 5951, "user_id": 287238, "user_type": "registered", "accept_rate": 75, "profile_image": "https://i.stack.imgur.com/oQJH2.jpg?s=256&g=1", "display_name": "mathtick", "link": "https://stackoverflow.com/users/287238/mathtick"}, "is_answered": false, "view_count": 421, "answer_count": 1, "score": 0, "last_activity_date": 1555273405, "creation_date": 1554304925, "last_edit_date": 1555273405, "question_id": 55498744, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/55498744/how-to-construct-and-reuse-networks-across-two-input-branches-of-a-network", "title": "How to construct and reuse networks across two input branches of a network?", "body": "<p>How to do something like this? </p>\n\n<pre><code>nn = get_networks()\nA = nn(X_input)\nB = nn(X_other_input)\nC = A + B\nmodel = ... \n</code></pre>\n\n<p>So that all the tensors in nn are the same, only the input-training branches are different? </p>\n\n<p>In pure tensorflow you do this with </p>\n\n<pre><code>tf.variable_scope('something', reuse=tf.AUTO_REUSE):\n       define stuff here\n</code></pre>\n\n<p>and carefully naming your layers.</p>\n\n<p>But basically you can construct nn in the first place because you can not pass a non-called layer to a layer <strong>call</strong>!</p>\n\n<p>For example:</p>\n\n<pre><code>In [21]: tf.keras.layers.Dense(16)(tf.keras.layers.Dense(8))\n...\nAttributeError: 'Dense' object has no attribute 'shape'\n</code></pre>\n\n<p><strong>UPDATE:</strong></p>\n\n<p>I have been accomplishing this by creating an uncompiled model as the sub-network. That \"model\" can then be passed to other network creation functions. For example, if you have a functionaly equation that you want to solve, you might approximate the function with a network and then pass the network to the function which is itself a network.</p>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 73}]
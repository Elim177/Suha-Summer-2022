[{"items": [{"tags": ["python", "tensorflow"], "owner": {"account_id": 3948330, "reputation": 5043, "user_id": 3259896, "user_type": "registered", "accept_rate": 60, "profile_image": "https://www.gravatar.com/avatar/641c30a7b383022f22b53c8cedb04e3f?s=256&d=identicon&r=PG&f=1", "display_name": "SantoshGupta7", "link": "https://stackoverflow.com/users/3259896/santoshgupta7"}, "is_answered": true, "view_count": 882, "accepted_answer_id": 53405366, "answer_count": 2, "score": 0, "last_activity_date": 1558441100, "creation_date": 1542759133, "question_id": 53403511, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/53403511/tensorflow-custom-estimator-how-to-implement-a-input-fn-function-that-returns", "title": "Tensorflow Custom Estimator: How to implement a `input_fn` function that returns a list of labels, and a list of features ?", "body": "<p>I am trying to convert my Tensorflow graph to use a custom tensorflow estimator, but I am getting stuck defining the function for <code>input_fn</code> ; I am currently getting an error. </p>\n\n<p>This is the function I use to generate my input data and labels</p>\n\n<pre><code>data_index = 0 \nepoch_index = 0 \nrecEpoch_indexA = 0 #Used to help keep store of the total number of epoches with the models\n\ndef generate_batch(batch_size, inputCount): \n    global data_index, epoch_index\n\n    batch = np.ndarray(shape=(batch_size, inputCount), dtype=np.int32) \n    labels = np.ndarray(shape=(batch_size, 1), dtype=np.int32)\n\n    n=0\n    while n &lt; batch_size:\n      if len(    set(my_data[data_index, 1])   ) &gt;= inputCount:\n        labels[n,0] = my_data[data_index, 0]\n        batch[n] = random.sample( set(my_data[data_index, 1]),  inputCount)\n        n = n+1\n        data_index = (data_index + 1) % len(my_data) #may have to do something like len my_data[:]\n        if data_index == 0:\n          epoch_index = epoch_index + 1\n          print('Completed %d Epochs' % epoch_index)\n      else:\n        data_index = (data_index + 1) % len(my_data)\n        if data_index == 0:\n          epoch_index = epoch_index + 1\n          print('Completed %d Epochs' % epoch_index)\n\n    return batch, labels     \n</code></pre>\n\n<p>This is where I define my Estimator and attempt to do training</p>\n\n<pre><code>#Define the estimator\nword2vecEstimator = tf.estimator.Estimator(\n        model_fn=my_model,\n        params={\n            'batch_size': 1024,\n            'embedding_size': 50,\n            'num_inputs': 5,\n            'num_sampled':128\n        })\n\nbatch_size = 16\nnum_inputs = 3\n\n#Train with Estimator\nword2vecEstimator.train(\n    input_fn=generate_batch(batch_size, num_inputs),\n    steps=10)\n</code></pre>\n\n<p>This is the error message that I get</p>\n\n<pre><code>---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\n/usr/lib/python3.6/inspect.py in getfullargspec(func)\n   1118                                        skip_bound_arg=False,\n-&gt; 1119                                        sigcls=Signature)\n   1120     except Exception as ex:\n\n/usr/lib/python3.6/inspect.py in _signature_from_callable(obj, follow_wrapper_chains, skip_bound_arg, sigcls)\n   2185     if not callable(obj):\n-&gt; 2186         raise TypeError('{!r} is not a callable object'.format(obj))\n   2187 \n\nTypeError: (array([[1851833,  670357,  343012],\n       [ 993526,  431296,  935528],\n       [ 938067, 1155719, 2277388],\n       [ 534965, 1125669, 1665716],\n       [1412657, 2152211, 1176177],\n       [ 268114, 2097642, 2707258],\n       [1280762, 1516464,  453615],\n       [2545980, 2302607, 2421182],\n       [1706260, 2735027,  292652],\n       [1802025, 2949676,  653015],\n       [ 854228, 2626773,  225486],\n       [1747135, 1608478, 2503487],\n       [1326661,  272883, 2089444],\n       [3082922, 1359481,  621031],\n       [2636832, 1842777, 1979638],\n       [2512269, 1617986,  389356]], dtype=int32), array([[1175598],\n       [2528125],\n       [1870906],\n       [ 643521],\n       [2349752],\n       [ 754986],\n       [2277570],\n       [2121120],\n       [2384306],\n       [1881398],\n       [3046987],\n       [2505729],\n       [2908573],\n       [2438025],\n       [ 441422],\n       [2355625]], dtype=int32)) is not a callable object\n\nThe above exception was the direct cause of the following exception:\n\nTypeError                                 Traceback (most recent call last)\n&lt;ipython-input-15-7acc939af001&gt; in &lt;module&gt;()\n      5 word2vecEstimator.train(\n      6     input_fn=generate_batch(batch_size, num_inputs),\n----&gt; 7     steps=10)\n\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py in train(self, input_fn, hooks, steps, max_steps, saving_listeners)\n    352 \n    353       saving_listeners = _check_listeners_type(saving_listeners)\n--&gt; 354       loss = self._train_model(input_fn, hooks, saving_listeners)\n    355       logging.info('Loss for final step: %s.', loss)\n    356       return self\n\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py in _train_model(self, input_fn, hooks, saving_listeners)\n   1205       return self._train_model_distributed(input_fn, hooks, saving_listeners)\n   1206     else:\n-&gt; 1207       return self._train_model_default(input_fn, hooks, saving_listeners)\n   1208 \n   1209   def _train_model_default(self, input_fn, hooks, saving_listeners):\n\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py in _train_model_default(self, input_fn, hooks, saving_listeners)\n   1232       features, labels, input_hooks = (\n   1233           self._get_features_and_labels_from_input_fn(\n-&gt; 1234               input_fn, model_fn_lib.ModeKeys.TRAIN))\n   1235       worker_hooks.extend(input_hooks)\n   1236       estimator_spec = self._call_model_fn(\n\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py in _get_features_and_labels_from_input_fn(self, input_fn, mode)\n   1073     \"\"\"Extracts the `features` and labels from return values of `input_fn`.\"\"\"\n   1074     return estimator_util.parse_input_fn_result(\n-&gt; 1075         self._call_input_fn(input_fn, mode))\n   1076 \n   1077   def _extract_batch_length(self, preds_evaluated):\n\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py in _call_input_fn(self, input_fn, mode)\n   1151       ValueError: if `input_fn` takes invalid arguments.\n   1152     \"\"\"\n-&gt; 1153     input_fn_args = function_utils.fn_args(input_fn)\n   1154     kwargs = {}\n   1155     if 'mode' in input_fn_args:\n\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/function_utils.py in fn_args(fn)\n     54     if _is_callable_object(fn):\n     55       fn = fn.__call__\n---&gt; 56     args = tf_inspect.getfullargspec(fn).args\n     57     if _is_bounded_method(fn):\n     58       args.remove('self')\n\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/tf_inspect.py in getfullargspec(obj)\n    214   return next((d.decorator_argspec\n    215                for d in decorators\n--&gt; 216                if d.decorator_argspec is not None), _getfullargspec(target))\n    217 \n    218 \n\n/usr/lib/python3.6/inspect.py in getfullargspec(func)\n   1123         # else. So to be fully backwards compatible, we catch all\n   1124         # possible exceptions here, and reraise a TypeError.\n-&gt; 1125         raise TypeError('unsupported callable') from ex\n   1126 \n   1127     args = []\n\nTypeError: unsupported callable\n</code></pre>\n\n<p>Here is a link to the Google Colab notebook for people to run on their own. For anyone looking to execute this, this will download a data file that is ~500 mbs. </p>\n\n<p><a href=\"https://colab.research.google.com/drive/1LjIz04xhRi5Fsw_Q3IzoG_5KkkXI3WFE\" rel=\"nofollow noreferrer\">https://colab.research.google.com/drive/1LjIz04xhRi5Fsw_Q3IzoG_5KkkXI3WFE</a></p>\n\n<p>And here is the full code, from the notebook. </p>\n\n<pre><code>import math\nimport numpy as np\nimport random\nimport zipfile\nimport shutil\nfrom collections import namedtuple\n\nimport os\nimport pprint\n\nimport tensorflow as tf\n\nimport pandas as pd\nimport pickle\nfrom numpy import genfromtxt\n\n!pip install -U -q PyDrive\n\nfrom google.colab import files\nfrom pydrive.auth import GoogleAuth\nfrom pydrive.drive import GoogleDrive\nfrom google.colab import auth\nfrom oauth2client.client import GoogleCredentials\n\nauth.authenticate_user()\ngauth = GoogleAuth()\ngauth.credentials = GoogleCredentials.get_application_default()\ndrive = GoogleDrive(gauth)\n\nvocabulary_size = 3096637 #updated 10-25-18 3096636\n\nimport gc\n\ndl_id = '19yha9Scxq4zOdfPcw5s6L2lkYQWenApC' #updated 10-22-18\n\nmyDownload = drive.CreateFile({'id': dl_id})\nmyDownload.GetContentFile('Data.npy')\nmy_data = np.load('Data.npy')\n#os.remove('Data.npy')\nnp.random.shuffle(my_data)\nprint(my_data[0:15])\n\ndata_index = 0 \nepoch_index = 0 \nrecEpoch_indexA = 0 #Used to help keep store of the total number of epoches with the models\n\ndef generate_batch(batch_size, inputCount): \n    global data_index, epoch_index\n\n    batch = np.ndarray(shape=(batch_size, inputCount), dtype=np.int32) \n    labels = np.ndarray(shape=(batch_size, 1), dtype=np.int32)\n\n    n=0\n    while n &lt; batch_size:\n      if len(    set(my_data[data_index, 1])   ) &gt;= inputCount:\n        labels[n,0] = my_data[data_index, 0]\n        batch[n] = random.sample( set(my_data[data_index, 1]),  inputCount)\n        n = n+1\n        data_index = (data_index + 1) % len(my_data) #may have to do something like len my_data[:]\n        if data_index == 0:\n          epoch_index = epoch_index + 1\n          print('Completed %d Epochs' % epoch_index)\n      else:\n        data_index = (data_index + 1) % len(my_data)\n        if data_index == 0:\n          epoch_index = epoch_index + 1\n          print('Completed %d Epochs' % epoch_index)\n\n    return batch, labels     \n\ndef my_model( features, labels, mode, params):\n\n#     train_dataset = tf.placeholder(tf.int32, shape=[batch_size, num_inputs ])\n#     train_labels = tf.placeholder(tf.int32, shape=[batch_size, 1])\n\n    train_dataset = features\n    train_labels = labels\n\n    batch_sizeE=params[\"batch_size\"]\n    embedding_sizeE=params[\"embedding_size\"]\n    num_inputsE=params[\"num_inputs\"]\n    num_sampledE=params[\"num_sampled\"]\n\n    epochCount = tf.get_variable( 'epochCount', initializer= 0) #to store epoch count to total # of epochs are known\n    update_epoch = tf.assign(epochCount, epochCount + 1)\n\n    embeddings = tf.get_variable( 'embeddings', dtype=tf.float32,\n        initializer= tf.random_uniform([vocabulary_size, embedding_sizeE], -1.0, 1.0, dtype=tf.float32) )\n\n    softmax_weights = tf.get_variable( 'softmax_weights', dtype=tf.float32,\n        initializer= tf.truncated_normal([vocabulary_size, embedding_sizeE],\n                             stddev=1.0 / math.sqrt(embedding_sizeE), dtype=tf.float32 ) )\n\n    softmax_biases = tf.get_variable('softmax_biases', dtype=tf.float32,\n        initializer= tf.zeros([vocabulary_size], dtype=tf.float32),  trainable=False )\n\n    embed = tf.nn.embedding_lookup(embeddings, train_dataset) #train data set is\n\n    embed_reshaped = tf.reshape( embed, [batch_sizeE*num_inputs, embedding_sizeE] )\n\n    segments= np.arange(batch_size).repeat(num_inputs)\n\n    averaged_embeds = tf.segment_mean(embed_reshaped, segments, name=None)\n\n    loss = tf.reduce_mean(\n        tf.nn.sampled_softmax_loss(weights=softmax_weights, biases=softmax_biases, inputs=averaged_embeds, \n                                   sampled_values=tf.nn.uniform_candidate_sampler(true_classes=tf.cast(train_labels, tf.int64), num_sampled=num_sampled, num_true=1, unique=True, range_max=vocabulary_size, seed=None),\n                                   labels=train_labels, num_sampled=num_sampled, num_classes=vocabulary_size)) \n\n    optimizer = tf.train.AdagradOptimizer(1.0).minimize(loss) \n\n    saver = tf.train.Saver()\n\n#Define the estimator\nword2vecEstimator = tf.estimator.Estimator(\n        model_fn=my_model,\n        params={\n            'batch_size': 1024,\n            'embedding_size': 50,\n            'num_inputs': 5,\n            'num_sampled':128\n        })\n\nbatch_size = 16\nnum_inputs = 3\n\n#Train with Estimator\nword2vecEstimator.train(\n    input_fn=generate_batch(batch_size, num_inputs),\n    steps=10)\n</code></pre>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 296}]
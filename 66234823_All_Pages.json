[{"items": [{"tags": ["tensorflow", "gradient", "gradienttape"], "owner": {"account_id": 13827493, "reputation": 1, "user_id": 9981367, "user_type": "registered", "profile_image": "https://www.gravatar.com/avatar/4805bf9d37ae7c494c0c6236e57db4b6?s=256&d=identicon&r=PG&f=1", "display_name": "C Chiang", "link": "https://stackoverflow.com/users/9981367/c-chiang"}, "is_answered": false, "view_count": 304, "answer_count": 1, "score": 0, "last_activity_date": 1613542341, "creation_date": 1613527996, "question_id": 66234823, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/66234823/problem-about-getting-none-from-the-gradienttape-gradient-in-tensorflow", "title": "Problem about getting None from the GradientTape.gradient in TensorFlow", "body": "<h2>I tried the following code:</h2>\n<pre><code>from d2l import tensorflow as d2l\nimport tensorflow as tf\n\n@tf.function\ndef corr2d(X, k, Y):  #@save\n    &quot;&quot;&quot;Compute 2D cross-correlation.&quot;&quot;&quot;\n    with tf.GradientTape() as tape:\n        for i in range(Y.shape[0]):\n            for j in range(Y.shape[1]):\n                Y[i, j].assign(tf.reduce_sum(tf.multiply(X[i: i + h, j: j + w], k)))\n    print('Gradients = ', tape.gradient(Y, k)) # show the gradient\n    print('Watched Variables = ', tape.watched_variables()) # show the watched varaibles\n\nprint(tf.__version__)\nXin= tf.constant([[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]])\nkernel = tf.Variable([[0.0, 1.0], [2.0, 3.0]])\nh, w = kernel.shape\nY_hat = tf.Variable(tf.zeros((Xin.shape[0] - h + 1, Xin.shape[1] - w + 1))) # prepare the output tensor\ncorr2d(X, kernel, Y_hat)\nprint(Y_hat)\n</code></pre>\n<p>I got the following results:</p>\n<pre><code>2.4.1\nGradients =  None\nWatched Variables =  (&lt;tf.Variable 'Variable:0' shape=(2, 2) dtype=float32&gt;, &lt;tf.Variable 'Variable:0' shape=(2, 2) dtype=float32&gt;)\n&lt;tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\narray([[19., 25.],\n       [37., 43.]], dtype=float32)&gt;\n</code></pre>\n<p>Can anyone explain why the returned gradient is <code>None</code> even though the source variable <code>kernel</code> is included in the list of watched variables?</p>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 255}]
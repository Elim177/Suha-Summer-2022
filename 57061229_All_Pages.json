[{"items": [{"tags": ["python", "tensorflow", "conv-neural-network", "tensorflow-datasets", "eager-execution"], "owner": {"user_type": "does_not_exist", "display_name": "user5586747"}, "is_answered": false, "view_count": 115, "answer_count": 0, "score": 0, "last_activity_date": 1563292506, "creation_date": 1563292506, "question_id": 57061229, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/57061229/tensorflow-program-terminates-without-running-to-the-end", "title": "tensorflow program terminates without running to the end", "body": "<p>I wrote the following code for image classification following the tutorial in the tensorflow website about dataset creation. The problem is that after creating the dataset variable, the code just stop executing and terminates. </p>\n\n<pre><code>path_ds = tf.data.Dataset.from_sparse_tensor_slices(all_images)\n# PROGRAM TERMINATES AND DOES NOT EXECUTE THE FOLLOWING LINE \nimage_ds = path_ds.map(load_image)\n</code></pre>\n\n<p>My initial guess was that it might be the problem with eager execution.\nI tried debugging using visual studio code debugger but could not get any far.</p>\n\n<pre><code>import os\nimport numpy as np \nimport tensorflow as tf \nfrom PIL import Image\n\ntf.compat.v1.enable_eager_execution()\n\ntest_folder = \"../Test\"\ntrain_folder = \"../Train\"\nBATCH_SIZE = 32\n\nfolders = os.listdir(train_folder)\nlabels = sorted(folders, key = lambda x : int(x.split(\"_\")[1]) if \"c\" in x else \\\n                                  int(x.split(\"_\")[1])+ 100)\nchar_to_int = dict((label, index) for index, label in enumerate(labels))\nint_to_char = dict((index, label) for index, label in enumerate(labels))\n\ndef load_image(infilename) :\n    img = Image.open( infilename )\n    img.load()\n    data = np.asarray( img, dtype=\"int32\" )\n    return tf.convert_to_tensor(np.expand_dims(data, axis=2))\n\ndef get_all_image_names(folder):\n    children = os.listdir(folder)\n    all_images = []\n    all_labels = []\n    for i in children:\n        images = os.listdir(os.path.join(folder,i))\n        for image in images:\n            path = os.path.join(folder, i, image)\n            all_images.append(path)\n            all_labels.append(char_to_int[i])\n    path_ds = tf.data.Dataset.from_sparse_tensor_slices(all_images)\n\n\n    # PROGRAM TERMINATES AFTER THIS LINE \n\n    image_ds = path_ds.map(load_image)\n    label_ds = tf.data.Dataset.from_sparse_tensor_slices(tf.cast(all_labels, tf.int64))\n    image_label_ds = tf.data.Dataset.zip((image_ds, label_ds))\n    return image_label_ds\n\ndataset = get_all_image_names(train_folder)\n\nds = dataset.shuffle(buffer_size=10000)\nds = ds.batch(BATCH_SIZE)\n\nmodel = tf.keras.models.Sequential([\n  tf.keras.layers.Flatten(input_shape=(32, 32,1)),\n  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n  tf.keras.layers.Dropout(0.2),\n  tf.keras.layers.Dense(64, activation=tf.nn.relu),\n  tf.keras.layers.Dropout(0.2),\n  tf.keras.layers.Dense(46, activation=tf.nn.softmax)\n])\n\nmodel.compile(optimizer='adam',\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])\nmodel.summary()\n\nmodel.fit(ds, epochs=55, verbose=1)\n\nprint(\"MOdel fitted\")\n</code></pre>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 263}]
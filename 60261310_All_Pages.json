[{"items": [{"tags": ["python", "tensorflow", "machine-learning"], "owner": {"account_id": 11089245, "reputation": 99, "user_id": 8141772, "user_type": "registered", "profile_image": "https://www.gravatar.com/avatar/4aff8ba6df657e96ba0244a98e8c3528?s=256&d=identicon&r=PG&f=1", "display_name": "Mr. Johnny Doe", "link": "https://stackoverflow.com/users/8141772/mr-johnny-doe"}, "is_answered": false, "view_count": 1039, "answer_count": 0, "score": 0, "last_activity_date": 1582044908, "creation_date": 1581938245, "last_edit_date": 1582044908, "question_id": 60261310, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/60261310/tf-io-read-file-unable-to-find-file-or-directory-from-a-numpy-array", "title": "tf.io.read_file unable to find file or directory from a numpy array", "body": "<p>For tensor flow data base loading, I saved a numpy array from my database. </p>\n\n<pre><code>images= train_dataset[i]\nimage_string = tf.io.read_file(images)\n</code></pre>\n\n<p>This is a part of my training function. And it seems to be failing.</p>\n\n<p>The issue is </p>\n\n<pre><code>(iP6)21.jpg; No such file or directory\n</code></pre>\n\n<p>Any help appreciated.</p>\n\n<p>Edited to explain the whole code:</p>\n\n<p>train_dataset is a variable to hold a numpy file.</p>\n\n<pre><code>train_dataset=X_train_shuffled\n</code></pre>\n\n<p>for the sake of completeness, here is the entire training function</p>\n\n<pre><code>'training'\nimport time\nimport tensorflow as tf\n#from tensorflow import read_file\ndef train():\n    data=filenames_shuffled\n    data\n    info=y_labels_one_hot_shuffled\n    #data, info = tfds.load(\"mnist\", with_info=True, data_dir='/data/tensorflow_datasets')\n    #train_data = data['train']\n    train_data=X_train_filenames\n\n    if not os.path.exists('./images'):\n        os.makedirs('./images')\n\n    # settting hyperparameter\n    latent_dim = 100\n    epochs = 800\n    batch_size = 32\n    buffer_size = 6000\n    save_interval = 50\n\n    img_shape = (32, 32, 3)\n\n    #num_classes = info.features['label'].num_classes\n    #num_classes=10\n    num_classes=y_train\n    generator = Generator(num_classes)\n    discriminator = Discriminator(num_classes)\n\n    gen_optimizer = tf.keras.optimizers.Adam(0.0002, 0.5)\n    disc_optimizer = tf.keras.optimizers.Adam(0.0002, 0.5)\n\n    #train_dataset = train_data.map(lambda x: preprocess_image(x, img_shape, num_classes)).shuffle(buffer_size).batch(batch_size)\n    train_dataset=train_data\n    cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n\n    @tf.function\n    def train_step(images, labels):\n        noise = tf.random.normal([batch_size, latent_dim])\n\n        with tf.GradientTape(persistent=True) as tape:\n            generated_images = generator(noise, labels)\n\n            real_output = discriminator(images, labels)\n            generated_output = discriminator(generated_images, labels)\n\n            gen_loss = generator_loss(cross_entropy, generated_output)\n            disc_loss = discriminator_loss(cross_entropy, real_output, generated_output)\n\n        grad_gen = tape.gradient(gen_loss, generator.trainable_variables)\n        grad_disc = tape.gradient(disc_loss, discriminator.trainable_variables)\n\n        gen_optimizer.apply_gradients(zip(grad_gen, generator.trainable_variables))\n        disc_optimizer.apply_gradients(zip(grad_disc, discriminator.trainable_variables))\n\n        return gen_loss, disc_loss\n\n    seed = tf.random.normal([16, latent_dim])\n    #train_dataset.append(y_train)\n    #train_dataset=np.append(train_dataset,y_train)\n    for epoch in range(1, epochs + 1):\n        start = time.time()\n        total_gen_loss = 0\n        total_disc_loss = 0\n        #for images in filenames_shuffled and labels in y_labels_one_hot_shuffled:\n        '''\n        Trying an alternate for loop thing. As your numpy cannot be called\n        for images,labels in train_dataset():\n            gen_loss, disc_loss = train_step(images, labels)\n\n            total_gen_loss += gen_loss\n            total_disc_loss += disc_loss\n        '''\n        i=0\n        #print(train_dataset)\n        #print(\"done\")\n        #print(y_train)\n        while i&lt;2200:\n          images= train_dataset[i]\n          labels=y_train[i]\n          '''\n          added this region. Not sure what is happening\n          Input filename tensor must be scalar, but had shape: [2200] [Op:ReadFile]\n          '''\n\n          image_string = tf.io.read_file(images)\n          image_decoded = tf.image.decode_jpeg(image_string, channels=3)\n          images = tf.cast(image_decoded, tf.float32)\n          '''\n          till here\n          '''\n          #filenames_shuffled_numpy, y_labels_one_hot_shuffled\n          #print(\"No error\")\n          gen_loss, disc_loss = train_step(images, labels)\n          #print(\"error\")\n          total_gen_loss += gen_loss\n          total_disc_loss += disc_loss\n          i=i+1\n        print('Time for epoch {} is {} sec - gen_loss = {}, disc_loss = {}'.format(epoch, time.time() - start, total_gen_loss / batch_size, total_disc_loss / batch_size))\n        if epoch % save_interval == 0:\n            save_imgs(epoch, generator, seed)\n\n\nif __name__ == \"__main__\":\n    train()\n</code></pre>\n\n<p>If you need more information, I will happily provide it</p>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 91}]
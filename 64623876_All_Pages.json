[{"items": [{"tags": ["python", "tensorflow", "keras", "lstm"], "owner": {"account_id": 11659632, "reputation": 332, "user_id": 9820561, "user_type": "registered", "profile_image": "https://www.gravatar.com/avatar/8874a9d5b872df17474c1303a9379460?s=256&d=identicon&r=PG&f=1", "display_name": "Mr.O", "link": "https://stackoverflow.com/users/9820561/mr-o"}, "is_answered": true, "view_count": 251, "accepted_answer_id": 64854112, "answer_count": 1, "score": 0, "last_activity_date": 1605511880, "creation_date": 1604161222, "question_id": 64623876, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/64623876/num-units-in-gru-and-lstm-layers-in-keras-tensorflow-2-confuse-meaning", "title": "num_units in GRU and LSTM layers in keras Tensorflow 2 - confuse meaning", "body": "<p>I know that this question raised many time, but I could not get a clear answer because there are different answers:\nIn tf.keras.layers.LSTM tf.keras.layers.GRU layers there is a parameter called num_units. I saw a lot of questions over the internet about this parameter. and there is not clear answer for what this parameter mean expect for the obvious meaning which is the shape of the output. some say that its mean that in each layer there num_units of LSTM or GRU units, some say that it is only one unit of LSTM or GRU, but with num_units hidden units (num_units of tanh, and sigmoids for each gate and so on..) inside the LSTM or GRU layer.</p>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 154}]
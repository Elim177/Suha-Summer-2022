[{"items": [{"tags": ["python", "machine-learning", "keras", "tensorflow2.0", "dcgan"], "owner": {"account_id": 20225836, "reputation": 21, "user_id": 14833771, "user_type": "registered", "profile_image": "https://www.gravatar.com/avatar/5b75cd27122ebef26d8a95fe71c85422?s=256&d=identicon&r=PG&f=1", "display_name": "adestin", "link": "https://stackoverflow.com/users/14833771/adestin"}, "is_answered": true, "view_count": 182, "answer_count": 2, "score": 2, "last_activity_date": 1629196825, "creation_date": 1608082628, "question_id": 65316098, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/65316098/getting-a-valueerror-for-2-inputs-into-a-dcgan-with-tensorflow-keras", "title": "Getting a ValueError for 2 inputs into a DCGAN with Tensorflow/Keras", "body": "<p>So I'm trying to follow the DCGAN guide for image generation on tensorflow <a href=\"https://www.tensorflow.org/tutorials/generative/dcgan\" rel=\"nofollow noreferrer\">https://www.tensorflow.org/tutorials/generative/dcgan</a> , and I have the code replicated pretty closely, just changing the dataset to one that I want to use. Whenever I try to train the model I'm getting this error -</p>\n<blockquote>\n<p>ValueError: Layer sequential_1 expects 1 inputs, but it received 2 input tensors. Inputs received: [&lt;tf.Tensor 'images:0' shape=(256, 28, 28, 3) dtype=float32&gt;, &lt;tf.Tensor 'images_1:0' shape=(256,) dtype=int32&gt;]</p>\n</blockquote>\n<p>Specifically this line  in the train_step function is causing the error,</p>\n<pre><code>real_output = discriminator(images, training=True)\n</code></pre>\n<p>when it gets called here within the train function</p>\n<pre><code>train(normalizedData, epochs)\n</code></pre>\n<p>The definition of the discriminator function is this, earlier in the code:</p>\n<pre><code>def make_discriminator_model():\n    model = tf.keras.Sequential()\n    model.add(layers.Conv2D(64, (5,5), strides=(2,2), padding='same', input_shape=[28, 28, 1]))\n    model.add(layers.LeakyReLU())\n    model.add(layers.Dropout(0.3))\n\n    model.add(layers.Conv2D(128, (5,5), strides=(2,2), padding='same'))\n    model.add(layers.LeakyReLU())\n    model.add(layers.Dropout(0.3))\n\n    model.add(layers.Flatten())\n    model.add(layers.Dense(1))\n\n    return model\n\ndiscriminator = make_discriminator_model()\n</code></pre>\n<p>Here is the rest of that block for context.</p>\n<pre><code>@tf.function\ndef train_step(images):\n    noise = tf.random.normal([batch_size, noise_dim])\n\n    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n        generated_images = generator(noise, training=True)\n\n        real_output = discriminator(images, training=True)\n        fake_output = discriminator(generated_images, training=True)\n\n        gen_loss = generator_loss(fake_output)\n        disc_loss = discriminator_loss(real_output, fake_output)\n\n    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n\n    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n\ndef train(dataset, epochs):\n    for epoch in range(epochs):\n        start = time.time()\n\n        for image_batch in dataset:\n            train_step(image_batch)\n\n        display.clear_output(wait=True)\n        generate_and_save_images(generator,\n                                 epoch + 1,\n                                 seed)\n\n        if (epoch + 1) % 15 == 0:\n            checkpoint.save(file_prefix = checkpoint_prefix)\n\n        print('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n\n    display.clear_output(wait=True)\n    generate_and_save_images(generator,\n                             epochs,\n                             seed)\n\ndef generate_and_save_images(model, epoch, test_input):\n\n    predictions = model(test_input, training=False)\n\n    fig = plt.figure(figsize=(4,4))\n\n    for i in range(predictions.shape[0]):\n        plt.subplot(4,4,i+1)\n        plt.imshow(predicitons[i, :, :, 0] * 127.5 + 127.5, cmap='gist_rainbow')\n        plt.axis('off')\n\n    plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n    plt.show()\n    \n        \ntrain(normalizedData, epochs)\n\n</code></pre>\n<p>I've seen different variations of this question on here about this value error, from what I've gathered that sequential layer is being input a list instead of a tuple?</p>\n<p>Thank you for your time and any help you can offer.</p>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 272}]
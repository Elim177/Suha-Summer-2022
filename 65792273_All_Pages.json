[{"items": [{"tags": ["python", "tensorflow", "machine-learning", "keras", "neural-network"], "owner": {"account_id": 18914215, "reputation": 403, "user_id": 13799627, "user_type": "registered", "profile_image": "https://www.gravatar.com/avatar/eb8d1cb060a1e1838653058c8088ce83?s=256&d=identicon&r=PG&f=1", "display_name": "Crysers", "link": "https://stackoverflow.com/users/13799627/crysers"}, "is_answered": false, "view_count": 637, "closed_date": 1611077004, "answer_count": 0, "score": 2, "last_activity_date": 1611078025, "creation_date": 1611062213, "last_edit_date": 1611078025, "question_id": 65792273, "link": "https://stackoverflow.com/questions/65792273/does-it-make-sense-to-zero-pad-a-time-series-for-a-cnn-model-with-global-average", "closed_reason": "Needs more focus", "title": "Does it make sense to zero-pad a Time Series for a CNN model with Global Average Pooling (GAP) in TensorFlow", "body": "<p>I implement a regression model of a multivariate time series in TensorFlow. The number of input features is 9 and the length of the sequences is variable. Lets say the sequence length is between 32 and 512, but most of them are nearer towards the lower end.</p>\n<p>As I understand, to train in a batched manner, all samples need to have the same length. If I choose the maximum length of all samples, the data tensor will have shape=[batch_size, 512, 9]. To achieve this, I need to zero-pad each sample with length&lt;512.</p>\n<p>My model consists of some simple convolutions plus maxpool-layers:</p>\n<pre class=\"lang-py prettyprint-override\"><code>    class MyModel(tf.keras.Model):\n        def __init__(self, params):\n            super(MyModel, self).__init__()\n            self.params = params\n        def build(self, inputs_shape):\n            self.conv1 = tf.keras.layers.Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=inputs_shape[1:])\n            self.pool1 = tf.keras.layers.MaxPool1D(pool_size=2)\n            self.conv2 = tf.keras.layers.Conv1D(filters=64, kernel_size=3, activation='relu')\n            self.pool2 = tf.keras.layers.MaxPool1D(pool_size=2)        \n            self.conv3 = tf.keras.layers.Conv1D(filters=64, kernel_size=3, activation='relu')\n            self.gpool1 = tf.keras.layers.GlobalAveragePooling1D()\n            self.dense2 = tf.keras.layers.Dense(32, activation='relu')\n            self.dense3 = tf.keras.layers.Dense(1)\n        def call(self, x):\n        ...\n</code></pre>\n<p>So I train my model with a sequence length of 512. In my test set I only have a maximum sequence length of lets say 128. So I only need to pad less.<br />\nDoes the different input sequence length have an impact on the outcome? Since when the majority of samples for an individual sequence is padded, the majority of the output of the convolutional layer will be zero. This means, that the input to the global average pooling will consist of a lot of zeros (dependent on how many samples were padded). When building the average, the presence of many zeros will change the overall outcome.<br />\nThis means, that differnet lengths of input samples will have differnet output.</p>\n<p><strong>So my question is:</strong><br />\nIs there any way to circumvent this problem? Either by A: masking the padded samples for later correction? Or B: training my model with a batch size of 1 so I do not need to pad any sample. --&gt; Is this even possible since the input tensor to the model is different for each training step.</p>\n<p>As far as I understand, this should not be the case when using global maximum pooling, since the additional zeros after the convolkution should not have an impact. However, my experiments show, that there is indeed a difference based on the padding size.<br />\nNow, I\u00b4m not sure, if my thoughts are correct, or am I missing something?</p>\n<p>For inference it also might happen that a never seen sample is even longer than 512 time stamps. This would mean that I need to feed the sample with it\u00b4s original dimensions to the model.</p>\n<p>The concept of Global average pooling is used in many differnet models and I want to implement the <a href=\"https://arxiv.org/pdf/1909.04939.pdf\" rel=\"nofollow noreferrer\">TimeInception network</a> which uses this principle as well.</p>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 223}]
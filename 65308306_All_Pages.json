[{"items": [{"tags": ["python", "machine-learning", "deep-learning", "nlp", "bert-language-model"], "owner": {"user_type": "does_not_exist", "display_name": "user13510399"}, "is_answered": false, "view_count": 194, "answer_count": 1, "score": 2, "last_activity_date": 1620218810, "creation_date": 1608044112, "question_id": 65308306, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/65308306/trying-to-train-model-for-intent-recognition-but-getting-float-error", "title": "Trying to train model for Intent Recognition but getting float error", "body": "<p>I'm trying to train the model for intent recognition. I tried removing all special characters and stop words but unable to resolve this error. I tried removing integers also but it's throwing an error. My data has two columns with one text and one intent column</p>\n<p>The code I've written is</p>\n<pre><code>class IntentDetectionData:\n  DATA_COLUMN = &quot;text&quot;\n  LABEL_COLUMN = &quot;intent&quot;\n\n  def __init__(self, train, test, tokenizer: FullTokenizer, classes, max_seq_len=192):\n    self.tokenizer = tokenizer\n    self.max_seq_len = 0\n    self.classes = classes\n    \n    train, test = map(lambda df: df.reindex(df[IntentDetectionData.DATA_COLUMN].str.len().sort_values().index), [train, test])\n    \n    ((self.train_x, self.train_y), (self.test_x, self.test_y)) = map(self._prepare, [train, test])\n\n    print(&quot;max seq_len&quot;, self.max_seq_len)\n    self.max_seq_len = min(self.max_seq_len, max_seq_len)\n    self.train_x, self.test_x = map(self._pad, [self.train_x, self.test_x])\n\n  def _prepare(self, df):\n    x, y = [], []\n    \n    for _, row in tqdm(df.iterrows()):\n      text, label = row[IntentDetectionData.DATA_COLUMN], row[IntentDetectionData.LABEL_COLUMN]\n      tokens = self.tokenizer.tokenize(text)\n      tokens = [&quot;[CLS]&quot;] + tokens + [&quot;[SEP]&quot;]\n      token_ids = self.tokenizer.convert_tokens_to_ids(tokens)\n      self.max_seq_len = max(self.max_seq_len, len(token_ids))\n      x.append(token_ids)\n      y.append(self.classes.index(label))\n\n    return np.array(x), np.array(y)\n\n  def _pad(self, ids):\n    x = []\n    for input_ids in ids:\n      input_ids = input_ids[:min(len(input_ids), self.max_seq_len - 2)]\n      input_ids = input_ids + [0] * (self.max_seq_len - len(input_ids))\n      x.append(np.array(input_ids))\n    return np.array(x)\n</code></pre>\n<p>The next function is</p>\n<pre><code>def create_model(max_seq_len, bert_ckpt_file):\n\n  with tf.io.gfile.GFile(bert_config_file, &quot;r&quot;) as reader:\n      bc = StockBertConfig.from_json_string(reader.read())\n      bert_params = map_stock_config_to_params(bc)\n      bert_params.adapter_size = None\n      bert = BertModelLayer.from_params(bert_params, name=&quot;bert&quot;)\n        \n  input_ids = keras.layers.Input(shape=(max_seq_len, ), dtype='int32', name=&quot;input_ids&quot;)\n  bert_output = bert(input_ids)\n\n  print(&quot;bert shape&quot;, bert_output.shape)\n\n  cls_out = keras.layers.Lambda(lambda seq: seq[:, 0, :])(bert_output)\n  cls_out = keras.layers.Dropout(0.5)(cls_out)\n  logits = keras.layers.Dense(units=768, activation=&quot;tanh&quot;)(cls_out)\n  logits = keras.layers.Dropout(0.5)(logits)\n  logits = keras.layers.Dense(units=len(classes), activation=&quot;softmax&quot;)(logits)\n\n  model = keras.Model(inputs=input_ids, outputs=logits)\n  model.build(input_shape=(None, max_seq_len))\n\n  load_stock_weights(bert, bert_ckpt_file)\n        \n  return model\n</code></pre>\n<p>The next code is:</p>\n<pre><code>classes = train.intent.unique().tolist()\n\ndata = IntentDetectionData(train, test, tokenizer, classes, max_seq_len=10000)\n</code></pre>\n<p>After running the above code I'm getting error like</p>\n<pre><code>ValueError: Unsupported string type: &lt;class 'float'&gt;\n</code></pre>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 250}]
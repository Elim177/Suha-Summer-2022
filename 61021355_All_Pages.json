[{"items": [{"tags": ["python", "tensorflow", "tensorflow2.0"], "owner": {"account_id": 8694719, "reputation": 111, "user_id": 6506534, "user_type": "registered", "profile_image": "https://lh6.googleusercontent.com/-1UqF7-tP82E/AAAAAAAAAAI/AAAAAAAAADI/13kkNumITXs/photo.jpg?sz=256", "display_name": "Yingzhou Li", "link": "https://stackoverflow.com/users/6506534/yingzhou-li"}, "is_answered": false, "view_count": 337, "answer_count": 2, "score": 1, "last_activity_date": 1587093390, "creation_date": 1585952895, "last_edit_date": 1586026588, "question_id": 61021355, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/61021355/missing-trainable-variables-in-tensorflow-2", "title": "Missing (trainable) variables in Tensorflow 2", "body": "<p>I encountered this issue in a larger code. And I reproduced it in the following test code. The trainable variables are not fully listed by tensorflow 2.1.</p>\n\n<pre><code>import os\nos.environ['TF_CPP_MIN_LOG_LEVEL']='2'\nimport tensorflow as tf\nimport numpy as np\n\nclass FooLayer(tf.keras.layers.Layer):\n    def __init__(self, siz):\n        super(FooLayer, self).__init__()\n        self.siz = siz\n        self.buildFoo(siz)\n\n    def call(self, in_data):\n        Foo0 = tf.multiply(in_data,self.FooTns0)\n        FooList = []\n        FooList.append(Foo0)\n        for it in range(1,self.siz+1):\n            tmp = tf.multiply(FooList[it-1],self.FooTns[it-1])\n            FooList.append(tmp)\n        return FooList[self.siz]\n\n    def buildFoo(self,siz):\n        self.FooTns0 = tf.Variable(1.0, name=\"TNS0\")\n        self.FooTns = []\n        for it in range(0,self.siz):\n            self.FooTns.append(tf.Variable(np.float32(it),\n                name=\"TNS\"+str(it+1)))\n            self.add_weight(\"TNS\"+str(it+1)) # Added after the first suggestion\n\nclass FooModel(tf.keras.Model):\n    def __init__(self, siz):\n        super(FooModel, self).__init__()\n        self.flayer = FooLayer(siz)\n\n    def call(self, in_data):\n        return self.flayer(in_data)\n\nmodel = FooModel(5)\n\nfor v in model.trainable_variables:\n    print(v.name)\n\nfor v in model.variables:\n    print(v.name)\n\nx = np.arange(1.0,2.0,1.0)\nx = x.astype(np.float32)\n\noptimizer = tf.keras.optimizers.Adam(learning_rate=0.1)\n\nwith tf.GradientTape() as tape:\n    y = model(x)\ngrads = tape.gradient(y, model.trainable_variables)\n\noptimizer.apply_gradients(zip(grads, model.trainable_variables))\n</code></pre>\n\n<p>The original output currently is only:</p>\n\n<pre><code>TNS0:0\nTNS0:0\n</code></pre>\n\n<p>While the expected output is listing all 6 tensors, ''self.FooTns0'' and ''self.FooTns''.</p>\n\n<p><strong>First suggestion</strong></p>\n\n<p>After the first suggestion by @Wathek LOUED, I added the line <code>self.add_weight(\"TNS\"+str(it+1))</code> and the output does include all other TNS. However, the gradient still does not find them and give error message as,</p>\n\n<pre><code>WARNING:tensorflow:Gradients do not exist for variables ['TNS1:0', 'TNS2:0', 'TNS3:0', 'TNS4:0', 'TNS5:0'] when minimizing the loss.\n</code></pre>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 129}]
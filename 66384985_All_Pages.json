[{"items": [{"tags": ["python", "python-3.x", "tensorflow", "generative-adversarial-network"], "owner": {"account_id": 13863149, "reputation": 156, "user_id": 10008270, "user_type": "registered", "profile_image": "https://www.gravatar.com/avatar/6263ccdfcf2d10b142abaefcb82b9c6c?s=256&d=identicon&r=PG&f=1", "display_name": "RR_28023", "link": "https://stackoverflow.com/users/10008270/rr-28023"}, "is_answered": true, "view_count": 277, "accepted_answer_id": 66408882, "answer_count": 1, "score": 0, "last_activity_date": 1641923854, "creation_date": 1614338803, "last_edit_date": 1641923854, "question_id": 66384985, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/66384985/valueerror-no-gradients-provided-for-any-variable-in-tensorflow-when-building-a", "title": "ValueError: No gradients provided for any variable in TensorFlow when building a GAN", "body": "<p>I'm trying to build a GAN for a university assignment. My code is very similar to the intro example in <a href=\"https://www.tensorflow.org/tutorials/generative/dcgan?hl=en\" rel=\"nofollow noreferrer\">this tutorial</a> from TF's website.</p>\n<p>Below are what I think the relevant parts of the code (can provide more details if needed eg. how the discriminator model is built). The line that gives me the error is:</p>\n<pre><code>generator_optimizer.apply_gradients(zip(gradients_of_generator, generador.trainable_variables))\n</code></pre>\n<p>It might be related with the layers of my generator since it is almost the only difference with TF's example code..</p>\n<pre><code>def create_generator(max_len, vocab_size):\n  model = tf.keras.Sequential()\n  model.add(tf.keras.layers.Embedding(vocab_size, output_dim=64, input_length=max_len))  \n  model.add(tf.keras.layers.LSTM(units=1024, activation='tanh'))\n  model.add(tf.keras.layers.Dense(units=1024, activation='sigmoid'))\n  model.add(tf.keras.layers.Dense(units=MAX_LEN, activation=None))\n\n  return model\n\ngenerator = create_generator(MAX_LEN, VOCABULARY_SIZE)\n\nfor epoch in range(EPOCHS):\n  noise = (tf.random.uniform([BATCH_SIZE, LATENT_DIM], minval=0, maxval = VOCABULARY_SIZE))\n\n  with tf.GradientTape() as disc_tape, tf.GradientTape() as gen_tape:\n\n    # Generator loss    \n    fake_revs = generator(noise)\n    pred_class_fake_revs = discriminator(fake_revs)\n    gen_loss, gen_acc = generator_loss_and_accuracy(pred_class_fake_revs)\n\n    # Disc loss\n    real_revs = reviews_tok_padded[np.random.randint(0, len(reviews_tok_padded),BATCH_SIZE)]\n    pred_class_real_revs = discriminator(real_revs) \n    disc_loss, disc_acc = discriminator_loss_and_accuracy(pred_class_real_revs, pred_class_fake_revs)\n\n    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)    \n    disc_grad = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n\n    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n    disc_optimizer.apply_gradients(zip(disc_grad, discriminator.trainable_variables))\n</code></pre>\n<p>The exact error I get is:</p>\n<pre><code>ValueError: No gradients provided for any variable: ['embedding_22/embeddings:0', 'lstm_22/lstm_cell_30/kernel:0', 'lstm_22/lstm_cell_30/recurrent_kernel:0', 'lstm_22/lstm_cell_30/bias:0', 'dense_44/kernel:0', 'dense_44/bias:0', 'dense_45/kernel:0', 'dense_45/bias:0'].\n</code></pre>\n<p>Edit: after some further investigation it is clear that the issue is that the tape does not compute the gradient, so the variable <code>gradients_of_generator</code> equals none for all <code>generator.trainable_variables</code>. However, I don't know why this happens.</p>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 249}]
[{"items": [{"tags": ["python", "tensorflow", "keras", "deep-learning"], "owner": {"account_id": 17424229, "reputation": 41, "user_id": 12629261, "user_type": "registered", "profile_image": "https://www.gravatar.com/avatar/4d7306156bcde0b7a5c05a8b5b5b7a9e?s=256&d=identicon&r=PG&f=1", "display_name": "Jiayuan Li", "link": "https://stackoverflow.com/users/12629261/jiayuan-li"}, "is_answered": false, "view_count": 2547, "answer_count": 1, "score": 2, "last_activity_date": 1578454123, "creation_date": 1577762919, "last_edit_date": 1578454123, "question_id": 59539241, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/59539241/failed-to-train-with-tf-keras-applications-mobilenetv2", "title": "Failed to train with tf.keras.applications.MobileNetV2", "body": "<p>Environment:\nTF2.0\nPython 3.5\nubuntu 16.04</p>\n\n<p>Problem:\nI try to use the pre-trained mobilenet_V2 but accuracy doesn't increase:</p>\n\n<pre class=\"lang-py prettyprint-override\"><code>base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n                                               include_top=False,\n                                               weights='imagenet')\n</code></pre>\n\n<p>The script is copied from the tutorial of the tensorflow 2.0(<a href=\"https://www.tensorflow.org/tutorials/images/transfer_learning?hl=zh-cn\" rel=\"nofollow noreferrer\">https://www.tensorflow.org/tutorials/images/transfer_learning?hl=zh-cn</a>)  </p>\n\n<p>The only change I made is the dataset which feed into the network. The original code makes binary classification between dogs and cats, and everything works. However, the accuracy never increases while  using multi-classes datasets like: \"mnist\", \"tf_flowers\". Please note that, I used the correct loss function and metrics.</p>\n\n<p>Naive model and results:\n<a href=\"https://i.stack.imgur.com/NK8d5.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/NK8d5.png\" alt=\"enter image description here\"></a></p>\n\n<p>Keras.mobilenetv2:\n<a href=\"https://i.stack.imgur.com/tCpa8.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/tCpa8.png\" alt=\"enter image description here\"></a></p>\n\n<p>Here is the code:</p>\n\n<pre><code>from __future__ import absolute_import, division, print_function, unicode_literals\nimport os\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Input, Dense, Flatten, Conv2D, GlobalAveragePooling2D\nfrom tensorflow.keras import Model\n\nkeras = tf.keras\nimport tensorflow_datasets as tfds\n# tfds.disable_progress_bar()\n\n\nIMG_SIZE = 224\nIMG_SHAPE = (IMG_SIZE, IMG_SIZE, 3)\n\ndef format_example(image, label):\n    if image.shape[-1] == 1:\n        image = tf.concat([image, image, image], 2)\n    image = tf.cast(image, tf.float32)\n    image = (image/127.5) - 1\n    image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))\n    return image, label\n\n##----functional model----##\nclass TinyModel():\n    def __init__(self, num_classes, hiddens=32, input_shape=IMG_SHAPE):\n        import tensorflow as tf\n        self.num_classes = num_classes\n        self.input_shape = input_shape\n        self.hiddens = hiddens\n    def build(self):\n        inputs = Input(shape=self.input_shape)\n        x = Conv2D(16, 3, activation=\"relu\", strides=2)(inputs)\n        x = Conv2D(32, 3, activation=\"relu\", strides=2)(x)\n        x = Conv2D(32, 3, activation=\"relu\", strides=2)(x)\n        x = Conv2D(16, 3, activation=\"relu\")(x)\n        x = Flatten()(x)\n        x = Dense(self.hiddens, activation=\"relu\")(x)\n        outputs = Dense(self.num_classes, activation=\"softmax\")(x)\n        model = Model(inputs=inputs, outputs=outputs, name='my_model')\n        return model\n\n\ndef assemble_model(num_classes, model_name='MobileNetV2'):\n    import tensorflow as tf \n    base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n                                                    weights='imagenet',\n                                                    include_top=False)\n    model = tf.keras.Sequential([\n                                base_model,\n                                GlobalAveragePooling2D(),\n                                Dense(num_classes, activation='softmax')\n                                ])\n    model.trainable = True\n    return model\n\n\n\n## ---- dataset preparation -----##\nSPLIT_WEIGHTS = (8, 1, 1)\nsplits = tfds.Split.TRAIN.subsplit(weighted=SPLIT_WEIGHTS)\n\n(raw_train, raw_validation, raw_test), metadata = tfds.load(\n    'tf_flowers', split=list(splits),\n    with_info=True, as_supervised=True)\nget_label_name = metadata.features['label'].int2str\n\n\n\n\n\n\ntrain = raw_train.map(format_example)\nvalidation = raw_validation.map(format_example)\ntest = raw_test.map(format_example)\n\nBATCH_SIZE = 32\nSHUFFLE_BUFFER_SIZE = 1000\n\ntrain_ds = train.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\nvalidation_ds = validation.batch(BATCH_SIZE)\ntest_ds = test.batch(BATCH_SIZE)\n\n\nIMG_SHAPE = (IMG_SIZE, IMG_SIZE, 3)\n\n\n\n## ----- model config ---- ##\n# Create an instance of the model\nmodel = TinyModel(num_classes=5).build()   # model 1\n# model = assemble_model(num_classes=5)    # model 2\nmodel.summary()\n\n\n## ----- training config -----##\n\nloss_object = tf.keras.losses.SparseCategoricalCrossentropy()\noptimizer = tf.keras.optimizers.Adam()\n\ntrain_loss = tf.keras.metrics.Mean(name='train_loss')\ntrain_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n\ntest_loss = tf.keras.metrics.Mean(name='test_loss')\ntest_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')\n\n\n## ----- training loop -----##\n@tf.function\ndef train_step(images, labels):\n  with tf.GradientTape() as tape:\n    predictions = model(images)\n    loss = loss_object(labels, predictions)\n  gradients = tape.gradient(loss, model.trainable_variables)\n  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n\n  train_loss(loss)\n  train_accuracy(labels, predictions)\n\n@tf.function\ndef test_step(images, labels):\n  predictions = model(images)\n  t_loss = loss_object(labels, predictions)\n\n  test_loss(t_loss)\n  test_accuracy(labels, predictions)\n\nEPOCHS = 5\n\nfor epoch in range(EPOCHS):\n  # Reset the metrics at the start of the next epoch\n  train_loss.reset_states()\n  train_accuracy.reset_states()\n  test_loss.reset_states()\n  test_accuracy.reset_states()\n\n  for images, labels in train_ds:\n    train_step(images, labels)\n\n  for test_images, test_labels in test_ds:\n    test_step(test_images, test_labels)\n\n  template = 'Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, Test Accuracy: {}'\n  print(template.format(epoch+1,\n                        train_loss.result(),\n                        train_accuracy.result()*100,\n                        test_loss.result(),\n                        test_accuracy.result()*100))\n</code></pre>\n\n<p>----------------------<strong>SOLVED</strong>-----------------------\nSolution\uff1aadd the argument \"training=True\" when training the keras.application.. For example</p>\n\n<pre class=\"lang-py prettyprint-override\"><code>model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,weights=\"imagenet\",include_top=False)\n\npred = model(inputs, training=True)\n</code></pre>\n\n<p>The reason might be caused by \"batchnorm\" layer. Those model which has BN layers works well in keras training loop, \"model.fit()\", and nothing to takecare. However, they cannot learn anything by costume training loop if you forget to set training=True in model()</p>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 149}]
[{"items": [{"tags": ["tensorflow"], "owner": {"account_id": 4910266, "reputation": 507, "user_id": 4397162, "user_type": "registered", "profile_image": "https://www.gravatar.com/avatar/44a2f7aea6a0ee61359f985e5171c58e?s=256&d=identicon&r=PG&f=1", "display_name": "johnsmith", "link": "https://stackoverflow.com/users/4397162/johnsmith"}, "is_answered": true, "view_count": 355, "accepted_answer_id": 50302552, "answer_count": 1, "score": 0, "last_activity_date": 1526095384, "creation_date": 1525952396, "last_edit_date": 1526089179, "question_id": 50272125, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/50272125/tensorflow-no-printing-output-looking-up-embedding", "title": "TensorFlow: no printing output looking up embedding", "body": "<p>I've been following the instructions at <a href=\"https://ireneli.eu/2017/01/17/tensorflow-07-word-embeddings-2-loading-pre-trained-vectors/\" rel=\"nofollow noreferrer\">https://ireneli.eu/2017/01/17/tensorflow-07-word-embeddings-2-loading-pre-trained-vectors/</a>.</p>\n\n<p>Why do I get no output (in the last cell, which contains sess.run()) running the following:</p>\n\n<pre><code>from __future__ import absolute_import, division, print_function\n\nimport os\nimport matplotlib.pyplot as plt\n\nimport tensorflow as tf\n</code></pre>\n\n<p>[new cell]</p>\n\n<pre><code>import numpy as np\nfilename = 'glove.6B.50d.txt'\ndef loadGloVe(filename):\n</code></pre>\n\n<p>[see above link for rest of definition]</p>\n\n<p>[see above link to initialise embedding]</p>\n\n<p>[new cell]</p>\n\n<pre><code>sent_toks = None\nwith open(\"documents.json\") as f:\n    training = js.load(f)\n    all_parags = [compute this value]\n\nsent_toks = nltk.sent_tokenize(all_parags)\n</code></pre>\n\n<p>[new cell - see above link]</p>\n\n<pre><code>import tensorflow.contrib.learn as le\n\n# init vocab processor\n[etc.]\nx = np.array(list(vocab_processor.transform(sent_toks)))\n</code></pre>\n\n<p>[new cell]</p>\n\n<pre><code>g = tf.Graph()\n\nwith g.as_default():\n    W = tf.Variable(tf.constant(0.0, shape=[vocab_size, embedding_dim]),\n            trainable=False, name=\"W\")\n    embedding_placeholder = tf.placeholder(tf.float32, [vocab_size, embedding_dim])\n    embedding_init = W.assign(embedding_placeholder)\n    foo = tf.nn.embedding_lookup(W, x[0])\n\n    init_op = tf.initialize_all_variables()\n    print_output = tf.Print(foo, [foo])\n\n    with tf.Session(graph = g) as sess:\n        sess.run(init_op)\n        sess.run(print_output)\n</code></pre>\n\n<p>By the way,</p>\n\n<pre><code>print(x[0])\n</code></pre>\n\n<p>gives</p>\n\n<pre><code>[    0  2827     5  6097    19     0     0    18    13  1427     1 59126\n  4135   111     1  7770 43737     2   622     0     2     6 19517 31152\n  1245 44144     5     6 20308    10  2891   509   707  6385     4     1\n  6307  3649     2    41   970 19123  2656     0     0     0     0     0\n     0     0]\n</code></pre>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 37}]
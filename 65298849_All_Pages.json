[{"items": [{"tags": ["python", "tensorflow", "keras", "conv-neural-network"], "owner": {"user_type": "does_not_exist", "display_name": "user13788928"}, "is_answered": false, "view_count": 426, "answer_count": 2, "score": 1, "last_activity_date": 1608025883, "creation_date": 1607996140, "last_edit_date": 1608022874, "question_id": 65298849, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/65298849/how-to-merge-multiple-inputs-four-into-neural-network-for-binary-image-classif", "title": "How to merge multiple inputs (four) into neural network for binary image classification?", "body": "<p>How would I structure a neural network for binary classification with four inputs (i.e., instead of feeding in one full image, I want to feed in four equally sized patches/tiles of the image that are labeled either class 1 or class 2).</p>\n<p>My current implementation follows a simple sequential model for binary classes and I would like to convert this to the scheme as mentioned above.</p>\n<pre><code>train_generator = train_datagen.flow_from_directory(\n        r'MY\\\\TRAINING\\\\PATH',\n        classes = ['Class1', 'Class2'],\n        target_size=(100, 100), \n        batch_size=16,\n        shuffle=False,\n        class_mode='binary')\n\nvalidation_generator = validation_datagen.flow_from_directory(\n        r'MY\\\\VALIDATION\\\\PATH',\n        classes = ['Class1', 'Class2'],\n        target_size=(100, 100), \n        batch_size=8,\n        # Use binary labels\n        shuffle=False,\n        class_mode='binary')\n\nmodel = tf.keras.models.Sequential([\n                                    tf.keras.layers.Conv2D(8, (3, 3), activation='relu', input_shape=(100, 100, 3)),\n                                    tf.keras.layers.MaxPooling2D((2, 2)),\n                                    tf.keras.layers.Conv2D(16, (3, 3), activation='relu'),\n                                    tf.keras.layers.MaxPooling2D((2, 2)),\n                                    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n                                    tf.keras.layers.Flatten(),\n                                    tf.keras.layers.Dense(1, activation='sigmoid')\n                                    ])\n\n</code></pre>\n<p>As an example, the file structure of my data would look like this:</p>\n<pre><code>\u251c\u2500\u2500 training\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 Class1_Quadrant1\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 IMG_1.jpg\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 IMG_2.jpg\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 IMG_3.jpg\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 etc.jpg\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 Class1_Quadrant2\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 IMG_1.jpg\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 IMG_2.jpg\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 IMG_3.jpg\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 etc.jpg\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 Class1_Quadrant3\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 IMG_1.jpg\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 IMG_2.jpg\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 IMG_3.jpg\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 etc.jpg\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 Class1_Quadrant4\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 IMG_1.jpg\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 IMG_2.jpg\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 IMG_3.jpg\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 etc.jpg\n</code></pre>\n<p>and have the same exact structure for my validation set.</p>\n<p>Ideally, something similar to this image if it helps:</p>\n<p><img src=\"https://i.stack.imgur.com/gLDuv.png\" alt=\"NN Example\" /></p>\n<p><strong>EDIT:</strong></p>\n<pre><code># Input Model 1\ninput1 = Input(shape=(100, 100, 3))\nconv11 = Conv2D(32, kernel_size = 4, activation = 'relu')(input1)\npool11 = MaxPooling2D(pool_size = (2, 2))(conv11)\nconv12 = Conv2D(16, kernel_size = 4, activation = 'relu')(pool11)\npool12 = MaxPooling2D(pool_size = (2, 2))(conv12)\nconv12 = Conv2D(8, kernel_size = 4, activation = 'relu')(pool11)\npool12 = MaxPooling2D(pool_size = (2, 2))(conv12)\nflat1 = Flatten()(pool12)\ndense1 = Dense(1)(flat1)\n\n# ... same structure repeated up to Input 4\n\n\n# Merge All Input Models\nmerge = concatenate([flat1, flat2, flat3, flat4])\n\n# Dense layers\nhidden1 = Dense(1, activation = 'relu')(merge)\nhidden2 = Dense(1, activation = 'relu')(hidden1)\nhidden3 = Dense(1, activation = 'relu')(hidden2)\nhidden4 = Dense(1, activation = 'relu')(hidden3)\noutput = Dense(1, activation = 'sigmoid')(hidden4)\nmodel = Model(inputs = [input1, input2, input3, input4], outputs = output)\n\n# Lastly my data comes from \n\ntrain_datagen = ImageDataGenerator(1 / 255.0)\nvalidation_datagen = ImageDataGenerator(1 / 255.0)\n\ntrain_generator1 = train_datagen.flow_from_directory(\n    r'training\\\\path\\\\Q1',  \n    classes = ['D1', 'D2'],\n    target_size = (100, 100),  \n    batch_size = 16,\n    shuffle = False,\n    class_mode = 'binary'\n    )\n\nvalidation_generator1 = validation_datagen.flow_from_directory(\n    r'validation\\\\path\\\\Q1',  \n    classes = ['D1', 'D2'],\n    target_size = (100, 100), \n    batch_size = 8,\n    shuffle = False,\n    class_mode = 'binary'\n    )\n\n# this continues on for the 4 training and 4 validation generators\n# until I get the error thrown here\n\nmodel.compile(\n    optimizer = tensorflow.optimizers.Adam(learning_rate = 1e-4),\n    loss = 'binary_crossentropy',\n    metrics = ['accuracy']\n    )\n\nhistory = model.fit(\n    [train_generator1, train_generator2, train_generator3, train_generator4],  \n    epochs = 100,\n    verbose = 1,\n    validation_data = [validation_generator1, validation_generator2, validation_generator3, validation_generator4],\n    )\n\n</code></pre>\n<p>Traceback:</p>\n<pre><code>history = model.fit(\n    [train_generator1, train_generator2, train_generator3, train_generator4],  \n    epochs = 100,\n    verbose = 1,\n    validation_data = [validation_generator1, validation_generator2, validation_generator3, validation_generator4],\n    )\nTraceback (most recent call last):\n\n  File &quot;&lt;ipython-input-23-332d3f7e4bba&gt;&quot;, line 5, in &lt;module&gt;\n    validation_data = [validation_generator1, validation_generator2, validation_generator3, validation_generator4],\n\n  File &quot;C:\\Users\\Eitan Flor\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py&quot;, line 108, in _method_wrapper\n    return method(self, *args, **kwargs)\n\n  File &quot;C:\\Users\\Eitan Flor\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py&quot;, line 1063, in fit\n    steps_per_execution=self._steps_per_execution)\n\n  File &quot;C:\\Users\\Eitan Flor\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py&quot;, line 1104, in __init__\n    adapter_cls = select_data_adapter(x, y)\n\n  File &quot;C:\\Users\\Eitan Flor\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py&quot;, line 971, in select_data_adapter\n    _type_name(x), _type_name(y)))\n\nValueError: Failed to find data adapter that can handle input: (&lt;class 'list'&gt; containing values of types {&quot;&lt;class 'tensorflow.python.keras.preprocessing.image.DirectoryIterator'&gt;&quot;}), &lt;class 'NoneType'&gt;\n</code></pre>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 251}]
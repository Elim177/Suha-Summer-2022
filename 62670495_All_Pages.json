[{"items": [{"tags": ["python", "tensorflow", "tf.keras"], "owner": {"account_id": 16936736, "reputation": 615, "user_id": 12323228, "user_type": "registered", "profile_image": "https://www.gravatar.com/avatar/6498d422e6c38d0808483be485b0fcc4?s=256&d=identicon&r=PG&f=1", "display_name": "cmed123", "link": "https://stackoverflow.com/users/12323228/cmed123"}, "is_answered": false, "view_count": 710, "answer_count": 0, "score": 3, "last_activity_date": 1593619240, "creation_date": 1593582763, "last_edit_date": 1593619240, "question_id": 62670495, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/62670495/using-xla-in-tensorflow-libdevice-10-bc-internaler", "title": "Using XLA in TensorFlow libdevice.10.bc InternalEr", "body": "<p>When I run this line of code:</p>\n<pre><code>tf.config.optimizer.set_jit(True)\n</code></pre>\n<p>To enable <code>XLA in TensorFlow 2.1</code>, I get the follow error:</p>\n<pre><code>InternalError:  libdevice not found at ./libdevice.10.bc\n     [[{{node cluster_1_1/xla_compile}}]]\n</code></pre>\n<p>I've looked at this post here: <a href=\"https://github.com/google/jax/issues/989\" rel=\"nofollow noreferrer\">https://github.com/google/jax/issues/989</a></p>\n<p>But I can't seem to figure out how to do this via <code>Anaconda</code> and using <code>os.environ['XLA_FLAGS']</code> instead of having to run the <code>symlink command</code> beforehand.</p>\n<p>For instance, I've tried:</p>\n<pre><code>os.environ['XLA_FLAGS'] = &quot;--xla_gpu_cuda_data_dir=/anaconda_path/envs/env/lib/libdevice.10.bc&quot;\n</code></pre>\n<p>But I still get the same error. Any tips would be greatly appreciated!</p>\n<p>I'm using <code>Ubuntu 18.04, TensorFlow 2.1, and Python 3.7.7</code>.</p>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 215}]
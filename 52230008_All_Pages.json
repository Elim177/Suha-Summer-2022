[{"items": [{"tags": ["python-2.7", "tensorflow", "deep-learning"], "owner": {"account_id": 4548208, "reputation": 3430, "user_id": 8089695, "user_type": "registered", "accept_rate": 100, "profile_image": "https://www.gravatar.com/avatar/92107cb1b109e2b8281e9cb76b5e3f16?s=256&d=identicon&r=PG&f=1", "display_name": "MiloMinderbinder", "link": "https://stackoverflow.com/users/8089695/milominderbinder"}, "is_answered": true, "view_count": 46, "accepted_answer_id": 52230361, "answer_count": 1, "score": 0, "last_activity_date": 1536359785, "creation_date": 1536356989, "question_id": 52230008, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/52230008/how-exactly-is-tensorflow-control-dependecy-applied", "title": "How exactly is tensorflow.control_dependecy applied?", "body": "<pre><code>        self.solver = 'adam'\n        if self.solver == 'adam':\n            optimizer = tf.train.AdamOptimizer(self.learning_rate_init)\n        if self.solver == 'sgd_nestrov':\n            optimizer = tf.train.MomentumOptimizer(learning_rate = self.learning_rate_init, momentum = self.momentum, \\\n                                                  use_nesterov = True)\n        gradients, variables = zip(*optimizer.compute_gradients(self.loss))\n        clipped_gradients, self.global_norm = tf.clip_by_global_norm(gradients, self.max_grad_norm)\n        update_ops_ = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n        optimizer_op = optimizer.apply_gradients(zip(clipped_gradients, variables))\n        control_ops = tf.group([self.ema_op] + update_ops_)\n        with tf.control_dependencies([optimizer_op]):\n            self.optimizer = control_ops\n</code></pre>\n\n<p>i call self.optimizer with the session</p>\n\n<p>The code above is not updating the gradients. However if i change the control dependencies part of the code to the one below it works perfectly fine except that it misses out on a final exponential moving average (self.ema_op) update, which is not desirable to me:</p>\n\n<pre><code>        self.solver = 'adam'\n        if self.solver == 'adam':\n            optimizer = tf.train.AdamOptimizer(self.learning_rate_init)\n        if self.solver == 'sgd_nestrov':\n            optimizer = tf.train.MomentumOptimizer(learning_rate = self.learning_rate_init, momentum = self.momentum, \\\n                                                  use_nesterov = True)\n        gradients, variables = zip(*optimizer.compute_gradients(self.loss))\n        clipped_gradients, self.global_norm = tf.clip_by_global_norm(gradients, self.max_grad_norm)\n        update_ops_ = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n        optimizer_op = optimizer.apply_gradients(zip(clipped_gradients, variables))\n        control_ops = tf.group([self.ema_op] + update_ops_)\n#         with tf.control_dependencies(optimizer_op):\n#             self.optimizer = control_ops\n        with tf.control_dependencies([self.ema_op] + update_ops_):\n            self.optimizer = optimizer.apply_gradients(zip(clipped_gradients, variables))\n</code></pre>\n\n<p>Please tell me what am i missing?</p>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 169}]
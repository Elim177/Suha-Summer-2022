[{"items": [{"tags": ["tensorflow", "machine-learning", "tf.keras", "tensorflow-probability", "probabilistic-programming"], "owner": {"account_id": 4907541, "reputation": 29, "user_id": 3953843, "user_type": "registered", "profile_image": "https://www.gravatar.com/avatar/?s=256&d=identicon&r=PG&f=1", "display_name": "sorooshi", "link": "https://stackoverflow.com/users/3953843/sorooshi"}, "is_answered": false, "view_count": 308, "answer_count": 0, "score": 1, "last_activity_date": 1595551846, "creation_date": 1595526743, "last_edit_date": 1595551846, "question_id": 63060296, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/63060296/implementing-variational-auto-encoder-using-tensoroflow-probability-not-on-mnist", "title": "Implementing Variational Auto Encoder using Tensoroflow_Probability NOT on MNIST data set", "body": "<p>I know there are many questions related to Variational Auto Encoders. However, this question in two aspects differs from the existing ones: 1) it is implemented using Tensforflow V2 and Tensorflow_probability; 2) It does not use MNIST or any other image data set.</p>\n<p><strong>As about the problem itself:</strong></p>\n<p>I am trying to implement VAE using Tensorflow_probability and Keras. and I want to train and evaluate it on some synthetic data sets --as part of my research. I provided the code below.</p>\n<p>Although the implementation is done and during the training, the loss value decreases but once I want to evaluate the trained model on my test set I face different errors.</p>\n<p>I am somehow confident that the issue is related to input/output shape but unfortunately I did not manage the solve it.</p>\n<p>Here is the code:</p>\n<pre><code>import numpy as np\nimport tensorflow as tf\nimport tensorflow.keras as tfk\nimport tensorflow_probability as tfp\nfrom tensorflow.keras import layers as tfkl\nfrom sklearn.datasets import make_classification\nfrom tensorflow_probability import layers as tfpl\nfrom sklearn.model_selection import train_test_split\n\n\ntfd = tfp.distributions\n\n\nn_epochs = 5\n    n_features = 2\n    latent_dim = 1\n    n_units = 4\n    learning_rate = 1e-3\n    n_samples = 400\n    batch_size = 32\n\n    # Generate synthetic data / load data sets\n    x_in, y_in = make_classification(n_samples=n_samples, n_features=n_features, n_informative=2, n_redundant=0,\n                                     n_repeated=0, n_classes=2, n_clusters_per_class=2, weights=[0.5, 0.5],\n                                     flip_y=0.01, class_sep=1.0, hypercube=True,\n                                     shift=0.0, scale=1.0, shuffle=False, random_state=42)\n\n    x_in = x_in.astype('float32')\n    y_in = y_in.astype('float32')  # .reshape(-1, 1)\n\n    x_train, x_test, y_train, y_test = train_test_split(x_in, y_in, test_size=0.4, random_state=42, shuffle=True)\n    x_test, x_val, y_test, y_val = train_test_split(x_test, y_test, test_size=0.5, random_state=42, shuffle=True)\n\n    print(&quot;shapes:&quot;, x_train.shape, y_train.shape, x_test.shape, y_test.shape, x_val.shape, y_val.shape)\n\n    prior = tfd.Independent(tfd.Normal(loc=[tf.zeros(latent_dim)], scale=1.), reinterpreted_batch_ndims=1)\n\n    train_dataset = tf.data.Dataset.from_tensor_slices(x_train).batch(batch_size)\n\n    valid_dataset = tf.data.Dataset.from_tensor_slices(x_val).batch(batch_size)\n\n    test_dataset = tf.data.Dataset.from_tensor_slices(x_test).batch(batch_size)\n\n    encoder = tf.keras.Sequential([\n        tfkl.InputLayer(input_shape=[n_features, ], name='enc_input'),\n        tfkl.Lambda(lambda x: tf.cast(x, tf.float32)),  # - 0.5\n        tfkl.Dense(n_units, activation='relu', name='enc_dense1'),\n        tfkl.Dense(int(n_units / 2), activation='relu', name='enc_dense2'),\n        tfkl.Dense(tfpl.MultivariateNormalTriL.params_size(latent_dim),\n                   activation=None, name='mvn_triL1'),\n        tfpl.MultivariateNormalTriL(\n            # weight &gt;&gt; num_train_samples or some thing except 1 to convert VAE to beta-VAE\n            latent_dim, activity_regularizer=tfpl.KLDivergenceRegularizer(prior, weight=1.), name='bottleneck'),\n    ])\n\n    decoder = tf.keras.Sequential([\n        tfkl.InputLayer(input_shape=latent_dim, name='dec_input'),\n        # tfkl.Dense(n_units, activation='relu', name='dec_dense1'),\n        # tfkl.Dense(int(n_units * 2), activation='relu', name='dec_dense2'),\n        tfpl.IndependentBernoulli([n_features], tfd.Bernoulli.logits, name='dec_output'),\n    ])\n\n    vae = tfk.Model(inputs=encoder.inputs, outputs=decoder(encoder.outputs), name='VAE')\n\n    print(&quot;enoder:&quot;, encoder)\n    print(&quot; &quot;)\n    print(&quot;encoder.inputs:&quot;, encoder.inputs)\n    print(&quot; &quot;)\n    print(&quot; encoder.outputs:&quot;,  encoder.outputs)\n    print(&quot; &quot;)\n    print(&quot;decoder:&quot;, decoder)\n    print(&quot; &quot;)\n    print(&quot;decoder:&quot;, decoder.inputs)\n    print(&quot; &quot;)\n    print(&quot;decoder.outputs:&quot;, decoder.outputs)\n    print(&quot; &quot;)\n\n    # negative log likelihood i.e the E_{S(eps)} [p(x|z)];\n    # because the KL term was added in the last layer of the encoder, i.e., via activity_regularizer.\n    # this loss function takes two arguments, namely the original data points x, and the output of the model,\n    # which we call it rv_x (because it is a random variable)\n    negloglik = lambda x, rv_x: -rv_x.log_prob(x)\n\n    vae.compile(optimizer=tf.optimizers.Adam(learning_rate=learning_rate),\n                loss=negloglik,)\n\n    vae.summary()\n\n    history = vae.fit(train_dataset, epochs=n_epochs, validation_data=valid_dataset,)\n\n    print(&quot;x.shape:&quot;, x_test.shape)\n    x_hat = vae(x_test)\n\n    print(&quot;original:&quot;)\n    print(x_test)\n    print(&quot; &quot;)\n    print(&quot;Decoded Random Samples:&quot;)\n    print(x_hat.sample())\n    print(&quot; &quot;)\n    print(&quot;Decoded Means:&quot;)\n    print(x_hat.mean())\n\n\n</code></pre>\n<p><strong>The Questions:</strong></p>\n<ol>\n<li>With the above code I receive the following error:</li>\n</ol>\n<p><strong>tensorflow.python.framework.errors_impl.InvalidArgumentError: Input to reshape is a tensor with 80 values, but the requested shape has 160 [Op:Reshape]</strong></p>\n<ol start=\"2\">\n<li><p>As far I know we can add as many layers as I want in the decoder model before its output layer --as it is done a convolutional VAEs, am I right?</p>\n</li>\n<li><p>If I uncomment the following two lines of code in decoder:</p>\n</li>\n</ol>\n<pre><code># tfkl.Dense(n_units, activation='relu', name='dec_dense1'),\n# tfkl.Dense(int(n_units * 2), activation='relu', name='dec_dense2'),\n\n</code></pre>\n<p>I see the following warnings and the upcoming error:</p>\n<p><strong>WARNING:tensorflow:Gradients do not exist for variables ['dec_dense1/kernel:0', 'dec_dense1/bias:0', 'dec_dense2/kernel:0', 'dec_dense2/bias:0'] when minimizing the loss.\nWARNING:tensorflow:Gradients do not exist for variables ['dec_dense1/kernel:0', 'dec_dense1/bias:0', 'dec_dense2/kernel:0', 'dec_dense2/bias:0'] when minimizing the loss.\nWARNING:tensorflow:Gradients do not exist for variables ['dec_dense1/kernel:0', 'dec_dense1/bias:0', 'dec_dense2/kernel:0', 'dec_dense2/bias:0'] when minimizing the loss.\nWARNING:tensorflow:Gradients do not exist for variables ['dec_dense1/kernel:0', 'dec_dense1/bias:0', 'dec_dense2/kernel:0', 'dec_dense2/bias:0'] when minimizing the loss.</strong></p>\n<p>And the error:</p>\n<p><strong>tensorflow.python.framework.errors_impl.InvalidArgumentError: Input to reshape is a tensor with 640 values, but the requested shape has 160 [Op:Reshape]</strong></p>\n<p>Now the question is why the decoder layers are not used during the training as it is mentioned in the warning.</p>\n<p>PS, I also tried to pass the x_train, x_valid, x_test directly during the training and evaluation process but it does not help.</p>\n<p>Any helps would be indeed appreciated.</p>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 74}]
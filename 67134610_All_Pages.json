[{"items": [{"tags": ["python", "tensorflow", "machine-learning", "image-processing", "generative-adversarial-network"], "owner": {"account_id": 20465057, "reputation": 21, "user_id": 15016764, "user_type": "registered", "profile_image": "https://i.stack.imgur.com/Up7SH.jpg?s=256&g=1", "display_name": "devanshu singh", "link": "https://stackoverflow.com/users/15016764/devanshu-singh"}, "is_answered": true, "view_count": 5031, "answer_count": 1, "score": 0, "last_activity_date": 1618645407, "creation_date": 1618633009, "question_id": 67134610, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/67134610/how-to-fix-typeerror-cannot-convert-the-value-to-a-tensorflow-dtype", "title": "How to fix &quot;TypeError: Cannot convert the value to a TensorFlow DType&quot;?", "body": "<p>I have tried to build a GAN (Generative Adversarial Network) for handwritten numbers dataset, I am facing a problem related to tensor Datatype error.</p>\n<ol>\n<li>Line 78, I is used &quot;tf.cast&quot; to convert all images into float32.</li>\n<li>For generator and discriminator loss, I used &quot;tf.losses.BinaryCrossentropy&quot;.</li>\n</ol>\n<p>I am not getting where the error is occurring.</p>\n<p>HERE IS THE FULL CODE</p>\n<pre><code>import tensorflow as tf\nimport matplotlib.pyplot as plt\nimport scipy.io as sio\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\n\n(train, label), (test, label_test) = tf.keras.datasets.mnist.load_data()\n\ntrain_images = train.reshape(train.shape[0], 28, 28, 1)\ntrain_images = (train_images-127.5)/127.5\n\nBUFFER_SIZE = train.shape[0]\nBATCH_SIZE = 100\ntrain_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n\ndef discriminator():\n    model = tf.keras.Sequential()\n    model.add(tf.keras.layers.Conv2D(7, (3,3), padding='same', input_shape=(28, 28, 1)))\n    model.add(tf.keras.layers.Flatten())\n    model.add(tf.keras.layers.LeakyReLU(0.1))\n    model.add(tf.keras.layers.Dense(128, activation='relu'))\n    model.add(tf.keras.layers.Dense(1))\n    return model\n\ndis_model = discriminator()\ndisc_opt = tf.optimizers.Adam()\n\ndef discriminator_loss(y_pred_real, y_pred_fake):\n    real = tf.sigmoid(y_pred_real)\n    fake = tf.sigmoid(y_pred_fake)\n    fake_loss = tf.losses.binary_crossentropy(tf.ones_like(y_pred_real), y_pred_real)\n    real_loss = tf.losses.binary_crossentropy(tf.zeros_like(y_pred_fake), y_pred_fake)\n    return fake_loss+real_loss\n\ndef generator():\n    model = tf.keras.Sequential()\n    model.add(tf.keras.layers.Dense(7*7*256, input_shape=(100,)))\n    model.add(tf.keras.layers.BatchNormalization())\n    model.add(tf.keras.layers.Reshape((7, 7, 256)))\n    model.add(tf.keras.layers.Conv2DTranspose(128, (3, 3), padding='same'))\n    model.add(tf.keras.layers.BatchNormalization())\n    model.add(tf.keras.layers.Conv2DTranspose(64, (3,3), strides=(2,2), padding='same'))\n    model.add(tf.keras.layers.BatchNormalization())\n    model.add(tf.keras.layers.Conv2DTranspose(1, (3,3), strides=(2,2), padding='same'))\n    return model\n\ngen_model = generator()\ngen_opt = tf.optimizers.Adam()\n\ndef generator_loss(fake_pred):\n    loss = tf.sigmoid(fake_pred)\n    fake_loss = tf.losses.BinaryCrossentropy(tf.zeros_like(fake_pred), fake_pred)\n    return fake_loss\n\ndef train_steps(images):\n    fake_noise = np.random.randn(BATCH_SIZE, 100).astype('float32')\n    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n        generated_images = gen_model(fake_noise)\n\n        fake_output = dis_model(generated_images)\n        real_output = dis_model(images)\n\n        gen_loss = generator_loss(fake_output)\n        disc_loss = discriminator_loss(real_output, fake_output)\n\n        gen_gradient = gen_tape.gradient(gen_loss, gen_model.trainable_variables)\n        disc_gradient = disc_tape.gradient(disc_loss, dis_model.trainable_variables)\n\n        gen_opt.apply_gradients(zip(gen_gradient, gen_model.trainable_variables))\n        disc_opt.apply_gradients(zip(disc_gradient, dis_model.trainable_variables))\n\n        print('disc_loss: ', np.mean(disc_loss))\n        print('gen_loss: ', np.mean(gen_loss))\n\ndef train(dataset, epoch):\n    for j in range(epoch):\n        for images in dataset:\n            images = tf.cast(images, tf.dtypes.float32)\n            train_steps(images)\n\n\ntrain(train_dataset, 2)\n\n</code></pre>\n<p>THE ERROR IS OCCURING</p>\n<pre><code>Traceback (most recent call last):\n  File &quot;D:/GANs_handwritten/model.py&quot;, line 81, in &lt;module&gt;\n    train(train_dataset, 2)\n  File &quot;D:/GANs_handwritten/model.py&quot;, line 78, in train\n    train_steps(images)\n  File &quot;D:/GANs_handwritten/model.py&quot;, line 66, in train_steps\n    gen_gradient = gen_tape.gradient(gen_loss, gene.trainable_variables)\n  File &quot;C:\\Users\\Devanshu\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py&quot;, line 1047, in gradient\n    if not backprop_util.IsTrainable(t):\n  File &quot;C:\\Users\\Devanshu\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\backprop_util.py&quot;, line 30, in IsTrainable\n    dtype = dtypes.as_dtype(dtype)\n  File &quot;C:\\Users\\Devanshu\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py&quot;, line 649, in as_dtype\n    raise TypeError(&quot;Cannot convert value %r to a TensorFlow DType.&quot; %\nTypeError: Cannot convert value &lt;tensorflow.python.keras.losses.BinaryCrossentropy object at 0x000001E5190BE850&gt; to a TensorFlow DType.\n</code></pre>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 164}]
[{"items": [{"tags": ["deep-learning", "computer-vision", "embedded", "tensorrt", "nvidia-jetson-nano"], "owner": {"user_type": "does_not_exist", "display_name": "user14142111"}, "is_answered": false, "view_count": 592, "answer_count": 1, "score": 0, "last_activity_date": 1619146955, "creation_date": 1601908748, "last_edit_date": 1601948326, "question_id": 64210813, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/64210813/how-to-convert-a-u-net-segmentation-model-to-tensorrt-on-nvidia-jetson-nano-p", "title": "How to convert a U-Net segmentation model to TensorRT on NVIDIA Jetson Nano ? (process killed error)", "body": "<p>I trained a U-Net segmentation model with Keras (using TF backend).\nI am trying to convert its frozen graph (.pb) to TensorRT format on the Jetson Nano but the process is killed (as seen below). I\u2019ve seen on other posts that it could be related to an \u00ab\u00a0out of memory\u00a0\u00bb problem.\nTo be known, I already have an SSD MobileNet V2 model running on the Jetson Nano.\u00a0</p>\n<p>If I stop the systemctl, I can make inference with the U-Net model without converting it to TensorRT (just using the frozen graph model loaded with Tensorflow). As this way doesn't work when I start the systemctl (so when the other neural network is running), I try to convert my U-Net segmentation model to TensorRT to get an optimized version of it (which failed because of a killed process), but it may not be the right way to do this.</p>\n<p>Is it possible to run two neural networks on a Jetson Nano ? Is there any other way to do this ?\u00a0</p>\n<p>For information, here is the way I try to convert the frozen graph to TensorRT :\u00a0</p>\n<pre><code>trt_graph = trt.create_inference_graph(\n    input_graph_def=frozen_graph_gd, # Pass the parsed graph def here\n    outputs=['conv2d_24/Sigmoid'],\n    max_batch_size=1,\n    max_workspace_size_bytes=1 &lt;&lt; 32, # I have tried 25 and 32 here\n    precision_mode='FP16'\n)\n</code></pre>\n<p>And here is when the process is killed (conversion of the U-Net frozen graph to TensorRT) :</p>\n<pre><code>2020-10-05 16:00:58.200269: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.2\n\nWARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.\n\n2020-10-05 16:01:11.976893: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libnvinfer.so.7\n\n2020-10-05 16:01:11.994472: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libnvinfer_plugin.so.7\n\nWARNING:tensorflow:\n\nThe TensorFlow contrib module will not be included in TensorFlow 2.0.\n\nFor more information, please see:\n\n* https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n\n* https://github.com/tensorflow/addons\n\n* https://github.com/tensorflow/io (for I/O related ops)\n\nIf you depend on functionality not listed there, please file an issue.\n\nWARNING:tensorflow:From convert_pb_to_tensorrt.py:14: The name tf.GraphDef is deprecated. Please use tf.compat.v1.GraphDef instead.\n\n2020-10-05 16:01:13.678101: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libnvinfer.so.7\n\n2020-10-05 16:01:15.506432: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n\n2020-10-05 16:01:15.512224: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:952] ARM64 does not support NUMA - returning NUMA node zero\n\n2020-10-05 16:01:15.512359: I tensorflow/core/grappler/devices.cc:55] Number of eligible GPUs (core count &gt;= 8, compute capability &gt;= 0.0): 0\n\n2020-10-05 16:01:15.512638: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session\n\n2020-10-05 16:01:15.532712: W tensorflow/core/platform/profile_utils/cpu_utils.cc:98] Failed to find bogomips in /proc/cpuinfo; cannot determine CPU frequency\n\n2020-10-05 16:01:15.533264: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x328fd900 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n\n2020-10-05 16:01:15.533318: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): Host, Default Version\n\n2020-10-05 16:01:15.632451: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:952] ARM64 does not support NUMA - returning NUMA node zero\n\n2020-10-05 16:01:15.632757: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x30d0edb0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n\n2020-10-05 16:01:15.632808: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): NVIDIA Tegra X1, Compute Capability 5.3\n\n2020-10-05 16:01:15.633163: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:952] ARM64 does not support NUMA - returning NUMA node zero\n\n2020-10-05 16:01:15.633276: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1634] Found device 0 with properties:\u00a0\n\nname: NVIDIA Tegra X1 major: 5 minor: 3 memoryClockRate(GHz): 0.9216\n\npciBusID: 0000:00:00.0\n\n2020-10-05 16:01:15.633348: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.2\n\n2020-10-05 16:01:15.633500: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n\n2020-10-05 16:01:15.716786: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n\n2020-10-05 16:01:15.903326: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n\n2020-10-05 16:01:16.060655: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n\n2020-10-05 16:01:16.141950: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n\n2020-10-05 16:01:16.142219: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8\n\n2020-10-05 16:01:16.142553: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:952] ARM64 does not support NUMA - returning NUMA node zero\n\n2020-10-05 16:01:16.142878: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:952] ARM64 does not support NUMA - returning NUMA node zero\n\n2020-10-05 16:01:16.142991: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1762] Adding visible gpu devices: 0\n\n2020-10-05 16:01:16.143133: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.2\n\n2020-10-05 16:01:27.700226: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1175] Device interconnect StreamExecutor with strength 1 edge matrix:\n\n2020-10-05 16:01:27.700377: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] 0\u00a0\n\n2020-10-05 16:01:27.700417: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1194] 0: N\u00a0\n\n2020-10-05 16:01:27.713559: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:952] ARM64 does not support NUMA - returning NUMA node zero\n\n2020-10-05 16:01:27.713897: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:952] ARM64 does not support NUMA - returning NUMA node zero\n\n2020-10-05 16:01:27.714101: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1320] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 200 MB memory) -&gt; physical GPU (device: 0, name: NVIDIA Tegra X1, pci bus id: 0000:00:00.0, compute capability: 5.3)\n\nKilled\n</code></pre>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 174}]
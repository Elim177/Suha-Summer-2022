[{"items": [{"tags": ["python", "tensorflow", "machine-learning", "roberta-language-model"], "owner": {"account_id": 19569119, "reputation": 339, "user_id": 14320652, "user_type": "registered", "profile_image": "https://lh3.googleusercontent.com/a-/AOh14Gh3o9pzDzccmcHyZ-f6LMrdqFov1tmu78cyVvht=k-s256", "display_name": "Sam V", "link": "https://stackoverflow.com/users/14320652/sam-v"}, "is_answered": false, "view_count": 638, "answer_count": 1, "score": 0, "last_activity_date": 1607790764, "creation_date": 1607777226, "question_id": 65265076, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/65265076/why-is-my-tensorflow-roberta-model-unable-to-train-finetune", "title": "Why is my tensorflow Roberta Model unable to train/finetune?", "body": "<p>We are trying to finetune / train our RoBERTa model on our own train data. The project is exactly the same as the SemEval-2020 task B on choosing the right reason out of 3 on why a sentence is against common sense. For the past two days we have been struggling with errors, mainly when trying to train/finetune our model. The code we have used comes from <a href=\"https://huggingface.co/transformers/model_doc/roberta.html#robertamodel\" rel=\"nofollow noreferrer\">https://huggingface.co/transformers/model_doc/roberta.html#robertamodel</a> . Although we have tried to alter this code in multiple ways we can't seem to really start training our model. Our main problem is the data we try to train the model on. We have tried to immediately insert a numpy array or pandas dataframe, but to no avail. Finally we tried to use a tfds. We used the following code, which results in the error code which can be found below.</p>\n<p>I install the following packages:</p>\n<pre><code># Modules\npip install transformers\nfrom transformers import RobertaConfig, RobertaModel\nfrom transformers import RobertaTokenizer, RobertaForMultipleChoice\nfrom transformers import AutoModel, AutoTokenizer\nimport tensorflow as tf\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\n</code></pre>\n<p>I import my train and test sets as csv files, where after the data is cleaned and concatenated.</p>\n<pre><code># Read csv files\nsample_data = pd.read_csv(&quot;sample.csv&quot;)\ntrain_data = pd.read_csv(&quot;train_data.csv&quot;)\ntrain_answers = pd.read_csv(&quot;train_answers.csv&quot;)\ntest_data = pd.read_csv(&quot;test_data.csv&quot;)\ntrain_data['A_concat'] = train_data['FalseSent'] + '. ' + train_data['OptionA']\ntrain_data['B_concat'] = train_data['FalseSent'] + '. ' + train_data['OptionB']\ntrain_data['C_concat'] = train_data['FalseSent'] + '. ' + train_data['OptionC']\ntrain_data.drop(['OptionA','OptionB','OptionC'],axis=1,inplace=True)\ntrain_data.columns = ['id', 'FalseSent', 'OptionA', 'OptionB', 'OptionC']\n</code></pre>\n<p>I make a tfds of the train and test data:</p>\n<pre><code>tf_train_data = tf.data.experimental.CsvDataset(&quot;train_data.csv&quot;, record_defaults='Tensor', header=True)\ntf_test_data = tf.data.experimental.CsvDataset(&quot;test_data.csv&quot;, record_defaults='Tensor', header=True)\n</code></pre>\n<p>These data sets are then used to train the model through the following code:</p>\n<pre><code>from transformers import TFRobertaForMultipleChoice, TFTrainer, TFTrainingArguments\n\nmodel = TFRobertaForMultipleChoice.from_pretrained(&quot;roberta-base&quot;)\n\ntraining_args = TFTrainingArguments(\n    output_dir='./results',          \n    num_train_epochs=3,              \n    per_device_train_batch_size=16,  \n    per_device_eval_batch_size=64,   \n    warmup_steps=500,                \n    weight_decay=0.01,               \n    logging_dir='./logs',            \n)\n\ntrainer = TFTrainer(\n    model=model,                        \n    args=training_args,                 \n    train_dataset=tf_train_data,    \n    eval_dataset=tf_test_data       \n)\n\ntrainer.train()\n</code></pre>\n<p>This results in the following error:</p>\n<p><strong>ValueError: The training dataset must have an asserted cardinality</strong></p>\n<p>If anybody has any advice or can point us in the right direction on how to train/finetune our model we would be very grateful!</p>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 53}]
[{"items": [{"tags": ["python", "class", "machine-learning", "deep-learning"], "owner": {"account_id": 9533520, "reputation": 3456, "user_id": 11573842, "user_type": "registered", "profile_image": "https://i.stack.imgur.com/BzrO9.jpg?s=256&g=1", "display_name": "Sabito \u9306\u514e stands with Ukraine", "link": "https://stackoverflow.com/users/11573842/sabito-%e9%8c%86%e5%85%8e-stands-with-ukraine"}, "is_answered": false, "view_count": 1241, "answer_count": 0, "score": 0, "last_activity_date": 1593433113, "creation_date": 1576138624, "last_edit_date": 1593433113, "question_id": 59300264, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/59300264/attributeerror-str-object-has-no-attribute-keras-mask", "title": "AttributeError: &#39;str&#39; object has no attribute &#39;_keras_mask&#39;", "body": "<p>The following code is for a deep convolution GAN:</p>\n<pre><code>class Dcgan:\ndef __init__(self,latent_space,gen_rate,disc_rate,images_source,resized_path,result_path,checkpoint_path,batch_size,optimizer,number_of_images_to_display,epoches):\n    self.latent_space = latent_space\n    self.gen_rate = gen_rate\n    self.disc_rate = disc_rate\n    self.images_source = images_source\n    self.training_path = os.listdir(self.images_source)\n    self.resized_path = resized_path\n    self.result_path = result_path\n    self.checkpoint_path = checkpoint_path\n    self.batch_size = batch_size\n    self.optimizer = optimizer\n    self.number_of_images_to_display = number_of_images_to_display\n    self.epoches = epoches\n    self.noise = tf.random.normal([self.batch_size,self.latent_space])\n    self.noise_gen_n_save = tf.random.normal([self.number_of_images_to_display,self.latent_space])\n\ndef resize_images(self):\n    if not os.path.exists(self.resized_path):\n        os.mkdir('images')\n\n    for i,image_path in enumerate(os.listdir(self.images_source)):\n        img = cv2.imread(os.path.join(self.images_source,image_path), cv2.IMREAD_UNCHANGED) \n        resized = cv2.resize(img, (28,28)) \n        path_new = path_save+'/'+image_path\n        status = cv2.imwrite(path_new,resized)\n\n    images=[]\n    image_paths = os.listdir('images')\n    for image_path in image_paths:\n        images.append(imread(os.path.join(path_save,image_path)))\n\n    images = np.array(images).astype('float32')\n    self.training_images = (images-127.5)/127.5\n\ndef Generator(self):\n\n    generator = tf.keras.Sequential()\n    generator.add(Dense(units=8*8*256,input_shape=(self.latent_space,),use_bias=False))\n    generator.add(BatchNormalization())\n    generator.add(LeakyReLU()) \n\n    \n    generator.add(Reshape((8,8,256)))\n    assert generator.output_shape == (None,8,8,256)\n\n    generator.add(Conv2DTranspose(filters = 64 ,kernel_size = (5,5),strides = (2,2),padding=&quot;same&quot;,use_bias=False)) # 8 to 16\n    assert generator.output_shape == (None,16,16,64)\n    generator.add(BatchNormalization())\n    generator.add(LeakyReLU())\n\n    generator.add(Conv2DTranspose(filters = 16,kernel_size = (5,5),strides = (2,2),padding=&quot;same&quot;,use_bias=False))  # 16 to 32      \n    assert generator.output_shape == (None,32,32,16)\n    generator.add(BatchNormalization())\n    generator.add(LeakyReLU())\n    \n    generator.add(Conv2DTranspose(filters = 3,kernel_size = (5,5),strides = (2,2),padding=&quot;same&quot;,activation='tanh',use_bias=False))  # 32 to 64\n    assert generator.output_shape == (None,64,64,3)        \n    return generator\n\ndef Discriminator(self):\n    discriminator = tf.keras.Sequential()\n    discriminator.add(Conv2D(filters = 64,kernel_size = (5,5) ,strides = (2,2),padding = &quot;same&quot;,activation='relu',input_shape=(64,64, 3)))\n    discriminator.add(Dropout(0.3))\n    \n    discriminator.add(Conv2D(filters = 128,kernel_size = (5,5) ,strides = (2,2),padding = &quot;same&quot;,activation='relu'))\n    discriminator.add(Dropout(0.3))\n    \n    discriminator.add(Conv2D(filters = 256,kernel_size = (5,5) ,strides = (2,2),padding = &quot;same&quot;,activation='relu'))\n    discriminator.add(Dropout(0.3))\n    \n    discriminator.add(Conv2D(filters = 512,kernel_size = (5,5) ,strides = (2,2),padding = &quot;same&quot;,activation='relu'))\n    discriminator.add(Dropout(0.3))\n    \n    discriminator.add(Flatten())\n    discriminator.add(Dense(1))\n    \n    return discriminator\n\ndef generator_loss(self):\n    self.gen_loss = BinaryCrossentropy(tf.ones_like(self.fake_output),self.fake_output)\n    return self.gen_loss\n\ndef discriminator_loss(self):\n    self.disc_loss_real = BinaryCrossentropy(tf.ones_like(self.real_output),self.real_output)        \n    self.disc_loss_fake = BinaryCrossentropy(tf.zeros_like(self.fake_output),self.fake_output)\n    self.total_disc_loss = self.disc_loss_real+self.disc_loss_fake\n    return self.total_disc_loss\n    \n@tf.function\ndef train_step(self):\n    generator,discriminator = self.Generator(),self.Discriminator()\n    with tf.GradientTape() as grad_gen, tf.GradientTape() as grad_disc:\n        self.generated_images = generator(self.noise,training=True)\n        self.real_output = discriminator(self.training_path,training=True)            \n        self.fake_output = discriminator(self.generated_images,training=True)            \n        self.discriminator_loss()\n        self.generator_loss()\n        self.gen_gradients = grad_gen.gradient(self.gen_loss,generator.trainable_variables)\n        self.disc_gradients = grad_disc.gradient(self.total_disc_loss,discriminator.trainable_variables)\n        \n    Adam(learning_rate=self.gen_rate).apply_gradients(zip(self.gen_gradients,generator.trainable_variables))\n    Adam(learning_rate=self.disc_rate).apply_gradients(zip(self.disc_gradients,discriminator.trainable_variables))\n    \n    return self.gen_loss,self.total_disc_loss\n\n\ndef display_and_save(self,epoch):\n    \n    output_images = self.generator(self.noise_gen_n_save,training = False)\n    \n    plt.figure(figsize=(13,13))\n\n    for i in range(self.number_of_images_to_display):\n        plt.subplot(8,8,i+1)\n        plt.imshow(output_images[i,:,:,0])\n        plt.axis('off')\n    \n    plt.savefig(fname='Traning images\\Generated images after epoch : {}'.format(epoch),)\n    \ndef training(self):\n    gen_losses,total_disc_losses = [],[]\n    for epoch in range(self.epoches):\n        start_time = time.time()\n        self.train_step()\n        gen_loss.append(self.gen_loss.numpy(),self.total_disc_loss.numpy())\n        display.clear_output(wait=True)\n        display_and_save(epoch)\n    return gen_losses,total_disc_losses\n        \n</code></pre>\n<p>When I run :</p>\n<pre><code>dcgan = Dcgan(\n\n    latent_space = 100,\n    gen_rate = 0.0002,\n    disc_rate = 0.0003,\n    images_source = 'D:/PlantVillage-Dataset/raw/color/Orange___Haunglongbing_(Citrus_greening)',\n    resized_path = 'resized_images',\n    result_path = 'generated_images',\n    checkpoint_path = 'training_checkpoints',\n    batch_size = 256,\n    optimizer = Adam,\n    number_of_images_to_display = 16,\n    epoches = 100,\n\n)\ndcgan.training()\n</code></pre>\n<p>I get the following warning followed by an Attribute error:</p>\n<pre><code>WARNING:tensorflow:Entity &lt;bound method Dcgan.Generator of &lt;__main__.Dcgan object at 0x0000024B49994E88&gt;&gt; could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of &lt;bound method Dcgan.Generator of &lt;__main__.Dcgan object at 0x0000024B49994E88&gt;&gt;, which Python reported as:\n    def Generator(self): ## followed by the entire code of Generator\n......\nAttributeError                            Traceback (most recent call last)\n&lt;ipython-input-122-9387d007efdb&gt; in &lt;module&gt;\n----&gt; 1 dcgan.training()\n\n&lt;ipython-input-118-f9eb662d913f&gt; in training(self)\n    134         for epoch in range(self.epoches):\n    135             start_time = time.time()\n--&gt; 136             self.train_step()\nAttributeError: 'str' object has no attribute '_keras_mask'\n</code></pre>\n<p>I am still fairly new to python. I am quit confident that the error is due to some mistake I made instead of a bug in Python itself (as the warning suggests). I just can't figure out what it is...</p>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 36}]
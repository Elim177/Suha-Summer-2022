[{"items": [{"tags": ["python", "macos", "tensorflow", "keras", "spyder"], "owner": {"account_id": 7773738, "reputation": 29, "user_id": 15450208, "user_type": "registered", "profile_image": "https://www.gravatar.com/avatar/68102ef812f46c290af79b7ba72aa108?s=256&d=identicon&r=PG&f=1", "display_name": "Wasonic", "link": "https://stackoverflow.com/users/15450208/wasonic"}, "is_answered": false, "view_count": 363, "answer_count": 0, "score": 0, "last_activity_date": 1632296713, "creation_date": 1632222320, "last_edit_date": 1632296713, "question_id": 69267805, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/69267805/tensorflow-stuck-on-first-epoch-macos", "title": "Tensorflow stuck on first epoch | macOS", "body": "<p>So as the title says, if I the following Python code on Spyder my machine freezes on the first epoch. What happens is: RAM usage goes to ~94%, after a while Spyder spits out a problem window but I get no error message in the console. The code just freezes.</p>\n<p>I am doing this with more than 6M observations so I tried it with 10 and it worked. Then I tried with 100,000 and it works but very very slowly which I think is weird.</p>\n<p>Can someone test this in their machine? It might be some package issue. Or it might be the code, I'm not too confident on the constrained_mse function.</p>\n<p>The code:</p>\n<pre><code>from os import path\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow import keras\nimport tensorflow as tf\ntf.compat.v1.enable_eager_execution()\nfrom tensorflow.keras import layers, losses\nimport numpy as np\n\n\n# Hyperparameters\nn_hidden_layers = 2 # Number of hidden layers.\nn_units = 128 # Number of neurons of the hidden layers.\nn_batch = 64 # Number of observations used per gradient update.\nn_epochs = 30\n\n\n# Create DataFrame (df) with random floats\ncall_df = pd.DataFrame(np.random.rand(6000000, 6) * 100, \n                       columns=['Strike', &quot;Time to Maturity&quot;, \n                                &quot;Option_Average_Price&quot;, &quot;RF Rate&quot;, \n                                &quot;Sigma 20 Days Annualized&quot;, \n                                &quot;Underlying Price&quot;])\n# call_df = call_df.iloc[-10:,:]\n\n# Split call_df into random train and test subsets, for inputs (X) and output (y)\ncall_X_train, call_X_test, call_y_train, call_y_test = (train_test_split(\n    call_df.drop([&quot;Option_Average_Price&quot;], axis = 1), \n    call_df.Option_Average_Price, test_size = 0.01))\n\n\n# Create model using Keras' Functional API\ndef mlp3_call(n_hidden_layers, n_units):\n    # Create input layer\n    inputs = keras.Input(shape = (call_X_train.shape[1],))\n    x = layers.LeakyReLU(alpha = 1)(inputs)\n\n    # Create hidden layers\n    for _ in range(n_hidden_layers):\n        x = hl(x, n_units)\n\n    # Create output layer\n    outputs = layers.Dense(1, activation = keras.activations.softplus)(x)\n\n    # Actually create the model\n    model = keras.Model(inputs=inputs, outputs=outputs)\n    \n    return model\n\n\n# Hidden layer generation function\ndef hl(tensor, n_units):\n    hl_output = layers.Dense(n_units, \n                             activation = layers.LeakyReLU(alpha=1))(tensor)\n    return hl_output\n\n\n# Custom loss function that is a MSE function plus three soft constraints\ndef constrained_mse(y_true, y_pred):\n    \n    mse = losses.mse(y_true, y_pred)\n    \n    x = tf.convert_to_tensor(call_X_train, np.float32)\n    \n    with tf.GradientTape() as tape:\n        tape.watch(x)\n        with tf.GradientTape(persistent=True) as tape2:\n            tape2.watch(x)\n            y = model(x)\n        \n    grad_y = tape2.gradient(y, x)\n    dy_dstrike = grad_y[0, 0]\n    dy_dttm = grad_y[0, 1]\n    \n    grad_y2 = tape.gradient(y, x)\n    d2y_dstrike2 = grad_y2[0, 0]\n    \n    loss = mse + dy_dstrike + dy_dttm + d2y_dstrike2\n\n    return loss\n\n\nmodel = mlp3_call(n_hidden_layers, n_units) \nmodel.compile(loss = constrained_mse, optimizer = keras.optimizers.Adam(),)\nhistory = model.fit(call_X_train, call_y_train, batch_size = n_batch, \n                    epochs = n_epochs, validation_split = 0.01, verbose = 1)\n\n# Save the model's architecture, weights and optimizer's state\ndirectory = path.join(&quot;Saved_models&quot;, &quot;mlp3_call_1&quot;)\nmodel.save(directory)\n\n# Save the model's train and validation losses for each epoch.\ntrain_loss = history.history[&quot;loss&quot;]\nvalidation_loss = history.history[&quot;val_loss&quot;]\nnumpy_train_loss = np.array(train_loss)\nnumpy_validation_loss = np.array(validation_loss)\nnp.savetxt(&quot;Saved_models/mlp3_call_1_train_losses.txt&quot;, \n            numpy_train_loss, delimiter=&quot;,&quot;)\nnp.savetxt(&quot;Saved_models/mlp3_call_1_validation_losses.txt&quot;, \n            numpy_validation_loss, delimiter=&quot;,&quot;)\n\n\n</code></pre>\n<p>EDIT: My machine is a Mac with 16GB of RAM and a 3210M 2.5GHz CPU. <a href=\"https://everymac.com/systems/apple/macbook_pro/specs/macbook-pro-core-i5-2.5-13-mid-2012-unibody-usb3-specs.html\" rel=\"nofollow noreferrer\">This</a> one, except mine has an SSD and 16GB of RAM</p>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 38}]
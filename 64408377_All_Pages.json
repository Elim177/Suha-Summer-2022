[{"items": [{"tags": ["python", "tensorflow", "machine-learning", "keras", "tensorflow2.0"], "owner": {"account_id": 5376490, "reputation": 123, "user_id": 4283195, "user_type": "registered", "profile_image": "https://www.gravatar.com/avatar/38550cc575c33d41b4b1efdd44f617a9?s=256&d=identicon&r=PG&f=1", "display_name": "Gregg Harrington", "link": "https://stackoverflow.com/users/4283195/gregg-harrington"}, "is_answered": false, "view_count": 24, "answer_count": 0, "score": 0, "last_activity_date": 1602978103, "creation_date": 1602978103, "question_id": 64408377, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/64408377/gradientmap-usage-to-train-model-all-output-converge-on-my-first-x-value", "title": "GradientMap usage to train model, all output converge on my first X value", "body": "<p>Growing past using model.fit() to train my model, I wanted to use a GradientMap to implement the training of a basic model that tried to produce the square of a value.</p>\n<pre><code>x_data = [1., 2., 3.]\ny_data = [1., 4., 9.]\n</code></pre>\n<p>The full code below is what is used to train the model. The model updates as the training loop occurs, but all of the output values are the same. Initial untrained model produces something like:</p>\n<pre><code>[[[0.51774]]]\n[[[0.53543544]]]\n[[[0.5530421]]]\n</code></pre>\n<p>Essentially random values (expected)... as the training loop goes, the predictions all seem to be updating based on the first X value of 1.0, and not training on 2.0 and 3.0.</p>\n<p>2500 loops in here is the output of the prediction:</p>\n<pre><code>2500\n[[[0.9999831]]]\n[[[0.99999976]]]\n[[[1.]]]\n</code></pre>\n<p>I was expecting it to predict 1, 4, and 9... or at least converge towards those numbers.</p>\n<p>Complete Code:</p>\n<pre><code>import tensorflow as tf\nfrom keras import models, layers, losses, metrics\n\n\ndef create_model():\n  model = models.Sequential()\n\n  input_layer = layers.Dense(1, input_shape=(None, 1), activation='relu')\n  model.add(input_layer)\n  model.add(layers.Dense(16, activation='relu'))\n  model.add(layers.Dense(1, activation='sigmoid'))  # todo: understand activation better\n\n  model.compile(loss=losses.BinaryCrossentropy(), metrics=[metrics.Accuracy()], optimizer='adam')\n\n  return model, input_layer\n\n\nx_data = [1., 2., 3.]\ny_data = [1., 4., 9.]\n\nmodel, input_layer = create_model()\n\ndef run_predictions():\n  output = model.predict(x_data)\n  print(output)\n\nrun_predictions()\n\nfor i in range(10000):\n  if i % 100 == 0:\n    print(i)\n    run_predictions()\n\n  for x in x_data:\n    x = tf.Variable(x, name='input')\n\n    with tf.GradientTape() as tape:\n      tape.watch(x)\n      y = model(tf.Variable([[x]]))\n      loss = x**2 - y\n\n    dy_dx = tape.gradient(loss, model.trainable_variables)\n    model.optimizer.apply_gradients(zip(dy_dx, model.trainable_weights))\n</code></pre>\n<p>Thanks for your help in advance!!</p>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 166}]
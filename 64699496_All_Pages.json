[{"items": [{"tags": ["python", "tensorflow", "keras"], "owner": {"account_id": 3608629, "reputation": 900, "user_id": 3010217, "user_type": "registered", "accept_rate": 82, "profile_image": "https://www.gravatar.com/avatar/57b3587ddb7127841ccd832730cacf1c?s=256&d=identicon&r=PG&f=1", "display_name": "Begoodpy", "link": "https://stackoverflow.com/users/3010217/begoodpy"}, "is_answered": true, "view_count": 61, "accepted_answer_id": 64700310, "answer_count": 1, "score": 0, "last_activity_date": 1604644347, "creation_date": 1604587423, "last_edit_date": 1604593815, "question_id": 64699496, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/64699496/how-to-compute-loss-of-chained-models-with-keras", "title": "How to compute loss of chained models with Keras?", "body": "<p>For testing, I have split a model into two models and I want to compute the loss and apply the gradient to both models like it would be one.</p>\n<p>Here are my two simple models:</p>\n<pre><code>model1 = tf.keras.models.Sequential([\n    tf.keras.layers.Dense(10, activation=&quot;relu&quot;, input_shape=(10,)),\n])\n\nmodel2 = tf.keras.models.Sequential([\n    tf.keras.layers.Dense(10, activation=&quot;softmax&quot;, input_shape=(10,)),\n])\n</code></pre>\n<p>And I run a forward pass through the two models, calculate the loss of the second model and apply the gradients:</p>\n<pre><code>optimizer = tf.keras.optimizers.SGD()\nloss = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n\nx = tf.random.normal((1, 10)) # Input of the 1st model\ny = tf.random.normal((1, 10)) # Expected output of the 2nd model\n\nwith tf.GradientTape() as tape:\n    pred1 = model1(x, training=True)\n    pred2 = model2(pred1, training=True)\n    loss_value2 = loss(y, pred2) # Compute the loss for the second model prediction\n\ngrads = tape.gradient(loss_value2, model2.trainable_variables)\noptimizer.apply_gradients(zip(grads, model2.trainable_variables))\n</code></pre>\n<p>But how do I get the expected output of the first model wrt the second model to compute the loss and apply gradients on it?</p>\n<p>EDIT:</p>\n<p>The end goal of the testing is to have two models 1, that send their output to a single third model. And having each model 1 trained on two GPUs:</p>\n<pre><code>with tf.device('/gpu:0'):\n    pred1_1 = model1_1(x, training=True)\n\nwith tf.device('/gpu:1'):\n    pred1_2 = model1_2(x, training=True)\n\npred1 = tf.keras.layers.concatenate([pred1_1, pred1_2])\n\nwith tf.device('/gpu:0'):\n    pred2 = model2(pred1, training=True)\n</code></pre>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 42}]
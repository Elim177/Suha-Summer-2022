[{"items": [{"tags": ["python", "tensorflow", "machine-learning", "deep-learning", "lstm"], "owner": {"account_id": 1720655, "reputation": 820, "user_id": 1757224, "user_type": "registered", "accept_rate": 85, "profile_image": "https://i.stack.imgur.com/yUXOQ.jpg?s=256&g=1", "display_name": "ARAT", "link": "https://stackoverflow.com/users/1757224/arat"}, "is_answered": true, "view_count": 464, "accepted_answer_id": 53257244, "answer_count": 1, "score": 0, "last_activity_date": 1542006034, "creation_date": 1541995906, "last_edit_date": 1541996368, "question_id": 53255873, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/53255873/tf-metrics-accuracy-and-hand-written-accuracy-function-give-different-results", "title": "tf.metrics.accuracy and hand-written accuracy function give different results", "body": "<p>I am trying to see how <code>tf.metrics.accuracy</code> works. I want to compare batch accuracy results of the function given below</p>\n\n<pre><code>with tf.name_scope('Accuracy1'):\n        correct_prediction = tf.equal(tf.argmax(predictions, 1), tf.argmax(y, 1))\n        accuracy1 = tf.reduce_mean(tf.cast(correct_prediction, tf.float32), name=\"accuracy\")\n</code></pre>\n\n<p>with </p>\n\n<pre><code>with tf.name_scope('Accuracy2'):\n        accuracy2, accuracy_op = tf.metrics.accuracy(labels=tf.argmax(y, 1), predictions=tf.argmax(predictions, 1))\n</code></pre>\n\n<p>Minimal working example is provided below:</p>\n\n<pre><code>import numpy as np \nimport pandas as pd \nimport tensorflow as tf\nimport math\n\nfrom tensorflow.examples.tutorials.mnist import input_data\nmnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n\nnum_steps=28\nnum_inputs = 28\nnum_classes = 10\nnum_neurons = 128\nnum_layers = 3\nbatch_size = 500\n\ngraph = tf.Graph()\nwith graph.as_default():\n    with tf.name_scope(\"graph_inputs\"):\n        X = tf.placeholder(tf.float32, [None, num_steps, num_inputs], name='input_placeholder')\n        y = tf.placeholder(tf.float32, [None, num_classes], name='labels_placeholder')\n       output_keep_prob = tf.placeholder_with_default(1.0, shape=(), name =\"output_dropout\")\n\ndef build_lstm_cell(num_neurons, output_keep_prob):\n    \"\"\"Returns a dropout-wrapped LSTM-cell.\n    See https://stackoverflow.com/a/44882273/2628369 for why this local function is necessary.\n    Returns:\n    tf.contrib.rnn.DropoutWrapper: The dropout-wrapped LSTM cell.\n    \"\"\"\n    initializer = tf.contrib.layers.xavier_initializer()\n    lstm_cell = tf.contrib.rnn.LSTMCell(num_units=num_neurons, initializer=initializer, forget_bias=1.0, state_is_tuple=True, name='LSTM_cell')\n    lstm_cell_drop = tf.contrib.rnn.DropoutWrapper(lstm_cell, output_keep_prob=output_keep_prob)\n    return lstm_cell_drop\n\nwith tf.name_scope(\"LSTM\"):\n    with tf.name_scope(\"Cell\"):\n        multi_layer_cell = tf.contrib.rnn.MultiRNNCell([build_lstm_cell(num_neurons, output_keep_prob) for _ in range(num_layers)], state_is_tuple=True)\n    with tf.name_scope(\"Model\"):\n        outputs, states = tf.nn.dynamic_rnn(cell=multi_layer_cell, inputs=X, swap_memory=False, time_major = False, dtype=tf.float32)#[Batch_size, time_steps, num_neurons]\n    with tf.name_scope(\"Graph_Outputs\"):\n        outputs = tf.transpose(outputs, [1, 0, 2]) # [num_timesteps, batch_size, num_neurons]\n        outputs = tf.gather(outputs, int(outputs.get_shape()[0]) - 1) # [batch_size, num_neurons]\n    with tf.variable_scope('Softmax'):\n        logits =  tf.layers.dense(inputs = outputs, units = num_classes, name=\"logits\") #[Batch_size, num_classes]\n    with tf.name_scope('Predictions'):\n        predictions = tf.nn.softmax(logits, name=\"predictions\")  #[Batch_size, num_classes]\n    with tf.name_scope('Accuracy1'):\n        correct_prediction = tf.equal(tf.argmax(predictions, 1), tf.argmax(y, 1))\n        accuracy1 = tf.reduce_mean(tf.cast(correct_prediction, tf.float32), name=\"accuracy\")\n    with tf.name_scope('Accuracy2'):\n        accuracy2, accuracy_op = tf.metrics.accuracy(labels=tf.argmax(y, 1), predictions=tf.argmax(predictions, 1))\n    with tf.name_scope('Loss'):\n        xentropy = tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=y)\n        loss = tf.reduce_mean(xentropy, name=\"loss\")\n    with tf.name_scope('Train'):\n        optimizer= tf.train.AdamOptimizer(learning_rate=0.0001)\n        trainer=optimizer.minimize(loss, name=\"training_op\")\n\nwith tf.Session(graph = graph) as sess:\n    tf.global_variables_initializer().run()\n    total_batch = mnist.train.num_examples // batch_size\n    for batch in range(total_batch):\n        tf.local_variables_initializer().run()\n        xBatch, yBatch = mnist.train.next_batch(batch_size)\n        xBatch = xBatch.reshape((batch_size, num_steps, num_inputs))\n        sess.run(trainer, feed_dict={X: xBatch, y: yBatch, output_keep_prob: 0.5})\n        miniBatchAccuracy1 = sess.run(accuracy1, feed_dict={X: xBatch, y: yBatch, output_keep_prob: 0.5})\n        print('[hand-written] Batch {} accuracy: {}'.format(batch, miniBatchAccuracy1))\n        accuracy_op_val = sess.run(accuracy_op, feed_dict={X: xBatch, y: yBatch, output_keep_prob: 0.5})\n        miniBatchAccuracy2 = sess.run(accuracy2)\n        print(\"[tf.metrics.accuracy] Batch {} accuracy: {}\".format(batch, miniBatchAccuracy2))\n    sess.close()\n</code></pre>\n\n<p>I print the accuracy values of each batches using these two approaches and they are different. Should not the results be the same? </p>\n\n<pre><code>[hand-written] Batch 0 accuracy: 0.09600000083446503\n[tf.metrics.accuracy] Batch 0 accuracy: 0.09399999678134918\n\n[hand-written] Batch 1 accuracy: 0.1120000034570694\n[tf.metrics.accuracy] Batch 1 accuracy: 0.07800000160932541\n\n[hand-written] Batch 2 accuracy: 0.10199999809265137\n[tf.metrics.accuracy] Batch 2 accuracy: 0.09600000083446503\n\n[hand-written] Batch 3 accuracy: 0.12999999523162842\n[tf.metrics.accuracy] Batch 3 accuracy: 0.12800000607967377\n\n[hand-written] Batch 4 accuracy: 0.1379999965429306\n[tf.metrics.accuracy] Batch 4 accuracy: 0.10199999809265137\n\n[hand-written] Batch 5 accuracy: 0.16200000047683716\n[tf.metrics.accuracy] Batch 5 accuracy: 0.1340000033378601\n\n[hand-written] Batch 6 accuracy: 0.1340000033378601\n[tf.metrics.accuracy] Batch 6 accuracy: 0.12600000202655792\n\n[hand-written] Batch 7 accuracy: 0.12999999523162842\n[tf.metrics.accuracy] Batch 7 accuracy: 0.16200000047683716\n...\n...\n...\n...\n</code></pre>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 123}]
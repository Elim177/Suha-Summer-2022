[{"items": [{"tags": ["python-3.x", "tensorflow2.0", "gradient-descent"], "owner": {"account_id": 21280745, "reputation": 3, "user_id": 15659204, "user_type": "registered", "profile_image": "https://www.gravatar.com/avatar/2a873d1c644686e6f3c5a1762144a260?s=256&d=identicon&r=PG&f=1", "display_name": "Valkar83", "link": "https://stackoverflow.com/users/15659204/valkar83"}, "is_answered": false, "view_count": 78, "answer_count": 1, "score": 0, "last_activity_date": 1646913076, "creation_date": 1618566730, "last_edit_date": 1618568175, "question_id": 67123024, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/67123024/took-gradients-through-a-stateful-object", "title": "Took gradients through a stateful object", "body": "<p>I have begun to learn TensorFlow with the official guide : <a href=\"https://www.tensorflow.org/guide\" rel=\"nofollow noreferrer\">https://www.tensorflow.org/guide</a>.</p>\n<p>My comprehension is struggling with a part of the guide named &quot;Automatic differentiation&quot; and especially &quot;Took gradients through a stateful object&quot;.</p>\n<p>I don't understand why they said that stateful object stops gradient. The guide gives this piece of code</p>\n<pre><code>x0 = tf.Variable(3.0)\nx1 = tf.Variable(0.0)\n\nwith tf.GradientTape() as tape:\n  # Update x1 = x1 + x0.\n  x1.assign_add(x0)\n  # The tape starts recording from x1.\n  y = x1**2   # y = (x1 + x0)**2\n\n# This doesn't work.\nprint(tape.gradient(y, x0))   #dy/dx0 = 2*(x1 + x0)\n\n</code></pre>\n<p>Why the gradient doesn't record <code>x0</code>?! Is it this function <code>.assign_add(x0)</code> that increments <code>x1</code> overshadow <code>x0</code>? Is it because <code>assign_add</code> will pick the value of <code>x0</code> and steal its allocated memory? Is it the right reason or there is another reason that I don't see?</p>\n<p>Thank you in advance for your answers.</p>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 232}]
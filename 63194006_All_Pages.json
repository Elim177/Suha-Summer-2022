[{"items": [{"tags": ["python", "html", "tensorflow", "keras"], "owner": {"user_type": "does_not_exist", "display_name": "user13494573"}, "is_answered": true, "view_count": 277, "accepted_answer_id": 63194243, "answer_count": 2, "score": 0, "last_activity_date": 1596207332, "creation_date": 1596206533, "last_edit_date": 1596206922, "question_id": 63194006, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/63194006/why-cant-i-run-my-tensorflow-cnn-model-on-this-single-image", "title": "Why can&#39;t I run my tensorflow CNN model on this single image?", "body": "<p>I created a TensorFlow CNN from scratch to identify certain types of animals. I believe the model is working because I am getting data about the training data and I see a new folder in my directory when I run the code. When I try to run the code to predict it for a new single image, which is right below, I get this error. I'm new to TensorFlow, so I'm not sure what I'm doing wrong. The image is in the main directory and is a .jpg image. Let me know if you need more information. Thanks</p>\n<pre><code>CATEGORIES = [&quot;cane&quot;, &quot;cavallo&quot;, &quot;elefante&quot;, &quot;farfalla&quot;, &quot;gallina&quot;,\n      &quot;gatto&quot;, &quot;mucca&quot;, &quot;pecora&quot;, &quot;ragno&quot;, &quot;scoiattolo&quot;]\ndef prepare(file):\nIMG_SIZE = 50\nimg_array = cv2.imread(file, cv2.IMREAD_GRAYSCALE)\nnew_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\nreturn new_array.reshape(-1, IMG_SIZE, IMG_SIZE, 1)\nmodel = tf.keras.models.load_model(&quot;CNN.model&quot;)\nfrom PIL import Image\nimport numpy as np\nfrom skimage import transform\nimage = load('test.jpg')\nmodel.predict(image)\nprediction = model.predict([image])\nprediction = list(prediction[0])\nprint(CATEGORIES[prediction.index(max(prediction))])\n</code></pre>\n<p>This is the error</p>\n<pre><code>ValueError                                Traceback (most recent call \nlast)\n&lt;ipython-input-4-5c3fc0a5d50b&gt; in &lt;module&gt;\n     14 from skimage import transform\n     15 image = load('test.jpg')\n---&gt; 16 model.predict(image)\n     17 prediction = model.predict([image])\n     18 prediction = list(prediction[0])\n\n~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py in _method_wrapper(self, *args, **kwargs)\n     86       raise ValueError('{} is not supported in multi-worker mode.'.format(\n     87           method.__name__))\n---&gt; 88     return method(self, *args, **kwargs)\n     89 \n     90   return tf_decorator.make_decorator(\n\n~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py in predict(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\n   1266           for step in data_handler.steps():\n   1267             callbacks.on_predict_batch_begin(step)\n-&gt; 1268             tmp_batch_outputs = predict_function(iterator)\n   1269             # Catch OutOfRangeError for Datasets of unknown size.\n   1270             # This blocks until the batch has finished executing.\n\n~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py in __call__(self, *args, **kwds)\n    578         xla_context.Exit()\n    579     else:\n--&gt; 580       result = self._call(*args, **kwds)\n    581 \n    582     if tracing_count == self._get_tracing_count():\n\n~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py in _call(self, *args, **kwds)\n    625       # This is the first call of __call__, so we have to initialize.\n    626       initializers = []\n--&gt; 627       self._initialize(args, kwds, add_initializers_to=initializers)\n    628     finally:\n    629       # At this point we know that the initialization is complete (or less\n\n~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py in _initialize(self, args, kwds, add_initializers_to)\n    504     self._concrete_stateful_fn = (\n    505         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n--&gt; 506             *args, **kwds))\n    507 \n    508     def invalid_creator_scope(*unused_args, **unused_kwds):\n\n~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py in _get_concrete_function_internal_garbage_collected(self, *args, **kwargs)\n   2444       args, kwargs = None, None\n   2445     with self._lock:\n-&gt; 2446       graph_function, _, _ = self._maybe_define_function(args, kwargs)\n   2447     return graph_function\n   2448 \n\n~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py in _maybe_define_function(self, args, kwargs)\n   2775 \n   2776       self._function_cache.missed.add(call_context_key)\n-&gt; 2777       graph_function = self._create_graph_function(args, kwargs)\n   2778       self._function_cache.primary[cache_key] = graph_function\n   2779       return graph_function, args, kwargs\n\n~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py in _create_graph_function(self, args, kwargs, override_flat_arg_shapes)\n   2665             arg_names=arg_names,\n   2666             override_flat_arg_shapes=override_flat_arg_shapes,\n-&gt; 2667             capture_by_value=self._capture_by_value),\n   2668         self._function_attributes,\n   2669         # Tell the ConcreteFunction to clean up its graph once it goes out of\n\n~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\n    979         _, original_func = tf_decorator.unwrap(python_func)\n    980 \n--&gt; 981       func_outputs = python_func(*func_args, **func_kwargs)\n    982 \n    983       # invariant: `func_outputs` contains only Tensors, CompositeTensors,\n\n~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py in wrapped_fn(*args, **kwds)\n    439         # __wrapped__ allows AutoGraph to swap in a converted function. We give\n    440         # the function a weak reference to itself to avoid a reference cycle.\n--&gt; 441         return weak_wrapped_fn().__wrapped__(*args, **kwds)\n    442     weak_wrapped_fn = weakref.ref(wrapped_fn)\n    443 \n\n~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py in wrapper(*args, **kwargs)\n    966           except Exception as e:  # pylint:disable=broad-except\n    967             if hasattr(e, &quot;ag_error_metadata&quot;):\n--&gt; 968               raise e.ag_error_metadata.to_exception(e)\n    969             else:\n    970               raise\n\nValueError: in user code:\n\n    /Users/rin/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1147 predict_function  *\n        outputs = self.distribute_strategy.run(\n    /Users/ron/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:951 run  **\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /Users/rn/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2290 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /Users/romin/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2649 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /Users/rin/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1122 predict_step  **\n        return self(x, training=False)\n    /Users/rn/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:886 __call__\n        self.name)\n    /Users/rkin/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/input_spec.py:216 assert_input_compatibility\n        ' but received input with shape ' + str(shape))\n\n    ValueError: Input 0 of layer sequential_10 is incompatible with the layer: expected axis -1 of input shape to have value 1 but received input with shape [None, 256, 256, 3]\n</code></pre>\n<p>This is code for the rest of the model:</p>\n<pre><code>file_list = []\nclass_list = []\n\nDATADIR = &quot;data&quot;\n\n# All the categories you want your elefante network to detect\nCATEGORIES = [&quot;cane&quot;, &quot;cavallo&quot;, &quot;elefante&quot;, &quot;farfalla&quot;, &quot;gallina&quot;,\n          &quot;gatto&quot;, &quot;mucca&quot;, &quot;pecora&quot;, &quot;ragno&quot;, &quot;scoiattolo&quot;]\n\n# The size of the images that your neural network will use\nIMG_SIZE = 50\n\n# Checking or all images in the data folder\nfor category in CATEGORIES :\n    path = os.path.join(DATADIR, category)\n    for img in os.listdir(path):\n        img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n\ntraining_data = []\n\ndef create_training_data():\n    for category in CATEGORIES :\n        path = os.path.join(DATADIR, category)\n        class_num = CATEGORIES.index(category)\n        for img in os.listdir(path):\n            try :\n                img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n                new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n                training_data.append([new_array, class_num])\n            except Exception as e:\n                pass\n\ncreate_training_data()\n\nrandom.shuffle(training_data)\n\nX = [] #features\ny = [] #labels\n\nfor features, label in training_data:\n    X.append(features)\n    y.append(label)\n\nX = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n\n# Creating the files containing all the information about your model\npickle_out = open(&quot;X.pickle&quot;, &quot;wb&quot;)\npickle.dump(X, pickle_out)\npickle_out.close()\n\npickle_out = open(&quot;y.pickle&quot;, &quot;wb&quot;)\npickle.dump(y, pickle_out)\npickle_out.close()\n\npickle_in = open(&quot;X.pickle&quot;, &quot;rb&quot;)\nX = pickle.load(pickle_in)\ny = np.array(y)\n\nimport tensorflow as tf \nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\nimport pickle\nfrom keras.models import model_from_json\nfrom keras.models import load_model\nimport matplotlib.pyplot as plt\n\n# Opening the files about data\nX = pickle.load(open(&quot;X.pickle&quot;, &quot;rb&quot;))\ny = pickle.load(open(&quot;y.pickle&quot;, &quot;rb&quot;))\n\n# normalizing data (a pixel goes from 0 to 255)\nX = X/255.0\n\nmodel = Sequential()\n# 3 convolutional layers\nmodel.add(Conv2D(32, (3, 3), input_shape = X.shape[1:]))\nmodel.add(Activation(&quot;relu&quot;))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Conv2D(64, (3, 3)))\nmodel.add(Activation(&quot;relu&quot;))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\n\nmodel.add(Conv2D(64, (3, 3)))\nmodel.add(Activation(&quot;relu&quot;))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\nmodel.add(Flatten())\nmodel.add(Dense(128))\nmodel.add(Activation(&quot;relu&quot;))\n\nmodel.add(Dense(128))\nmodel.add(Activation(&quot;relu&quot;))\nmodel.add(Dense(10))\nmodel.add(Activation(&quot;softmax&quot;))\n\n# Compiling the model using some basic parameters\nmodel.compile(loss=&quot;sparse_categorical_crossentropy&quot;,\n                optimizer=&quot;adam&quot;,\n                metrics=[&quot;accuracy&quot;])\nX = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n\ny = np.array(y)\n\nhistory = model.fit(X, y, batch_size=32, epochs=4, validation_split=0.1)\nmodel_json = model.to_json()\nwith open(&quot;model.json&quot;, &quot;w&quot;) as json_file :\n    json_file.write(model_json)\n\nmodel.save_weights(&quot;model.h5&quot;)\nprint(&quot;Saved model to disk&quot;)\n\nmodel.save('CNN.model')\n\n# Printing a graph showing the accuracy changes during the training phase\nprint(history.history.keys())\nplt.figure(1)\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\n</code></pre>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 276}]
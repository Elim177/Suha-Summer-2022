[{"items": [{"tags": ["keras"], "owner": {"account_id": 12699750, "reputation": 109, "user_id": 9226944, "user_type": "registered", "profile_image": "https://www.gravatar.com/avatar/325127a0db4df5c81dce8f9025e6876b?s=256&d=identicon&r=PG&f=1", "display_name": "mricdev", "link": "https://stackoverflow.com/users/9226944/mricdev"}, "is_answered": false, "view_count": 44, "answer_count": 0, "score": 1, "last_activity_date": 1618742427, "creation_date": 1618742427, "question_id": 67147622, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/67147622/keras-how-to-retrieve-layers-outputs-in-a-custom-training-loop-more-precisel", "title": "Keras, how to retrieve layers outputs in a custom training loop ? (more precisely in the *train_step* function)", "body": "<p>In the Keras <a href=\"https://keras.io/guides/customizing_what_happens_in_fit/\" rel=\"nofollow noreferrer\">documentation</a> we see that it's possible to customize what happens during training after every batch, for instance if we want to compute our own loss, we can override the <em>train_step</em> function:</p>\n<pre><code>class CustomModel(keras.Model):\n    def train_step(self, data):\n        x, y = data\n\n        with tf.GradientTape() as tape:\n            y_pred = self(x, training=True)  # Forward pass\n            # Compute our own loss\n            loss = keras.losses.mean_squared_error(y, y_pred)\n</code></pre>\n<p>But, what if I want to use some outputs of some layers in order to compute a custom loss after every batch ?</p>\n<p>Is there a way to have access to some layers outputs in the <em>train_step</em> function ?</p>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 163}]
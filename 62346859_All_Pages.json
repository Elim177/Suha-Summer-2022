[{"items": [{"tags": ["machine-learning", "keras", "pickle", "tensorflow2.0", "conv-neural-network"], "owner": {"account_id": 18785407, "reputation": 21, "user_id": 13699118, "user_type": "registered", "profile_image": "https://lh4.googleusercontent.com/-azJ2pRd0Qfg/AAAAAAAAAAI/AAAAAAAAAAA/AMZuucnu1Cf_gf1tIE4flYY7xJbHpvAWEQ/photo.jpg?sz=256", "display_name": "Melvin ", "link": "https://stackoverflow.com/users/13699118/melvin"}, "is_answered": false, "view_count": 77, "answer_count": 0, "score": 1, "last_activity_date": 1591973745, "creation_date": 1591973745, "question_id": 62346859, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/62346859/pickle-tf-gradient-tape-throws-error-typeerror-cant-pickle-tfe-tape-objects", "title": "Pickle tf.Gradient.Tape() throws Error: TypeError: can&#39;t pickle tfe.Tape objects", "body": "<p>I try to perform split-learning, which means the model is devided and trained on a client up to a specific layer. The output, labels and trainablevariables and GradientTape of the clientside model are sent to a server to complete the training on the second half of the model. On the server, a serverside gradient is calculated to update the server and a clientside gradient is calculated. The clientside gradient should be sent back to the client to update the clientside model.</p>\n\n<p>The problem is that i cannot pickle a tf.GradintTape(), which is necessary to transmit to the server in order to compute the clientside gradients. I get the following error:</p>\n\n<pre><code>TypeError: can't pickle tfe.Tape objects\n</code></pre>\n\n<p>You can see the server and client code below</p>\n\n<p>client:</p>\n\n<pre><code>import os\nimport struct\nimport socket\nfrom threading import Thread\nimport pickle \nimport time\nimport tensorflow as tf\nimport numpy as np\nfrom tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPool2D, MaxPooling2D, Dropout\n\n\n\nhost = '192.168.178.190'\nport = 10080\nmax_recv = 4096\n\n\ndef send_msg(sock, getid, content):\n    msg = [getid, content]  # add getid\n    msg = pickle.dumps(msg)\n    msg = struct.pack('&gt;I', len(msg)) + msg  # add 4-byte length in network byte order\n    sock.sendall(msg)\n\n\ndef recieve_msg(sock):\n    msg = recv_msg(sock)  \n    msg = pickle.loads(msg)\n    getid = msg[0]\n    content = msg[1]\n    #handle_request(sock, getid, content)\n    return content\n\ndef recv_msg(sock):\n    # read message length and unpack it into an integer\n    raw_msglen = recvall(sock, 4)\n    if not raw_msglen:\n        return None\n    msglen = struct.unpack('&gt;I', raw_msglen)[0]\n    # read the message data\n    return recvall(sock, msglen)\n\n\ndef recvall(sock, n):\n\n    data = b''\n    while len(data) &lt; n:\n        packet = sock.recv(n - len(data))\n        if not packet:\n            return None\n        data += packet\n    return data\n\n\n\nfashion_mnist = tf.keras.datasets.fashion_mnist\n(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n\n#pixel der bilder von 0-255 auf 0-1 herunterscalen\nx_train = x_train.astype('float32') / 255.0\nx_test = x_test.astype('float32') / 255.0\n\n\n#client klasse\nclass Client(tf.keras.Model):\n\n    def __init__(self, x_train, y_train):\n        super(Client, self).__init__()\n\n\n        self.num_samples = x_train.shape[0] \n        self.train_inputs = tf.expand_dims(x_train, 3) \n        self.train_labels = y_train #Traingslabel f\u00fcr erzeugten clienten\n        # Hyperparameters\n        self.batch_size = 50\n        self.epochs = 2\n\n        self.model = tf.keras.Sequential([Conv2D(32, (3,3), (1,1), activation='relu', kernel_initializer='he_normal'),\n                                         MaxPooling2D((2,2)),\n                                         Dropout(0.25),\n                                         Conv2D(64, (3,3), (1,1), activation='relu')])\n\n        # Optimizer\n        self.optimizer = tf.keras.optimizers.SGD(learning_rate=1e-2)\n\n    #get the output of clientside model with given inputs\n    def call(self, inputs):\n        output = self.model(inputs)\n        return output\n\n    def send(self, i):\n        start, end = i * self.batch_size, (i + 1) * self.batch_size \n        output_client = self.call(self.train_inputs[start:end]) \n\n        labels = self.train_labels[start:end] \n        return output_client, labels\n\n\n\n\n    def start_train(self, sock,  batchround):\n        for i in range(self.epochs):\n            print(\"Starte Trainingsepoche: \", i + 1)\n            for batchround in range(\n                    self.num_samples // self.batch_size):  \n                with tf.GradientTape(persistent=True) as tape:\n                    output_client, labels = self.send(batchround)  \n\n                    inputclient = tf.expand_dims(x_test, 3)\n\n                    test_output_client, test_labels = self.call(inputclient), y_test\n                    client_trainable_variables = self.model.trainable_variables\n                    msg = {\n                        'client_out': output_client,\n                        'label': labels,\n                        'client_output_test': test_output_client,\n                        'client_label_test': test_labels,\n                        'gradient_tape': tape,\n                        'trainable_variables': client_trainable_variables,\n                        }\n                    print(tape)\n                    send_msg(sock, 0, msg)\n                    backmsg = recieve_msg(sock)\n                    l = backmsg[\"loss\"]\n                    gradient_client = tape.gradient(l, client_trainable_variables)\n                    self.optimizer.apply_gradients(zip(gradient_client, self.model.trainable_variables))\n                    print(backmsg['test_status'], \"samples:\", batchround*self.batch_size, \"von\", self.num_samples)\n\n\n\ndef main():\n    global client\n    client = Client(x_train, y_train)\n    s = socket.socket()\n    s.connect((host, port))\n\n    client.start_train(s, 0)\n\n\n\nif __name__ == '__main__':\n    main()\n</code></pre>\n\n<p>server:</p>\n\n<pre><code>import os\nimport struct\nimport socket\nfrom threading import Thread\nimport pickle\nimport time\nimport tensorflow as tf\nimport numpy as np\nfrom tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPool2D, MaxPooling2D, Dropout\n\nhost = '0.0.0.0'#'localhost'\nport = 10080\nmax_recv = 4096\nmax_numclients = 5\nconnectedclients = []\ntrds = []\n\ndef send_msg(sock, content):\n    msg = pickle.dumps(content)\n    msg = struct.pack('&gt;I', len(msg)) + msg #add 4-byte length in netwwork byte order\n    sock.sendall(msg)\n\ndef recieve_msg(sock):\n    msg = recv_msg(sock)  \n    msg = pickle.loads(msg)\n    getid = msg[0]\n    content = msg[1]\n    handle_request(sock, getid, content)\n\n\ndef recv_msg(sock):\n\n    raw_msglen = recvall(sock, 4)\n    if not raw_msglen:\n        return None\n    msglen = struct.unpack('&gt;I', raw_msglen)[0]   \n    return recvall(sock, msglen)\n\ndef recvall(sock, n):\n\n    data = b''\n    while len(data) &lt; n:\n        packet = sock.recv(n - len(data))\n        if not packet:\n            return None\n        data += packet\n    return data\n\ndef handle_request(sock, getid, content):\n        switcher = {\n            0: server.calc_gradients,\n            1: sendtoallcliets,\n        }\n        switcher.get(getid, \"invalid request recieved\")(sock, content)\n\ndef clientHandler(conn, addr):\n     while True:\n            try:\n                recieve_msg(conn)\n            except:\n                pass\n\n\ndef sendtoallcliets(conn, content):\n    ret=\"nachricht an alle clienten\"\n\n    for client in connectedclients:\n        try:\n            send_msg(client, ret)\n        except:\n            pass\n\n\n\nclass Server(tf.keras.Model):\n\n    def __init__(self):\n        super(Server, self).__init__()\n\n\n        self.model = tf.keras.Sequential([Conv2D(128, (3,3), (1,1), activation='relu'),\n                                          Dropout(0.4),\n                                          Flatten(),\n                                          Dense(128, activation='relu'),\n                                          Dropout(0.4),\n                                          Dense(10, activation='softmax')])\n\n\n        self.loss_function = tf.keras.losses.SparseCategoricalCrossentropy()\n        self.optimizer = tf.keras.optimizers.SGD(1e-2)\n\n\n    def call(self, input):\n        output = self.model(input)\n        return output\n\n\n    def loss(self, output_server, labels):\n        return self.loss_function(labels, output_server)\n\n    def calc_gradients(self, sock, msg):\n        tape_gradient = msg[\"gradient_tape\"]\n        with tf.GradientTape(persistent=True) as tape:\n            output_client, labels, trainable_variables_client = msg[\"client_out\"], msg[\"label\"], msg[\n                \"trainable_variables\"]\n            output_client_test, labels_test = msg['client_output_test'], msg['client_label_test']\n            output_server = self.call(output_client)\n\n\n            l = self.loss(output_server, labels)  \n        gradient_server = tape.gradient(l,self.model.trainable_variables)  \n        self.optimizer.apply_gradients(zip(gradient_server,self.model.trainable_variables))  \n        gradient_client = tape_gradient.gradient(l, trainable_variables_client)\n        predictions = np.argmax(self.call(output_client_test), axis=1)\n        acc = np.mean(predictions == labels_test)\n        test_status = \"test_loss: {:.4f}, test_acc: {:.2f}%\".format(l, acc * 100)\n        print(test_status)\n\n        backmsg = {\n            'test_status': test_status,\n            'gradient_client': gradient_client,\n        }\n        send_msg(sock, backmsg)\n\n\n\ndef main():\n    global server\n    server=Server()\n\n    s = socket.socket()\n    s.bind((host, port))\n    s.listen(max_numclients)\n\n    for i in range(max_numclients):\n        c, addr = s.accept()\n        connectedclients.append(c)\n        #print(connectedclients)\n        print('Conntected with', addr)\n        t = Thread(target=clientHandler, args=(c, addr))\n        trds.append(t)\n        t.start()\n    for t in trds:\n        t.join()\n\n\nif __name__ == '__main__':\n    main()\n</code></pre>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 1}]
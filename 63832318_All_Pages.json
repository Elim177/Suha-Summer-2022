[{"items": [{"tags": ["python", "tensorflow", "keras"], "owner": {"account_id": 8680334, "reputation": 117, "user_id": 6496448, "user_type": "registered", "profile_image": "https://www.gravatar.com/avatar/91ebd5b36dd63a6c41e6979d8d3b5928?s=256&d=identicon&r=PG&f=1", "display_name": "A.Maine", "link": "https://stackoverflow.com/users/6496448/a-maine"}, "is_answered": false, "view_count": 530, "answer_count": 2, "score": 1, "last_activity_date": 1617896280, "creation_date": 1599749548, "last_edit_date": 1617869013, "question_id": 63832318, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/63832318/keras-using-a-generator-for-the-data-vae", "title": "Keras, using a generator for the data (VAE)", "body": "<p>I'm currently trying to implement a variational autoencoder but I'm quite stuck, I cannot understand how to use a datagenerator in Keras. What I have so far is:</p>\n<pre class=\"lang-py prettyprint-override\"><code>\nimport keras\nimport tensorflow as tf\nfrom tensorflow.keras import layers\n\n\nclass Sampling(layers.Layer):\n    \n    def call(self, inputs):\n        z_mean, z_log_var = inputs\n        batch = tf.shape(z_mean)[0]\n        dim = tf.shape(z_mean)[1]\n        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n        return z_mean + tf.exp(z_log_var / 2) * epsilon\n\nclass factor_vae(keras.Model):\n    def __init__(self):\n        super(factor_vae, self).__init__()\n        self.encoder = self.encoder_factor_vae()\n        self.decoder = self.decoder_factor_vae()\n        self.classifier = self.MLP_classifier()\n\n    def train_step(self, data):\n        data = data[0]\n        with tf.GradientTape() as tape:\n            z, z_mean, z_log_var = self.encoder(data)\n            reconstruction = self.decoder(z)\n            reconstruction_loss = tf.reduce_mean(\n                keras.losses.mse(data, reconstruction))\n            reconstruction_loss *= 4096 #denna kan \u00e4ndras\n            kl_loss = 1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var)\n            kl_loss = tf.reduce_mean(kl_loss)\n            kl_loss *= -0.5\n            total_loss = reconstruction_loss + (kl_loss)\n        grads = tape.gradient(total_loss, self.trainable_weights)\n        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n        return {\n            &quot;loss&quot;: total_loss,\n            &quot;reconstruction_loss&quot;: reconstruction_loss,\n            &quot;kl_loss&quot;: kl_loss,\n        }\n\n    def encoder_factor_vae(self):\n        x_inp = Input(shape=(64, 64, 1))\n        z = layers.Conv2D(filters=32, kernel_size=(4, 4), activation=&quot;relu&quot;, strides=2, padding=&quot;same&quot;)(x_inp)\n        z = BatchNormalization()(z)\n        z = layers.Conv2D(filters=32, kernel_size=(4, 4), activation=&quot;relu&quot;, strides=2, padding=&quot;same&quot;)(z)\n        z = BatchNormalization()(z)\n        z = layers.Conv2D(filters=64, kernel_size=(4, 4), activation=&quot;relu&quot;, strides=2, padding=&quot;same&quot;)(z)\n        z = BatchNormalization()(z)\n        z = layers.Conv2D(filters=64, kernel_size=(4, 4), activation=&quot;relu&quot;, strides=2, padding=&quot;same&quot;)(z)\n        z = BatchNormalization()(z)\n        z = layers.Flatten()(z)\n        z = Dense(units=128, activation='relu')(z)\n        z = BatchNormalization()(z)\n        z_mean = Dense(units=10, activation='relu')(z)  # h\u00e4r tror jag samplingen ska ske\n        z_log_var = Dense(units=10, activation='sigmoid')(z)  # b\u00f6r vara sampling fr\u00e5n reparameterizationen\n        z = Sampling()([z_mean, z_log_var])\n        encoder = keras.Model(x_inp, [z, z_mean, z_log_var], name=&quot;encoder&quot;)\n        encoder.summary()\n        return encoder\n\n    def decoder_factor_vae(self):\n        z_inp = Input(shape=(10,))\n        x_rec = Dense(units=128, activation='relu')(z_inp)\n        x_rec = BatchNormalization()(x_rec)\n        x_rec = Dense(units=1024, activation='relu')(x_rec) #hit fungerar\n        x_rec = BatchNormalization()(x_rec)\n        x_rec = layers.Reshape((4, 4, 64))(x_rec)\n        x_rec = layers.Conv2DTranspose(filters=64, kernel_size=(4, 4), activation='relu', strides=2, padding='same')(\n            x_rec)\n        x_rec = BatchNormalization()(x_rec)\n        x_rec = layers.Conv2DTranspose(filters=32, kernel_size=(4, 4), activation='relu', strides=2, padding='same')(\n            x_rec)\n        x_rec = BatchNormalization()(x_rec)\n        x_rec = layers.Conv2DTranspose(filters=32, kernel_size=(4, 4), activation='relu', strides=2, padding='same')(\n            x_rec)\n        x_rec = BatchNormalization()(x_rec)\n        x_rec = layers.Conv2DTranspose(filters=1, kernel_size=(4, 4), strides=2, padding='same')(\n            x_rec)\n        decoder = keras.Model(z_inp, x_rec, name=&quot;decoder&quot;)  # g\u00e5r att skicka in vilken batchsize som helst\n        decoder.summary()\n        return decoder\n\n    def MLP_classifier(self):\n        z_inp = Input(shape=(10,))\n        x_rec = Dense(units=1000)(z_inp) #1\n        x_rec = LeakyReLU(alpha=0.3)(x_rec)\n        x_rec = BatchNormalization()(x_rec)\n        x_rec = Dense(units=1000)(x_rec)  #2\n        x_rec = LeakyReLU(alpha=0.3)(x_rec)\n        x_rec = BatchNormalization()(x_rec)\n        x_rec = Dense(units=1000)(x_rec)  # 3\n        x_rec = LeakyReLU(alpha=0.3)(x_rec)\n        x_rec = BatchNormalization()(x_rec)\n        x_rec = Dense(units=1000)(x_rec)  # 4\n        x_rec = LeakyReLU(alpha=0.3)(x_rec)\n        x_rec = BatchNormalization()(x_rec)\n        x_rec = Dense(units=1000)(x_rec)  # 5\n        x_rec = LeakyReLU(alpha=0.3)(x_rec)\n        x_rec = BatchNormalization()(x_rec)\n        x_rec = Dense(units=2)(x_rec)  # 6\n        classifier = keras.Model(z_inp, x_rec, name=&quot;clasifier&quot;)\n        return classifier\n     \n    def generate_batches(data):\n        L = 50\n        start = 0\n        end = start + L\n        y_L_real = np.zeros((L, 2))\n        y_L_fake = np.zeros((L, 2))\n        y_L_real[:, 0] = 1\n        y_L_fake[:, 1] = 1\n        #total_y = np.vstack((y_L_real, y_L_fake))\n        while True:\n            x_L_real = data[start:end] #antalet v\u00e4rden \u00e4r 2xL\n            x_L_fake = np.roll(x_L_real, shift=2, axis=0)\n            total_x = np.vstack((x_L_real, x_L_fake))\n            start += L\n            end += L\n            if start &gt;= data.shape[0]:\n                start = 0\n                end = L\n            yield total_x, total_x\n            \n            \n    data = dsprite()\n    factor = factor_vae()\n    xyz = np.load(&quot;C:\\\\Users\\\\joaki\\\\OneDrive\\\\Skrivbord\\\\images\\\\dsprites_ndarray_&quot;\n                           &quot;co1sh3sc6or40x32y32_64x64.npz&quot;)\n    test_data = xyz['imgs']\n    train_steps = 3000\n    steps_epoch = 300\n    factor.compile(optimizer=keras.optimizers.Adam(0.001))\n    train_generator = generate_batches(test_data)\n    factor.fit_generator(train_generator, steps_per_epoch=steps_epoch, epochs=50)\n</code></pre>\n<p>There is a lot of code, but it  does work fine as long as I used my entire dataset, but as soon as I try to use my implemented &quot;train_generator&quot; it breaks down and I get the error message:\nNotImplementedError: When subclassing the <code>Model</code> class, you should implement a <code>call</code> method. So I know there is something wrong with my implementation of the train_generator, but I dont understand what I've missed, can someone provide me more information?</p>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 286}]
[{"items": [{"tags": ["python-3.x", "neural-network", "tensorflow2.0"], "owner": {"account_id": 4441934, "reputation": 1952, "user_id": 3616293, "user_type": "registered", "accept_rate": 35, "profile_image": "https://www.gravatar.com/avatar/cf7556b4227065cec9496375d64fea3d?s=256&d=identicon&r=PG&f=1", "display_name": "Arun", "link": "https://stackoverflow.com/users/3616293/arun"}, "is_answered": true, "view_count": 686, "answer_count": 1, "score": 0, "last_activity_date": 1594031989, "creation_date": 1592995776, "last_edit_date": 1592997392, "question_id": 62553320, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/62553320/tensorflow-2-0-data-augmentation-tf-keras-preprocessing-image-imagedatagenerato", "title": "TensorFlow 2.0 Data Augmentation: tf.keras.preprocessing.image.ImageDataGenerator flow() method", "body": "<p>I am trying to perform data augmentation using TensorFlow 2.2.0 and Python 3.7 for LeNet-300-100 Dense neural network for MNIST dataset. The code I have is as follows:</p>\n<pre><code>batch_size = 60\nnum_classes = 10\nnum_epochs = 100\n\n\n# Data preprocessing and cleadning:\n# input image dimensions\nimg_rows, img_cols = 28, 28\n\n# Load MNIST dataset-\n(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n\n\nif tf.keras.backend.image_data_format() == 'channels_first':\n    X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)\n    X_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)\n    input_shape = (1, img_rows, img_cols)\nelse:\n    X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n    X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n    input_shape = (img_rows, img_cols, 1)\n\nprint(&quot;\\n'input_shape' which will be used = {0}\\n&quot;.format(input_shape))\n# 'input_shape' which will be used = (28, 28, 1)\n\n\n# Convert datasets to floating point types-\nX_train = X_train.astype('float32')\nX_test = X_test.astype('float32')\n\n# Normalize the training and testing datasets-\nX_train /= 255.0\nX_test /= 255.0\n\n# convert class vectors/target to binary class matrices or one-hot encoded values-\ny_train = tf.keras.utils.to_categorical(y_train, num_classes)\ny_test = tf.keras.utils.to_categorical(y_test, num_classes)\n\n\nX_train.shape, y_train.shape\n# ((60000, 28, 28, 1), (60000, 10))\n\nX_test.shape, y_test.shape\n# ((10000, 28, 28, 1), (10000, 10))\n\n\n# Example of using 'tf.keras.preprocessing.image.ImageDataGenerator class's - flow(x, y)':\n\ndatagen = ImageDataGenerator(\n    # featurewise_center=True,\n    # featurewise_std_normalization=True,\n    rotation_range = 20,\n    width_shift_range = 0.2,\n    height_shift_range = 0.2,\n    horizontal_flip = True\n    )\n</code></pre>\n<p>Now, when I see the number of batches produced by 'datagen.flow()' with the code:</p>\n<pre><code># Sanity check-\ni = 0\n\nfor x, y in datagen.flow(X_train, y_train, batch_size = batch_size, shuffle = True):\n    # print(&quot;\\ntype(x) = {0}, type(y) = {1}&quot;.format(type(x), type(y)))\n    # print(&quot;x.shape = {0}, y.shape = {1}\\n&quot;.format(x.shape, y.shape))\n    print(i, end = ', ')\n    i += 1\n</code></pre>\n<p>The value of <em>i</em> keeps increasing without terminating. Of course something is going wrong. According to what I know, the number of batches = number of training examples / batch size.\nTherefore, in this example, the number of batches = 60000 / 60 = 1000.</p>\n<p>Then why is it producing so many batches of augmented data? And how can I stop it? What's going wrong?</p>\n<p>Thanks!</p>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 217}]
[{"items": [{"tags": ["python", "tensorflow", "machine-learning", "tensorflow2.0", "tf.keras"], "owner": {"account_id": 6086211, "reputation": 143, "user_id": 4750170, "user_type": "registered", "profile_image": "https://www.gravatar.com/avatar/254b92136c99574dbc4ddb4d599edf4b?s=256&d=identicon&r=PG&f=1", "display_name": "lida", "link": "https://stackoverflow.com/users/4750170/lida"}, "is_answered": true, "view_count": 2971, "accepted_answer_id": 60567742, "answer_count": 2, "score": 3, "last_activity_date": 1583616618, "creation_date": 1583089648, "last_edit_date": 1583616618, "question_id": 60478749, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/60478749/how-to-get-loss-gradient-wrt-internal-layer-output-in-tensorflow-2", "title": "How to get loss gradient wrt internal layer output in tensorflow 2?", "body": "<p>I would like to get gradient of the model's loss function with respect to specific layer's output during training. What I want to do with it next, is using a value of that gradient to modify something in layer in the next learning epoch. \nSo how to obtain that gradient?</p>\n\n<p>Here's a minimal example. \nMinimalRNNCell code is copied from TensorFlow's website and toy data is provided only to reproduce the behavior.</p>\n\n<pre><code>import tensorflow as tf \nfrom tensorflow.keras.layers import RNN, SimpleRNNCell, SimpleRNN, Layer, Dense, AbstractRNNCell\nfrom tensorflow.keras import Model\nimport numpy as np\nimport tensorflow.keras.backend as K\n\n\nclass MinimalRNNCell(AbstractRNNCell):\n\n    def __init__(self, units, **kwargs):\n      self.units = units\n      super(MinimalRNNCell, self).__init__(**kwargs)\n\n    @property\n    def state_size(self):\n      return self.units\n\n    def build(self, input_shape):\n      self.kernel = self.add_weight(shape=(input_shape[-1], self.units),\n                                    initializer='uniform',\n                                    name='kernel')\n      self.recurrent_kernel = self.add_weight(\n          shape=(self.units, self.units),\n          initializer='uniform',\n          name='recurrent_kernel')\n      self.built = True\n\n    def call(self, inputs, states):\n      prev_output = states[0]\n      h = K.dot(inputs, self.kernel)\n      output = h + K.dot(prev_output, self.recurrent_kernel)\n      return output, output\n\n\nclass MyModel(Model):\n    def __init__(self, size):\n        super(MyModel, self).__init__()\n        self.minimalrnn=RNN(MinimalRNNCell(size), name='minimalrnn')\n        self.out=Dense(4)\n\n    def call(self, inputs):\n        out=self.minimalrnn(inputs)\n        out=self.out(out)\n        return out\n\n\nx=np.array([[[3.],[0.],[1.],[2.],[3.]],[[3.],[0.],[1.],[2.],[3.]]])\ny=np.array([[[0.],[1.],[2.],[3.]],[[0.],[1.],[2.],[3.]]])\n\nmodel=MyModel(2)\nmodel.compile(optimizer='sgd', loss='mse')\nmodel.fit(x,y,epochs=10, batch_size=1, validation_split=0.2)\n\n\n\n</code></pre>\n\n<p>Now I want to get gradient of output of MyModel's minimalrnn layer (after every batch of data).</p>\n\n<p>How to do this? I suppose I can try with GradientTape watching model.get_layer('minimalrnn').output, but I need more learning resources or examples. </p>\n\n<p><strong>EDIT</strong></p>\n\n<p>I used GradientTape as in code provided by Tiago Martins Peres, but I specifically want to obtain gradient wrt layer output, and I'm still not able to achieve that. </p>\n\n<p>Now after class definitions my code looks like this:</p>\n\n<pre><code>\nx=np.array([[[3.],[0.],[1.],[2.],[3.]],[[3.],[0.],[1.],[2.],[3.]]])\ny=np.array([[0., 1., 2., 3.],[0., 1., 2., 3.]])\n\nmodel=MyModel(2)\n\n#inputs = tf.keras.Input(shape=(2,5,1))\n#model.call(x)\n\ndef gradients(model, inputs, targets):\n    with tf.GradientTape() as tape:\n        tape.watch(model.get_layer('minimalrnn').output)\n        loss_value = loss_fn(model, inputs, targets)\n    return tape.gradient(loss_value, model.trainable_variables)\n\ndef loss_fn(model, inputs, targets):\n    error = model(inputs) - targets\n    return tf.reduce_mean(tf.square(error))\n\noptimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\nprint(\"Initial loss: {:.3f}\".format(loss_fn(model, x, y)))\nfor i in range(10):\n    grads = gradients(model, x, y)\n    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n    print(\"Loss at step {:03d}: {:.3f}\".format(i, loss_fn(model, x, y)))\nprint(\"Final loss: {:.3f}\".format(loss_fn(model, x, y)))\n</code></pre>\n\n<p>As you can see I added tape.watch in gradients function definition, because I want to watch layer output. However I'm getting error:</p>\n\n<pre><code>Traceback (most recent call last):\n  File \"/home/.../test2.py\", line 73, in &lt;module&gt;\n    grads = gradients(model, x, y)\n  File \"/home/.../test2.py\", line 58, in gradients\n    print(model.get_layer('minimalrnn').output)\n  File \"/home/.../.venv/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py\", line 1553, in output\n    raise AttributeError('Layer ' + self.name + ' has no inbound nodes.')\nAttributeError: Layer minimalrnn has no inbound nodes.\n</code></pre>\n\n<p>I also tried to call model on Input with specified size (commented lines), according to answer to this: <a href=\"https://stackoverflow.com/questions/59383356/accessing-layers-input-output-using-tensorflow-2-0-model-sub-classing\">Accessing layer&#39;s input/output using Tensorflow 2.0 Model Sub-classing</a>. It didn't help. Specifying input shape in model's init function, like below,  also doesn't help - still the same error.</p>\n\n<pre><code>self.minimalrnn=RNN(MinimalRNNCell(size), name='minimalrnn', input_shape=(2,5,1))\n</code></pre>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 60}]
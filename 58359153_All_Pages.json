[{"items": [{"tags": ["tensorflow", "tensorflow2.0", "tf.keras", "keras-2"], "owner": {"account_id": 1720655, "reputation": 820, "user_id": 1757224, "user_type": "registered", "accept_rate": 85, "profile_image": "https://i.stack.imgur.com/yUXOQ.jpg?s=256&g=1", "display_name": "ARAT", "link": "https://stackoverflow.com/users/1757224/arat"}, "is_answered": true, "view_count": 5284, "accepted_answer_id": 58517209, "answer_count": 2, "score": 5, "last_activity_date": 1624190405, "creation_date": 1570919985, "question_id": 58359153, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/58359153/cancellederror-derived-recvasync-is-cancelled", "title": "CancelledError: [_Derived_]RecvAsync is cancelled", "body": "<p>I am having an issue. I run the same code on my local machine with CPU and Tensorflow 1.14.0. It works fine. However, when I run it on GPU with Tensorflow 2.0, I get</p>\n\n<pre><code>CancelledError:  [_Derived_]RecvAsync is cancelled.      [[{{node Adam/Adam/update/AssignSubVariableOp/_65}}]]   [[Reshape_13/_62]] [Op:__inference_distributed_function_3722]\n\nFunction call stack: distributed_function\n</code></pre>\n\n<p>Reproducible code is here:</p>\n\n<pre><code>import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow import keras\nprint(tf.__version__)\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nbatch_size = 32\nnum_obs = 100\nnum_cats = 1 # number of categorical features\nn_steps = 10 # number of timesteps in each sample\nn_numerical_feats = 18 # number of numerical features in each sample\ncat_size = 12 # number of unique categories in each categorical feature\nembedding_size = 1 # embedding dimension for each categorical feature\n\nlabels =  np.random.random(size=(num_obs*n_steps,1)).reshape(-1,n_steps,1)\nprint(labels.shape)\n#(100, 10, 1)\n\n#3 numerical variable\nnum_data = np.random.random(size=(num_obs*n_steps,n_numerical_feats))\nprint(num_data.shape)\n#(1000, 3)\n#Reshaping numeric features to fit into an LSTM network\nfeatures = num_data.reshape(-1,n_steps, n_numerical_feats)\nprint(features.shape)\n#(100, 10, 3)\n\n#one categorical variables with 4 levels\ncat_data = np.random.randint(0,cat_size,num_obs*n_steps)\nprint(cat_data.shape)\n#(1000,)\nidx = cat_data.reshape(-1, n_steps)\nprint(idx.shape)\n#(100, 10)\n\nnumerical_inputs = keras.layers.Input(shape=(n_steps, n_numerical_feats), name='numerical_inputs', dtype='float32')\n#&lt;tf.Tensor 'numerical_inputs:0' shape=(?, 10, 36) dtype=float32&gt;\n\ncat_input = keras.layers.Input(shape=(n_steps,), name='cat_input')\n#&lt;tf.Tensor 'cat_input:0' shape=(None, 10) dtype=float32&gt;\n\ncat_embedded = keras.layers.Embedding(cat_size, embedding_size, embeddings_initializer='uniform')(cat_input)\n#&lt;tf.Tensor 'embedding_1/Identity:0' shape=(None, 10, 1) dtype=float32&gt;\n\nmerged = keras.layers.concatenate([numerical_inputs, cat_embedded])\n#&lt;tf.Tensor 'concatenate_1/Identity:0' shape=(None, 10, 37) dtype=float32&gt;\n\nlstm_out = keras.layers.LSTM(64, return_sequences=True)(merged)\n#&lt;tf.Tensor 'lstm_2/Identity:0' shape=(None, 10, 64) dtype=float32&gt;\n\nDense_layer1 = keras.layers.Dense(32, activation='relu', use_bias=True)(lstm_out)\n#&lt;tf.Tensor 'dense_4/Identity:0' shape=(None, 10, 32) dtype=float32&gt;\nDense_layer2 = keras.layers.Dense(1, activation='linear', use_bias=True)(Dense_layer1 )\n#&lt;tf.Tensor 'dense_5/Identity:0' shape=(None, 10, 1) dtype=float32&gt;\n\nmodel = keras.models.Model(inputs=[numerical_inputs, cat_input], outputs=Dense_layer2)\n\n#compile model\noptimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\nmodel.compile(loss='mse',\n              optimizer=optimizer,\n              metrics=['mae', 'mse'])\nEPOCHS =5\n\n#fit the model\n#you can use input layer names instead\nhistory = model.fit([features, idx], \n                    y = labels,\n                    epochs=EPOCHS,\n                    batch_size=batch_size)\n</code></pre>\n\n<p>Does anyone have similar issues? Obviously this is a bug but i do not know how to come around because I want to use Tensorflow 2.0.</p>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 123}]
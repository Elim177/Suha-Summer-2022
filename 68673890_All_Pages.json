[{"items": [{"tags": ["python", "tensorflow", "machine-learning", "keras", "recurrent-neural-network"], "owner": {"account_id": 20445571, "reputation": 117, "user_id": 15001463, "user_type": "registered", "profile_image": "https://i.stack.imgur.com/QwZ6d.jpg?s=256&g=1", "display_name": "Jared Frazier", "link": "https://stackoverflow.com/users/15001463/jared-frazier"}, "is_answered": false, "view_count": 152, "answer_count": 1, "score": 0, "last_activity_date": 1628636226, "creation_date": 1628200380, "question_id": 68673890, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/68673890/for-loop-with-grucell-in-call-method-of-subclassed-tf-keras-model", "title": "For loop with GRUCell in call method of subclassed tf.keras.Model", "body": "<p>I have subclassed <code>tf.keras.Model</code> and I use <code>tf.keras.layers.GRUCell</code> in a for loop to compute sequences 'y_t' (n, timesteps, hidden_units) and final hidden states 'h_t' (n, hidden_units). For my loop to output 'y_t', I update a <code>tf.Variable</code> after each iteration of the loop. Calling the model with <code>model(input)</code> is not a problem, but <strong>when I fit the model with the for loop in the call method I get either a TypeError or a ValueError.</strong></p>\n<p>Please note, I cannot simply use <code>tf.keras.layers.GRU</code> because I am trying to implement this <a href=\"https://www.isca-speech.org/archive/Interspeech_2019/pdfs/1548.pdf\" rel=\"nofollow noreferrer\">paper</a>. Instead of just passing x_t to the next cell in the RNN, the paper performs some computation as a step in the for loop (they implement in PyTorch) and pass the result of that computation to the RNN cell. They end up essentially doing this: h_t = f(special_x_t, h_t-1).</p>\n<p>Please see the model below that causes the error:</p>\n<pre class=\"lang-py prettyprint-override\"><code>class CustomGruRNN(tf.keras.Model):\n    def __init__(self, batch_size, timesteps, hidden_units, features, **kwargs):\n\n        # Inheritance\n        super().__init__(**kwargs)\n\n        # Args\n        self.batch_size = batch_size\n        self.timesteps = timesteps\n        self.hidden_units = hidden_units        \n\n        # Stores y_t\n        self.rnn_outputs = tf.Variable(tf.zeros(shape=(batch_size, timesteps, hidden_units)), trainable=False)\n\n        # To be used in for loop in call\n        self.gru_cell = tf.keras.layers.GRUCell(units=hidden_units)\n\n        # Reshape to match input dimensions\n        self.dense = tf.keras.layers.Dense(units=features)\n\n    def call(self, inputs):\n        &quot;&quot;&quot;Inputs is rank-3 tensor of shape (n, timesteps, features) &quot;&quot;&quot;\n\n        # Initial state for gru cell\n        h_t = tf.zeros(shape=(self.batch_size, self.hidden_units))\n\n        for timestep in tf.range(self.timesteps):\n            # Get the the timestep of the inputs\n            x_t = tf.gather(inputs, timestep, axis=1)  # Same as x_t = inputs[:, timestep, :]\n\n            # Compute outputs and hidden states\n            y_t, h_t = self.gru_cell(x_t, h_t)\n            \n            # Update y_t at the t^th timestep\n            self.rnn_outputs = self.rnn_outputs[:, timestep, :].assign(y_t)\n\n        # Outputs need to have same last dimension as inputs\n        outputs = self.dense(self.rnn_outputs)\n\n        return outputs\n</code></pre>\n<p>An example that would throw the error:</p>\n<pre class=\"lang-py prettyprint-override\"><code># Arbitrary values for dataset\nnum_samples = 128\nbatch_size = 4\ntimesteps = 5\nfeatures = 10\n\n# Arbitrary dataset\nx = tf.random.uniform(shape=(num_samples, timesteps, features))\ny = tf.random.uniform(shape=(num_samples, timesteps, features))\n\ntrain_data = tf.data.Dataset.from_tensor_slices((x, y))\ntrain_data = train_data.shuffle(batch_size).batch(batch_size, drop_remainder=True)\n\n# Model with arbitrary hidden units\nmodel = CustomGruRNN(batch_size, timesteps, hidden_units=5)\nmodel.compile(loss=tf.keras.losses.MeanSquaredError(), optimizer=tf.keras.optimizers.Adam())\n</code></pre>\n<p>When running eagerly:</p>\n<pre class=\"lang-py prettyprint-override\"><code>model.fit(train_data, epochs=2, run_eagerly=True)\n</code></pre>\n<blockquote>\n<p>Epoch 1/2\nWARNING:tensorflow:Gradients do not exist for variables\n['stack_overflow_gru_rnn/gru_cell/kernel:0',\n'stack_overflow_gru_rnn/gru_cell/recurrent_kernel:0',\n'stack_overflow_gru_rnn/gru_cell/bias:0'] when minimizing the loss.\nValueError: substring not found ValueError</p>\n</blockquote>\n<p>When not running eagerly:</p>\n<pre class=\"lang-py prettyprint-override\"><code>model.fit(train_data, epochs=2, run_eagerly=False)\n</code></pre>\n<blockquote>\n<p>Epoch 1/2\nTypeError: in user code:\nTypeError: Can not convert a NoneType into a Tensor or Operation.</p>\n</blockquote>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 193}]
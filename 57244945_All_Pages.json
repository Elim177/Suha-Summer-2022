[{"items": [{"tags": ["tensorflow2.0", "tensorflow-probability"], "owner": {"account_id": 108161, "reputation": 5951, "user_id": 287238, "user_type": "registered", "accept_rate": 75, "profile_image": "https://i.stack.imgur.com/oQJH2.jpg?s=256&g=1", "display_name": "mathtick", "link": "https://stackoverflow.com/users/287238/mathtick"}, "is_answered": true, "view_count": 1011, "accepted_answer_id": 57312748, "answer_count": 1, "score": 3, "last_activity_date": 1564674591, "creation_date": 1564347762, "last_edit_date": 1564348756, "question_id": 57244945, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/57244945/how-to-train-a-tensorflow-probability-bijector-weights-in-tensorflow-2-0", "title": "How to train a tensorflow probability bijector (weights) in tensorflow 2.0?", "body": "<p>The following example is a simple version of some bijector transform (for example a generalization of BatchNorm (fit a distribution to the inputs and use the CDF to transform the inputs like a copula would). The code below leads to \"No gradients provided\" errors.</p>\n\n<p>Is there a pattern for this in the docs? I am not finding it. </p>\n\n<pre><code>import tensorflow as tf\nimport tensorflow_probability as tfp\ntfb = tfp.bijectors\ntfd = tfp.distributions\n\n\nclass BijectorBase(tfb.Bijector):\n\n    def transformed_log_prob(self, log_prob, x):\n        return (self.inverse_log_det_jacobian(x, event_ndims=0) + log_prob(tfp.bijector.inverse(x)))\n\n    def transformed_sample(self, x):\n        return tfp.bijector.forward(x)\n\n\n# quite easy to interpret - multiplying by alpha causes a contraction in volume.\nclass LeakyReLU(BijectorBase):\n\n    def __init__(self, alpha=0.5, validate_args=False, name=\"leaky_relu\"):\n        super().__init__(event_ndims=1, validate_args=validate_args, name=name)\n        self.alpha = alpha\n\n    def _forward(self, x):\n        return tf.where(tf.greater_equal(x, 0), x, self.alpha * x)\n\n    def _inverse(self, y):\n        return tf.where(tf.greater_equal(y, 0), y, 1. / self.alpha * y)\n\n    def _inverse_log_det_jacobian(self, y):\n        event_dims = self._event_dims_tensor(y)\n        I = tf.ones_like(y)\n        J_inv = tf.where(tf.greater_equal(y, 0), I, 1.0 / self.alpha * I)\n        # abs is actually redundant here, since this det Jacobian is &gt; 0\n        log_abs_det_J_inv = tf.math.log(tf.abs(J_inv))\n        return tf.reduce_sum(log_abs_det_J_inv, axis=event_dims)\n\nclass Exp(BijectorBase):\n\n    def __init__(self, validate_args=False, name=\"exp\"):\n        super(Exp, self).__init__(\n            validate_args=validate_args,\n            forward_min_event_ndims=0,\n            name=name)\n\n    def _forward(self, x):\n        return tf.math.exp(x)\n\n    def _inverse(self, y):\n        return tf.math.log(y)\n\n    def _inverse_log_det_jacobian(self, y):\n        return -self._forward_log_det_jacobian(self._inverse(y))\n        # return -self._forward_log_det_jac(self._inverse(y))  # Note negation. alt version\n\n    def _forward_log_det_jacobian(self, x):\n        # Notice that we needn't do any reducing, even when`event_ndims &gt; 0`.\n        # The base Bijector class will handle reducing for us; it knows how\n        # to do so because we called `super` `__init__` with\n        # `forward_min_event_ndims = 0`.\n        return x\n\n\nclass TrainStepper():\n    def __init__(self, optimizer, model):\n        self.optimizer = optimizer\n        self.model = model\n        self._debug = False\n        self._tfcall = tf.function(self._call)\n        self.step = 0\n\n    def debug(self, value=None):\n        if value is None:\n            self._debug = not self._debug\n        else:\n            self._debug = value\n        print(f'debug={self.debug}')\n\n    def __call__(self, *data):\n        self.step += 1\n        if self._debug:\n            return self._call(*data)\n        else:\n            return self._tfcall(*data)\n\n    def _call(self, *data):\n        with tf.GradientTape() as tape:\n            d = self.model(*data)\n        print(self.model.trainable_variables)\n        gradients = tape.gradient(d['loss'], self.model.trainable_variables)\n        _ = self.optimizer.apply_gradients(zip(gradients, self.model.trainable_variables))\n        return d\n\n    def train(self, data, epochs=1000, log_period=100):\n        for epoch in range(epochs):\n            d = self(*data)\n            if self.step % log_period == 0:\n                print({k: v.numpy() for k, v in d.items()})\n                for k, v in d.items():\n                    tf.summary.scalar(k, v, step=self.step)\n\nimport numpy as np\nx = np.random.rand(100, 1) * 2.34 + 7.3\n\nclass MyLayer(tf.keras.models.Model):\n\n    def __init__(self):\n        super().__init__()\n        self.bijectors = list()\n        self.shift = tf.Variable([0.], dtype=tf.float32, name='shift')\n        self.scale_diag = tf.Variable([10.], dtype=tf.float32, name='scale_diag')\n        self.bijectors.append(tfb.Affine(shift=self.shift, scale_diag=self.scale_diag))        self.bijectors.append(Exp())\n        self.bijector = tfb.Chain(self.bijectors[::-1])\n        self.model = tfd.TransformedDistribution(\n                        distribution=tfd.Uniform(),\n                        bijector=self.bijector,\n                        event_shape=(1,))\n\n    def call(self, *inputs):\n        return self.model(*inputs)\n\nclass LossModel(tf.keras.models.Model):\n\n    def __init__(self, bijector_layer):\n        super().__init__()\n        self.model = bijector_layer\n\n    def call(self, *x):\n        return dict(loss=tf.reduce_mean(self.model.model.log_prob(x)))\n\nmylayer = MyLayer()\nlossmodel = LossModel(mylayer)\noptimizer = tf.optimizers.Adam(learning_rate=0.001)\nstepper = TrainStepper(optimizer=optimizer, model=lossmodel)\n\nstepper.train(x)\n</code></pre>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 87}]
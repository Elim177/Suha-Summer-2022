[{"items": [{"tags": ["neural-network", "tensorflow2.0"], "owner": {"account_id": 4441934, "reputation": 1952, "user_id": 3616293, "user_type": "registered", "accept_rate": 35, "profile_image": "https://www.gravatar.com/avatar/cf7556b4227065cec9496375d64fea3d?s=256&d=identicon&r=PG&f=1", "display_name": "Arun", "link": "https://stackoverflow.com/users/3616293/arun"}, "is_answered": false, "view_count": 96, "answer_count": 1, "score": 1, "last_activity_date": 1597593170, "creation_date": 1597582154, "question_id": 63437089, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/63437089/freezing-tensorflow2-layers", "title": "Freezing TensorFlow2 layers", "body": "<p>I have a LeNet-300-100 dense neural network for MNIST dataset where I want to freeze the first two layers having 300 and 100 hidden neurons in the first two hidden layers. I just want to train the output layer. The code I have to do this is as follows:</p>\n<pre><code>from tensorflow import keras\n\ninner_model = keras.Sequential(\n    [\n        keras.Input(shape=(1024,)),\n        keras.layers.Dense(300, activation=&quot;relu&quot;, kernel_initializer = tf.initializers.GlorotNormal()),\n        keras.layers.Dense(100, activation=&quot;relu&quot;, kernel_initializer = tf.initializers.GlorotNormal()),\n    ]\n)\n\nmodel_mnist = keras.Sequential(\n    [keras.Input(shape=(1024,)), inner_model, keras.layers.Dense(10, activation=&quot;softmax&quot;),]\n)\n\n# model_mnist.trainable = True  # Freeze the outer model\n# Freeze the inner model-\ninner_model.trainable = False\n\n\n# Sanity check-\ninner_model.trainable, model_mnist.trainable\n# (False, True)\n\n# Compile NN-\nmodel_mnist.compile(\n    loss=tf.keras.losses.categorical_crossentropy,\n    # optimizer='adam',\n    optimizer=tf.keras.optimizers.Adam(lr = 0.0012),\n    metrics=['accuracy'])\n    \n</code></pre>\n<p>However, this code doesn't seem to be freezing the first two hidden layers and they are also learning. What am I doing wrong?</p>\n<p>Thanks!</p>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 193}]
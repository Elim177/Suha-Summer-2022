[{"items": [{"tags": ["tensorflow", "tensorflow-datasets"], "owner": {"account_id": 113180, "reputation": 4305, "user_id": 298209, "user_type": "registered", "accept_rate": 50, "profile_image": "https://www.gravatar.com/avatar/22dcc7ab1b47c2f014361452b5453544?s=256&d=identicon&r=PG&f=1", "display_name": "Milad", "link": "https://stackoverflow.com/users/298209/milad"}, "is_answered": false, "view_count": 497, "answer_count": 1, "score": 1, "last_activity_date": 1535054591, "creation_date": 1535044549, "last_edit_date": 1535054591, "question_id": 51991102, "content_license": "CC BY-SA 4.0", "link": "https://stackoverflow.com/questions/51991102/how-to-get-the-same-data-batch-multiple-times-using-tensorflows-tf-data-api", "title": "How to get the same data batch multiple times using TensorFlow&#39;s `tf.data` API", "body": "<p>Is there a way to evaluate a tensor that depends on an tf.data iterator but temporarily pause the iterator so that it returns the previous batch? </p>\n\n<p>Imagine snippet below:</p>\n\n<pre><code>dataset = tf.data.Dataset.range(5)\niterator = dataset.make_one_shot_iterator()\nnext_batch = iterator.get_next()\ntrain_op = next_batch * 10\n</code></pre>\n\n<p>Every time I evaluate <code>train_op</code> it does so by fetching a new batch of data \u2013 which is what I want. However every N steps I'd like to do some additional stuff for debugging like evaluating accuracy on the training batch, creating a checkpoint, running things with dropout disabled etc. I'd like these operations to happen on the same data batch I have just used but I haven't found a way to <em>pause</em> <code>tf.data</code> iterator for one or multiple steps.</p>\n\n<p>The obvious solution is to use placeholders instead of directly using <code>next_batch</code>. This means I have to evaluate <code>next_batch</code> first, and then feed it back to the session using <code>feed_dict</code> to evaluate <code>train_op</code>. I believe this is not recommended due to performance penalty. Is that still the case? If so what is the recommended way to deal with these cases?</p>\n\n<p><strong>Edit</strong>: adding pseudo code for what I'm after:</p>\n\n<pre><code>for step in num_steps:\n\n    sess.run(train_op) # train_op depends on next_batch and therefore fetches new batch\n\n    if step % N == 0:\n        # I want below to run on the same batch above but acc_op also\n        # depends on next_batch and therefore fetches a new batch\n        acc = sess.run([acc_op, saver_op, feed_dic={keep_drop:1}]) \n</code></pre>\n"}], "has_more": false, "quota_max": 300, "quota_remaining": 106}]